{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network (now predicts only the median)\n",
    "class NextStateMedianNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(NextStateMedianNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(state_dim + action_dim, 256)\n",
    "        self.layer2 = nn.Linear(256, 256)\n",
    "        self.layer3 = nn.Linear(256, state_dim)  # Single output per state dim\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        if len(state.shape) == 1:\n",
    "            x = torch.cat((action, state))\n",
    "        else:\n",
    "            x = torch.cat((action, state), dim=1) # .unsqueeze(1)\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        return self.layer3(x)\n",
    "\n",
    "def quantile_loss_median(predicted, target):\n",
    "    error = target - predicted\n",
    "    quantile = torch.tensor(0.5)\n",
    "    loss = torch.max(\n",
    "        quantile * error,\n",
    "        (quantile - 1) * error\n",
    "    )\n",
    "    return loss.mean()\n",
    "\n",
    "def mse_loss(predicted, target):\n",
    "    error = target - predicted\n",
    "    return error.pow(2).mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test where I removed the quadratic part, need to put the threshold back to 1 to back to standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextStateQuantileNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, num_quantiles):\n",
    "        super(NextStateQuantileNetwork, self).__init__()\n",
    "        self.num_quantiles = num_quantiles\n",
    "\n",
    "        # Input layer (state + action concatenation)\n",
    "        self.layer1 = nn.Linear(state_dim + action_dim, 256)\n",
    "        self.layer2 = nn.Linear(256, 256)\n",
    "        self.layer3 = nn.Linear(256, state_dim * num_quantiles)  # Output quantiles for each state dimension\n",
    "        # self.layer3 = torch.tanh(256, state_dim * num_quantiles)  # Output quantiles for each state dimension\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        # Concatenate state and action\n",
    "        # x = torch.cat((action, state))\n",
    "        # print(\"action \", action, \"\\n\")\n",
    "        \n",
    "        # print(\"state \", state, \"\\n\")\n",
    "        # print(\"state.shape \", state.shape, \"\\n\")\n",
    "        # print(\"action \", action, \"\\n\")\n",
    "        # print(\"action.shape \", action.shape, \"\\n\")\n",
    "        \n",
    "        if len(state.shape) == 1:\n",
    "            x = torch.cat((action, state))\n",
    "        else:\n",
    "            x = torch.cat((action, state), dim=1) # .unsqueeze(1)\n",
    "            \n",
    "        # print(\"x \", x, \"\\n\")\n",
    "        # print(\"x.shape \", x.shape, \"\\n\")\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x.view(-1, self.num_quantiles, state.size(-1))\n",
    "\n",
    "\n",
    "def quantile_huber_loss(predicted, target, quantiles, batch_size=32):\n",
    "    \"\"\"\n",
    "    Calculate Quantile Huber Loss.\n",
    "    :param predicted: Predicted quantiles, shape (batch_size, state_dim, num_quantiles)\n",
    "    :param target: Target next state, shape (batch_size, state_dim)\n",
    "    :param quantiles: Quantiles (e.g., [0.1, 0.3, 0.7, 0.9]), shape (num_quantiles,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # print(\"target.shape \", target.shape, \"\\n\")\n",
    "    # print(\"target \", target, \"\\n\")\n",
    "    # target = target.unsqueeze(-1)  # Shape: (batch_size, state_dim, 1)\n",
    "    target = target.unsqueeze(1).repeat(1,len(quantiles),1)\n",
    "    # print(\"target \", target, \"\\n\")\n",
    "    # print(\"predicted \", predicted, \"\\n\")\n",
    "    # print(\"target.shape \", target.shape, \"\\n\")\n",
    "    # print(\"predicted.shape \", predicted.shape, \"\\n\")\n",
    "    \n",
    "    error = target - predicted  # Shape: (batch_size, state_dim, num_quantiles)\n",
    "    \n",
    "    # print(\"error \", error, \"\\n\")\n",
    "    quantiles = quantiles.view(1, -1, 1)\n",
    "    quantiles = quantiles.repeat(batch_size, 1, target.shape[-1])  # Shape: [3, 4, 2]\n",
    "    # quantiles = quantiles.repeat(batch_size, target.shape[-1], 1) \n",
    "    # quantiles = quantiles.transpose(1, 2)  # Shape: [3, 2, 4]\n",
    "    # print(\"quantiles \", quantiles, \"\\n\")\n",
    "    \n",
    "    # # Make delta adaptive by scaling it based on quantiles\n",
    "    # delta = 1.0\n",
    "    # adaptive_delta = delta * (1.0 + torch.abs(quantiles - 0.5))  # Give more tolerance to extreme quantiles\n",
    "    \n",
    "    # # print(\"quantiles.shape \", quantiles.shape, \"\\n\")\n",
    "    # # Calculate loss\n",
    "    # huber_loss = torch.where(\n",
    "    #     error.abs() <= 0.0, # 1.0\n",
    "    #     0.5 * error.pow(2),\n",
    "    #     error.abs() - 0.5\n",
    "    # )\n",
    "\n",
    "    # # huber_loss = error.abs()-0.5  # Simple L1 loss\n",
    "    \n",
    "    # # print(\"huber_loss \", huber_loss, \"\\n\")\n",
    "    # # print(\"huber_loss.shape \", huber_loss.shape, \"\\n\")\n",
    "    \n",
    "    # # Quantile loss computation\n",
    "    # quantile_loss = (quantiles - (error < 0).float()).abs() * huber_loss\n",
    "\n",
    "    # Standard Quantile Loss (Pinball Loss)\n",
    "    quantile_loss = torch.max(\n",
    "        quantiles * error,\n",
    "        (quantiles - 1) * error\n",
    "    )\n",
    "\n",
    "    return quantile_loss.mean()\n",
    "\n",
    "    # Quantile loss computation\n",
    "    # quantile_loss = torch.abs(quantiles - (error.detach() < 0).float()) * huber_loss\n",
    "    # return quantile_loss.sum(dim=1).mean()\n",
    "\n",
    "# def quantile_huber_loss(predicted, target, quantiles, batch_size=32):\n",
    "#     \"\"\"\n",
    "#     Calculate Quantile Huber Loss.\n",
    "#     :param predicted: Predicted quantiles, shape (batch_size, state_dim, num_quantiles)\n",
    "#     :param target: Target next state, shape (batch_size, state_dim)\n",
    "#     :param quantiles: Quantiles (e.g., [0.1, 0.3, 0.7, 0.9]), shape (num_quantiles,)\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # print(\"target.shape \", target.shape, \"\\n\")\n",
    "#     # print(\"target \", target, \"\\n\")\n",
    "#     # target = target.unsqueeze(-1)  # Shape: (batch_size, state_dim, 1)\n",
    "#     target = target.unsqueeze(1).repeat(1,len(quantiles),1)\n",
    "#     print(\"target \", target, \"\\n\")\n",
    "#     print(\"predicted \", predicted, \"\\n\")\n",
    "#     print(\"target.shape \", target.shape, \"\\n\")\n",
    "#     print(\"predicted.shape \", predicted.shape, \"\\n\")\n",
    "    \n",
    "#     error = target - predicted  # Shape: (batch_size, state_dim, num_quantiles)\n",
    "    \n",
    "#     # print(\"error \", error, \"\\n\")\n",
    "#     quantiles = quantiles.view(1, -1, 1)\n",
    "#     quantiles = quantiles.repeat(batch_size, 1, target.shape[-1])  # Shape: [3, 4, 2]\n",
    "#     # quantiles = quantiles.repeat(batch_size, target.shape[-1], 1) \n",
    "#     # quantiles = quantiles.transpose(1, 2)  # Shape: [3, 2, 4]\n",
    "#     print(\"quantiles \", quantiles, \"\\n\")\n",
    "    \n",
    "#     # print(\"quantiles.shape \", quantiles.shape, \"\\n\")\n",
    "#     # Calculate loss\n",
    "#     huber_loss = torch.where(\n",
    "#         error.abs() <= 1.0,\n",
    "#         0.5 * error.pow(2),\n",
    "#         error.abs() - 0.5\n",
    "#     )\n",
    "    \n",
    "#     # print(\"huber_loss \", huber_loss, \"\\n\")\n",
    "#     # print(\"huber_loss.shape \", huber_loss.shape, \"\\n\")\n",
    "    \n",
    "#     # Quantile loss computation\n",
    "#     # quantile_loss = (quantiles - (error < 0).float()).abs() * huber_loss\n",
    "#     # return quantile_loss.mean()\n",
    "\n",
    "#     # Quantile loss computation\n",
    "#     quantile_loss = torch.abs(quantiles - (error.detach() < 0).float()) * huber_loss\n",
    "#     return quantile_loss.sum(dim=1).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph of number of values below the different quantiles graph and calculation functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nb_below_quantiles(nb_belowq1_list, nb_belowq2_list, nb_belowq3_list, nb_belowq4_list, nb_belowq5_list, nb_belowq6_list, nb_belowq7_list, nb_belowq8_list, nb_belowq9_list, nb_belowq10_list, variable):\n",
    "    \n",
    "    if variable == \"theta\":\n",
    "        variable = r\"$\\theta$\"\n",
    "\n",
    "    plt.figure(1)\n",
    "    # plt.plot(nb_belowq1_list, label=f'quantile1_{variable}')\n",
    "    # plt.plot(nb_belowq2_list, label=f'quantile2_{variable}')\n",
    "    # plt.plot(nb_belowq3_list, label=f'quantile3_{variable}')\n",
    "    # plt.plot(nb_belowq4_list, label=f'quantile4_{variable}')\n",
    "    # plt.plot(nb_belowq5_list, label=f'quantile5_{variable}')\n",
    "    # plt.plot(nb_belowq6_list, label=f'quantile6_{variable}')\n",
    "    # plt.plot(nb_belowq7_list, label=f'quantile7_{variable}')\n",
    "    # plt.plot(nb_belowq8_list, label=f'quantile8_{variable}')\n",
    "    # plt.plot(nb_belowq9_list, label=f'quantile9_{variable}')\n",
    "    # plt.plot(nb_belowq10_list, label=f'quantile10_{variable}')\n",
    "    plt.plot(nb_belowq1_list, label=f'Q1_{variable}')\n",
    "    plt.plot(nb_belowq2_list, label=f'Q2_{variable}')\n",
    "    plt.plot(nb_belowq3_list, label=f'Q3_{variable}')\n",
    "    plt.plot(nb_belowq4_list, label=f'Q4_{variable}')\n",
    "    plt.plot(nb_belowq5_list, label=f'Q5_{variable}')\n",
    "    plt.plot(nb_belowq6_list, label=f'Q6_{variable}')\n",
    "    plt.plot(nb_belowq7_list, label=f'Q7_{variable}')\n",
    "    plt.plot(nb_belowq8_list, label=f'Q8_{variable}')\n",
    "    plt.plot(nb_belowq9_list, label=f'Q9_{variable}')\n",
    "    plt.plot(nb_belowq10_list, label=f'Q10_{variable}')\n",
    "    plt.hlines(0.1, 0, len(nb_belowq1_list), colors='r', linestyles='dashed') # , label='quantile1'\n",
    "    plt.hlines(0.2, 0, len(nb_belowq1_list), colors='r', linestyles='dashed') # , label='quantile2'\n",
    "    plt.hlines(0.3, 0, len(nb_belowq1_list), colors='r', linestyles='dashed') # , label='quantile3'\n",
    "    plt.hlines(0.4, 0, len(nb_belowq1_list), colors='r', linestyles='dashed') # , label='quantile4'\n",
    "    plt.hlines(0.5, 0, len(nb_belowq1_list), colors='r', linestyles='dashed') # , label='quantile5'\n",
    "    plt.hlines(0.6, 0, len(nb_belowq1_list), colors='r', linestyles='dashed') # , label='quantile6'\n",
    "    plt.hlines(0.7, 0, len(nb_belowq1_list), colors='r', linestyles='dashed') # , label='quantile7'\n",
    "    plt.hlines(0.8, 0, len(nb_belowq1_list), colors='r', linestyles='dashed') # , label='quantile8'\n",
    "    plt.hlines(0.9, 0, len(nb_belowq1_list), colors='r', linestyles='dashed') # , label='quantile9'\n",
    "    plt.hlines(1.0, 0, len(nb_belowq1_list), colors='r', linestyles='dashed') # , label='quantile10'\n",
    "    plt.xlabel('Number of steps')\n",
    "    plt.ylabel(f'Number of steps below quantile {variable}')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_below_quantile(env, quantile0, quantile1, quantile2, quantile3, quantile4, quantile5, quantile6, quantile7, quantile8, quantile9, quantile10):\n",
    "    \n",
    "    nb_belowq1 = 0\n",
    "    nb_belowq2 = 0\n",
    "    nb_belowq3 = 0\n",
    "    nb_belowq4 = 0\n",
    "    nb_belowq5 = 0\n",
    "    nb_belowq6 = 0\n",
    "    nb_belowq7 = 0\n",
    "    nb_belowq8 = 0\n",
    "    nb_belowq9 = 0\n",
    "    nb_belowq10 = 0\n",
    "    \n",
    "    nb_belowq1_list = [0]\n",
    "    nb_belowq2_list = [0]\n",
    "    nb_belowq3_list = [0]\n",
    "    nb_belowq4_list = [0]\n",
    "    nb_belowq5_list = [0]\n",
    "    nb_belowq6_list = [0]\n",
    "    nb_belowq7_list = [0]\n",
    "    nb_belowq8_list = [0]\n",
    "    nb_belowq9_list = [0]\n",
    "    nb_belowq10_list = [0]\n",
    "    \n",
    "    \n",
    "    for i in range(len(quantile0)):\n",
    "        \n",
    "        if env[i] < quantile1[i]:\n",
    "            nb_belowq1 += 1\n",
    "            \n",
    "        if env[i] < quantile2[i]:\n",
    "            nb_belowq2 += 1\n",
    "            \n",
    "        if env[i] < quantile3[i]:\n",
    "            nb_belowq3 += 1\n",
    "            \n",
    "        if env[i] < quantile4[i]:\n",
    "            nb_belowq4 += 1\n",
    "            \n",
    "        if env[i] < quantile5[i]:\n",
    "            nb_belowq5 += 1\n",
    "            \n",
    "        if env[i] < quantile6[i]:\n",
    "            nb_belowq6 += 1\n",
    "            \n",
    "        if env[i] < quantile7[i]:\n",
    "            nb_belowq7 += 1\n",
    "            \n",
    "        if env[i] < quantile8[i]:\n",
    "            nb_belowq8 += 1\n",
    "            \n",
    "        if env[i] < quantile9[i]:\n",
    "            nb_belowq9 += 1\n",
    "            \n",
    "        if env[i] < quantile10[i]:\n",
    "            nb_belowq10 += 1\n",
    "\n",
    "        nb_belowq1_list.append(nb_belowq1/(i+1))\n",
    "        nb_belowq2_list.append(nb_belowq2/(i+1))\n",
    "        nb_belowq3_list.append(nb_belowq3/(i+1))\n",
    "        nb_belowq4_list.append(nb_belowq4/(i+1))\n",
    "        nb_belowq5_list.append(nb_belowq5/(i+1))\n",
    "        nb_belowq6_list.append(nb_belowq6/(i+1))\n",
    "        nb_belowq7_list.append(nb_belowq7/(i+1))\n",
    "        nb_belowq8_list.append(nb_belowq8/(i+1))\n",
    "        nb_belowq9_list.append(nb_belowq9/(i+1))\n",
    "        nb_belowq10_list.append(nb_belowq10/(i+1))\n",
    "        \n",
    "        \n",
    "\n",
    "    return nb_belowq1_list, nb_belowq2_list, nb_belowq3_list, nb_belowq4_list, nb_belowq5_list, nb_belowq6_list, nb_belowq7_list, nb_belowq8_list, nb_belowq9_list, nb_belowq10_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acrobot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When taking a step in the env, the state variables are $\\cos{(\\theta_1)}, \\sin{(\\theta_1)}, \\cos{(\\theta_2)}, \\sin{(\\theta_2)}, \\omega_1, \\omega_2$.\n",
    "\n",
    "When using env.state, we have $\\theta_1, \\theta_2, \\omega_1, \\omega_2$. This allows us to have more precision in the angles which is needed in the MPC cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying different PF and pre-trained using rnd actions QRNN - Feb 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train on randomly sampled actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_magnitudes_costheta1 = []\n",
    "error_magnitudes_sintheta1 = []\n",
    "error_magnitudes_costheta2 = []\n",
    "error_magnitudes_sintheta2 = []\n",
    "error_magnitudes_omega1 = []\n",
    "error_magnitudes_omega2 = []\n",
    "\n",
    "env_costheta1 = []\n",
    "env_sintheta1 = []\n",
    "env_costheta2 = []\n",
    "env_sintheta2 = []\n",
    "env_omega1 = []\n",
    "env_omega2 = []\n",
    "\n",
    "pred_costheta1 = []\n",
    "pred_sintheta1 = []\n",
    "pred_costheta2 = []\n",
    "pred_sintheta2 = []\n",
    "pred_omega1 = []\n",
    "pred_omega2 = []\n",
    "\n",
    "# pred_x_var = []\n",
    "# pred_y_var = []\n",
    "# pred_z_var = []\n",
    "\n",
    "seed = 0\n",
    "\n",
    "env = gym.make('Acrobot-v1')#.unwrapped\n",
    "sim_env = gym.make('Acrobot-v1')#.unwrapped  # Additional simulation model for MPC\n",
    "# max_episode_steps = 500\n",
    "# env = gym.make('CartPole-v1').unwrapped\n",
    "# sim_env = gym.make('CartPole-v1').unwrapped  # Additional simulation model for MPC\n",
    "sim_env.reset(seed=seed)\n",
    "env.reset(seed=seed)\n",
    "\n",
    "# Hyperparameters\n",
    "state_dim = env.observation_space.shape[0]#-2#-1 # Since we only care about angle and omega which are given using env.state\n",
    "# action_dim = env.action_space.shape[0]  # For Pendulum, it's continuous\n",
    "action_dim=1\n",
    "\n",
    "# Initialize the Next-State Prediction Network\n",
    "model = NextStateMedianNetwork(state_dim, action_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_func = quantile_loss_median\n",
    "\n",
    "states_low = torch.tensor([-1, -1, -1, -1, -12.566371, -28.274334])\n",
    "states_high = torch.tensor([1, 1, 1, 1, 12.566371, 28.274334])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Experience replay buffer\n",
    "replay_buffer = []\n",
    "discrete = True\n",
    "num_test_steps = 20000\n",
    "\n",
    "state, _ = env.reset(seed=seed)\n",
    "episode_reward = 0\n",
    "actions_list = []\n",
    "done = False\n",
    "truncated = False\n",
    "\n",
    "actions_taken = np.zeros(num_test_steps)\n",
    "env.action_space.seed(seed)\n",
    "\n",
    "for step in range(num_test_steps):\n",
    "    # state = env.state\n",
    "    action = env.action_space.sample()\n",
    "    actions_taken[step] = action\n",
    "    \n",
    "    # Apply the first action from the optimized sequence\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    # next_state = env.state\n",
    "    episode_reward += reward\n",
    "    actions_list.append(action)\n",
    "    \n",
    "    if step >= 1:\n",
    "        # test_env = env.copy()\n",
    "        # test_action = test_env.action_space.sample()\n",
    "        # test_next_state, _, _, _, _ = test_env.step(test_action)\n",
    "        # test_next_state = test_next_state['observation'][:3]\n",
    "        \n",
    "        test_next_state = torch.tensor(next_state, dtype=torch.float32)\n",
    "        # test_next_state = torch.clip(test_next_state, states_low, states_high)\n",
    "        # print(\"test_next_state \", test_next_state, \"\\n\")\n",
    "        \n",
    "        if discrete:\n",
    "            test_action = torch.tensor(np.array([action]), dtype=torch.float32)#.unsqueeze(1)  # Example action\n",
    "        else:\n",
    "            test_action = torch.tensor(action, dtype=torch.float32)\n",
    "            \n",
    "        test_state = torch.tensor(state, dtype=torch.float32)#.reshape(1, -1)\n",
    "        test_state = torch.clip(test_state, states_low, states_high)\n",
    "        \n",
    "        # Predict next state quantiles\n",
    "        preds = model(test_state, test_action)  # Shape: (1, num_quantiles, state_dim)\n",
    "        # lower_quantile = predicted_quantiles[:, 0, :]  # Shape: (1, state_dim)\n",
    "        # mid_quantile = predicted_quantiles[:, int(num_quantiles/2), :].detach().numpy()  # Shape: (1, state_dim)\n",
    "        # upper_quantile = predicted_quantiles[:, -1, :]  # Shape: (1, state_dim)\n",
    "        # print(\"predicted_quantiles \", predicted_quantiles, \"\\n\")\n",
    "        # print(\"Lower Quantile:\", lower_quantile, \"\\n\")\n",
    "        # print(\"Mid Quantile:\", mid_quantile, \"\\n\")\n",
    "        # print(\"Upper Quantile:\", upper_quantile, \"\\n\")\n",
    "        \n",
    "        pred_costheta1 = np.append(pred_costheta1, preds[0].detach().numpy())\n",
    "        pred_sintheta1 = np.append(pred_sintheta1, preds[1].detach().numpy())\n",
    "        pred_costheta2 = np.append(pred_costheta2, preds[2].detach().numpy()) \n",
    "        pred_sintheta2 = np.append(pred_sintheta2, preds[3].detach().numpy())\n",
    "        # pred_theta2 = np.append(pred_sintheta2, preds[3].detach().numpy())  \n",
    "        pred_omega1 = np.append(pred_omega1, preds[4].detach().numpy())\n",
    "        pred_omega2 = np.append(pred_omega2, preds[5].detach().numpy())\n",
    "        \n",
    "        deltacostheta1 = test_next_state[0] - preds[0]\n",
    "        deltasintheta1 = test_next_state[1] - preds[1]\n",
    "        deltacostheta2 = test_next_state[2] - preds[2]\n",
    "        deltasintheta2 = test_next_state[3] - preds[3]\n",
    "        deltaomega1 = test_next_state[4] - preds[4]\n",
    "        deltaomega2 = test_next_state[5] - preds[5]\n",
    "\n",
    "        # delta = env_test_state - mean_next_state.flatten()#.detach().numpy()\n",
    "        # print(\"delta \", delta, \"\\n\") # 6\n",
    "        # print(\"delta_x \", deltax, \"\\n\") # 7\n",
    "        # error_magnitude = np.linalg.norm(delta)\n",
    "        # error_magnitudes.append(error_magnitude)\n",
    "        error_magnitudes_costheta1.append(np.abs(deltacostheta1.detach().numpy())) # .detach().numpy()\n",
    "        error_magnitudes_sintheta1.append(np.abs(deltasintheta1.detach().numpy())) # .detach().numpy()\n",
    "        error_magnitudes_costheta2.append(np.abs(deltacostheta2.detach().numpy())) # .detach().numpy()\n",
    "        error_magnitudes_sintheta2.append(np.abs(deltasintheta2.detach().numpy())) # .detach().numpy()\n",
    "        error_magnitudes_omega1.append(np.abs(deltaomega1.detach().numpy())) # .detach().numpy()\n",
    "        error_magnitudes_omega2.append(np.abs(deltaomega2.detach().numpy())) # .detach().numpy()\n",
    "        # env_next_states.append(env_test_state)\n",
    "        env_costheta1.append(test_next_state[0])\n",
    "        env_sintheta1.append(test_next_state[1])\n",
    "        env_costheta2.append(test_next_state[2])\n",
    "        env_sintheta2.append(test_next_state[3])\n",
    "        env_omega1.append(test_next_state[4])\n",
    "        env_omega2.append(test_next_state[5])\n",
    "    \n",
    "    # next_state = env.state.copy()\n",
    "    # Store experience in replay buffer\n",
    "    replay_buffer.append((state, np.array([action]), reward, next_state, done))\n",
    "    if len(replay_buffer) < batch_size:\n",
    "        pass\n",
    "    else:\n",
    "        batch = random.sample(replay_buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        states = torch.tensor(states, dtype=torch.float32)\n",
    "        actions = torch.tensor(actions, dtype=torch.float32)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "        next_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "        dones = torch.tensor(dones, dtype=torch.float32)\n",
    "        \n",
    "        states = torch.clip(states, states_low, states_high)\n",
    "        \n",
    "        # Predict next state quantiles\n",
    "        predicted_quantiles = model(states, actions)  # Shape: (batch_size, num_quantiles, state_dim)\n",
    "        \n",
    "        # Use next state as target (can be improved with target policy)\n",
    "        target_quantiles = next_states\n",
    "        \n",
    "        # Compute the target quantiles (e.g., replicate next state across the quantile dimension)\n",
    "        # target_quantiles = next_states.unsqueeze(-1).repeat(1, 1, num_quantiles)\n",
    "\n",
    "        # # Compute Quantile Huber Loss\n",
    "        # loss = quantile_huber_loss(predicted_quantiles, target_quantiles, quantiles)\n",
    "\n",
    "        loss = loss_func(predicted_quantiles, target_quantiles)\n",
    "        \n",
    "        # # Compute Quantile Huber Loss\n",
    "        # loss = quantile_huber_loss(predicted_quantiles, target_quantiles, quantiles)\n",
    "        \n",
    "        # Optimize the model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    state = next_state\n",
    "    \n",
    "    if done or truncated:\n",
    "        state, _ = env.reset(seed=seed)\n",
    "        episode_reward = 0\n",
    "        actions_list = []\n",
    "        done = False\n",
    "        truncated = False\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 1., ..., 2., 2., 0.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_taken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots for the acrobot env when using cos(theta1), sin(theta1), cos(theta2), sin(theta2), omega1, omega2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.seed(seed)\n",
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014062022 0.012367484 0.01634132 0.015746923 0.021136057 0.030880123\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(error_magnitudes_costheta1),\n",
    "      np.mean(error_magnitudes_sintheta1),\n",
    "      np.mean(error_magnitudes_costheta2),\n",
    "      np.mean(error_magnitudes_sintheta2),\n",
    "      np.mean(error_magnitudes_omega1),\n",
    "      np.mean(error_magnitudes_omega2),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011818848 0.01061995 0.015087273 0.02083896 0.019701451 0.03330051\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(error_magnitudes_costheta1[-100:]),\n",
    "      np.mean(error_magnitudes_sintheta1[-100:]),\n",
    "      np.mean(error_magnitudes_costheta2[-100:]),\n",
    "      np.mean(error_magnitudes_sintheta2[-100:]),\n",
    "      np.mean(error_magnitudes_omega1[-100:]),\n",
    "      np.mean(error_magnitudes_omega2[-100:]),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All steps\n",
      "$\\cos(\\theta_1)$ comparison: 0.014259083040138105\n",
      "$\\sin(\\theta_1)$ comparison: 0.012019605254067398\n",
      "$\\cos(\\theta_2)$ comparison: 0.01669554924419381\n",
      "$\\sin(\\theta_2)$ comparison: 0.015700123135560764\n",
      "$(\\omega_1)$ comparison: 0.021046459018309094\n",
      "$(\\omega_2)$ comparison: 0.030769384093134518\n"
     ]
    }
   ],
   "source": [
    "print(\"All steps\")\n",
    "print(f\"$\\\\cos(\\\\theta_1)$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_costheta1)-np.array(env_costheta1))))\n",
    "\n",
    "print(f\"$\\\\sin(\\\\theta_1)$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_sintheta1)-np.array(env_sintheta1))))\n",
    "\n",
    "print(f\"$\\\\cos(\\\\theta_2)$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_costheta2)-np.array(env_costheta2))))\n",
    "\n",
    "print(f\"$\\\\sin(\\\\theta_2)$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_sintheta2)-np.array(env_sintheta2))))\n",
    "\n",
    "print(f\"$(\\\\omega_1)$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_omega1)-np.array(env_omega1))))\n",
    "\n",
    "print(f\"$(\\\\omega_2)$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_omega2)-np.array(env_omega2))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amonsgt last 100 steps:\n",
      "$\\cos(\\theta_1)$ comparison: 0.011284043192863464\n",
      "$\\sin(\\theta_1)$ comparison: 0.011820157812908292\n",
      "$\\cos(\\theta_2)$ comparison: 0.012580422889441252\n",
      "$\\sin(\\theta_2)$ comparison: 1.3085402970403084\n",
      "$(\\omega_1)$ comparison: 0.025020531043410302\n",
      "$(\\omega_2)$ comparison: 0.029290043469518422\n"
     ]
    }
   ],
   "source": [
    "print(\"Amonsgt last 100 steps:\")\n",
    "print(f\"$\\\\cos(\\\\theta_1)$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_costheta1[-100:])-np.array(env_costheta1[-100:]))))\n",
    "\n",
    "print(f\"$\\\\sin(\\\\theta_1)$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_sintheta1[-100:])-np.array(env_sintheta1[-100:]))))\n",
    "\n",
    "print(f\"$\\\\cos(\\\\theta_2)$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_costheta2[-100:])-np.array(env_costheta2[-100:]))))\n",
    "\n",
    "print(f\"$\\\\sin(\\\\theta_2)$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_sintheta2[-100:])-np.array(env_sintheta2[-100:]))))\n",
    "\n",
    "print(f\"$(\\\\omega_1)$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_omega1[-100:])-np.array(env_omega1[-100:]))))\n",
    "\n",
    "print(f\"$(\\\\omega_2)$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_omega2[-100:])-np.array(env_omega2[-100:]))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amonsgt last 2000 steps/Without first 18000 steps:\n",
      "$\\cos(\\theta_1)$ comparison: 0.009180909454689294\n",
      "$\\sin(\\theta_1)$ comparison: 0.009465246656789035\n",
      "$\\cos(\\theta_2)$ comparison: 0.011249271747657332\n",
      "$\\sin(\\theta_2)$ comparison: 0.011653422186535626\n",
      "$(\\omega_1)$ comparison: 0.014863518170715162\n",
      "$(\\omega_2)$ comparison: 0.023180260252579767\n"
     ]
    }
   ],
   "source": [
    "print(\"Amonsgt last 2000 steps/Without first 18000 steps:\")\n",
    "print(f\"$\\\\cos(\\\\theta_1)$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_costheta1[18000:])-np.array(env_costheta1[18000:]))))\n",
    "\n",
    "print(f\"$\\\\sin(\\\\theta_1)$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_sintheta1[18000:])-np.array(env_sintheta1[18000:]))))\n",
    "\n",
    "print(f\"$\\\\cos(\\\\theta_2)$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_costheta2[18000:])-np.array(env_costheta2[18000:]))))\n",
    "\n",
    "print(f\"$\\\\sin(\\\\theta_2)$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_sintheta2[18000:])-np.array(env_sintheta2[18000:]))))\n",
    "\n",
    "print(f\"$(\\\\omega_1)$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_omega1[18000:])-np.array(env_omega1[18000:]))))\n",
    "\n",
    "print(f\"$(\\\\omega_2)$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_omega2[18000:])-np.array(env_omega2[18000:]))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(1)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.plot(error_magnitudes_costheta1)\n",
    "# plt.ylabel(f'Error magnitudes $\\\\cos(\\\\theta_1)$')\n",
    "# # plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_1_{timestamp}.png')\n",
    "# plt.yscale('log')\n",
    "\n",
    "# plt.figure(2)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.plot(error_magnitudes_sintheta1)\n",
    "# plt.ylabel(f'Error magnitudes $\\\\sin(\\\\theta_1)$')\n",
    "# # plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_1_{timestamp}.png')\n",
    "# plt.yscale('log')\n",
    "\n",
    "# plt.figure(3)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.plot(error_magnitudes_costheta2)\n",
    "# plt.ylabel(f'Error magnitudes $\\\\cos(\\\\theta_1)$')\n",
    "# # plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_2_{timestamp}.png')\n",
    "# plt.yscale('log')\n",
    "\n",
    "# plt.figure(4)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.plot(error_magnitudes_sintheta2)\n",
    "# plt.ylabel(f'Error magnitudes $\\\\sin(\\\\theta_2)$')\n",
    "# # plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_2_{timestamp}.png')\n",
    "# plt.yscale('log')\n",
    "\n",
    "# plt.figure(5)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.plot(error_magnitudes_omega1)\n",
    "# plt.ylabel(f'Error magnitudes $\\omega_1$')\n",
    "# # plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_1_{timestamp}.png')\n",
    "# plt.yscale('log')\n",
    "\n",
    "# plt.figure(6)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.plot(error_magnitudes_omega2)\n",
    "# plt.ylabel(f'Error magnitudes $\\omega_2$')\n",
    "# # plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_2_{timestamp}.png')\n",
    "# plt.yscale('log')\n",
    "\n",
    "# plt.figure(7)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.ylabel(f'$\\\\cos(\\\\theta_1)$ comparison between env and QRNN')\n",
    "# plt.plot(env_costheta1, label='env_next_states')\n",
    "# plt.plot(pred_costheta1, label='pred_next_states')\n",
    "# # plt.fill_between(np.arange(len(pred_theta1)), pred_theta1 - pred_theta1_bottom_1std, pred_theta1 + pred_theta1_top_2std, alpha=0.5, label='1 std', color='green')\n",
    "# # plt.fill_between(np.arange(len(pred_theta1)), pred_theta1 - pred_theta1_bottom_2std, pred_theta1 + pred_theta1_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\angles_comparison_GP_env_{timestamp}.png')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure(8)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.ylabel(f'$\\\\sin(\\\\theta_1)$ comparison between env and QRNN')\n",
    "# plt.plot(env_sintheta1, label='env_next_states')\n",
    "# plt.plot(pred_sintheta1, label='pred_next_states')\n",
    "# # plt.fill_between(np.arange(len(pred_theta1)), pred_theta1 - pred_theta1_bottom_1std, pred_theta1 + pred_theta1_top_2std, alpha=0.5, label='1 std', color='green')\n",
    "# # plt.fill_between(np.arange(len(pred_theta1)), pred_theta1 - pred_theta1_bottom_2std, pred_theta1 + pred_theta1_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\angles_comparison_GP_env_{timestamp}.png')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure(9)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.ylabel(f'$\\\\cos(\\\\theta_2)$ comparison between env and QRNN')\n",
    "# plt.plot(env_costheta2, label='env_next_states')\n",
    "# plt.plot(pred_costheta2, label='pred_next_states')\n",
    "# # plt.fill_between(np.arange(len(pred_theta2)), pred_theta2 - pred_theta2_bottom_1std, pred_theta2 + pred_theta2_top_2std, alpha=0.5, label='1 std', color='green')\n",
    "# # plt.fill_between(np.arange(len(pred_theta2)), pred_theta2 - pred_theta2_bottom_2std, pred_theta2 + pred_theta2_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\omegas_comparison_GP_env_{timestamp}.png')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure(10)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.ylabel(f'$\\\\sin(\\\\theta_2)$ comparison between env and QRNN')\n",
    "# plt.plot(env_sintheta2, label='env_next_states')\n",
    "# plt.plot(pred_sintheta2, label='pred_next_states')\n",
    "# # plt.fill_between(np.arange(len(pred_theta2)), pred_theta2 - pred_theta2_bottom_1std, pred_theta2 + pred_theta2_top_2std, alpha=0.5, label='1 std', color='green')\n",
    "# # plt.fill_between(np.arange(len(pred_theta2)), pred_theta2 - pred_theta2_bottom_2std, pred_theta2 + pred_theta2_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\omegas_comparison_GP_env_{timestamp}.png')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure(11)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.ylabel(f'$\\omega_1$ comparison between env and QRNN')\n",
    "# plt.plot(env_omega1, label='env_next_states')\n",
    "# plt.plot(pred_omega1, label='pred_next_states')\n",
    "# # plt.fill_between(np.arange(len(pred_omega1)), pred_omega1 - pred_omega1_bottom_1std, pred_omega1 + pred_omega1_top_1std, alpha=0.5, label='1 std', color='green')\n",
    "# # plt.fill_between(np.arange(len(pred_omega1)), pred_omega1 - pred_omega1_bottom_2std, pred_omega1 + pred_omega1_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\angles_comparison_GP_env_{timestamp}.png')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure(12)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.ylabel(f'$\\omega_2$ comparison between env and QRNN')\n",
    "# plt.plot(env_omega2, label='env_next_states')\n",
    "# plt.plot(pred_omega2, label='pred_next_states')\n",
    "# # plt.fill_between(np.arange(len(pred_omega2)), pred_omega2 - pred_omega2_bottom_1std, pred_omega2 + pred_omega2_top_1std, alpha=0.5, label='1 std', color='green')\n",
    "# # plt.fill_between(np.arange(len(pred_omega2)), pred_omega2 - pred_omega2_bottom_2std, pred_omega2 + pred_omega2_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\omegas_comparison_GP_env_{timestamp}.png')\n",
    "# plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cart pole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_magnitudes_x = []\n",
    "error_magnitudes_v = []\n",
    "error_magnitudes_theta = []\n",
    "error_magnitudes_omega = []\n",
    "\n",
    "env_x = []\n",
    "env_v = []\n",
    "env_theta = []\n",
    "env_omega = []\n",
    "\n",
    "pred_x = []\n",
    "pred_v = []\n",
    "pred_theta = []\n",
    "pred_omega = []\n",
    "\n",
    "# pred_x_var = []\n",
    "# pred_y_var = []\n",
    "# pred_z_var = []\n",
    "\n",
    "seed = 0\n",
    "\n",
    "env = gym.make('CartPole-v1')#.unwrapped\n",
    "sim_env = gym.make('CartPole-v1')#.unwrapped  # Additional simulation model for MPC\n",
    "# max_episode_steps = 500\n",
    "# env = gym.make('CartPole-v1').unwrapped\n",
    "# sim_env = gym.make('CartPole-v1').unwrapped  # Additional simulation model for MPC\n",
    "sim_env.reset(seed=seed)\n",
    "env.reset(seed=seed)\n",
    "\n",
    "# Hyperparameters\n",
    "state_dim = env.observation_space.shape[0]#-2#-1 # Since we only care about angle and omega which are given using env.state\n",
    "# action_dim = env.action_space.shape[0]  # For Pendulum, it's continuous\n",
    "action_dim=1\n",
    "\n",
    "# Initialize the Next-State Prediction Network\n",
    "model = NextStateMedianNetwork(state_dim, action_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_func = quantile_loss_median\n",
    "\n",
    "states_low = torch.tensor([-4.8, -torch.inf, -0.41887903, -torch.inf])\n",
    "states_high = torch.tensor([4.8, torch.inf, 0.41887903, torch.inf])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Experience replay buffer\n",
    "replay_buffer = []\n",
    "discrete = True\n",
    "num_test_steps = 20000\n",
    "\n",
    "state, _ = env.reset(seed=seed)\n",
    "episode_reward = 0\n",
    "actions_list = []\n",
    "done = False\n",
    "truncated = False\n",
    "\n",
    "actions_taken = np.zeros(num_test_steps)\n",
    "env.action_space.seed(seed)\n",
    "\n",
    "for step in range(num_test_steps):\n",
    "    # state = env.state\n",
    "    action = env.action_space.sample()\n",
    "    actions_taken[step] = action\n",
    "    \n",
    "    # Apply the first action from the optimized sequence\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    # next_state = env.state\n",
    "    episode_reward += reward\n",
    "    actions_list.append(action)\n",
    "    \n",
    "    if step >= 1:\n",
    "        # test_env = env.copy()\n",
    "        # test_action = test_env.action_space.sample()\n",
    "        # test_next_state, _, _, _, _ = test_env.step(test_action)\n",
    "        # test_next_state = test_next_state['observation'][:3]\n",
    "        \n",
    "        test_next_state = torch.tensor(next_state, dtype=torch.float32)\n",
    "        # test_next_state = torch.clip(test_next_state, states_low, states_high)\n",
    "        # print(\"test_next_state \", test_next_state, \"\\n\")\n",
    "        \n",
    "        if discrete:\n",
    "            test_action = torch.tensor(np.array([action]), dtype=torch.float32)#.unsqueeze(1)  # Example action\n",
    "        else:\n",
    "            test_action = torch.tensor(np.array([action]), dtype=torch.float32).unsqueeze(1)\n",
    "            \n",
    "        test_state = torch.tensor(state, dtype=torch.float32)#.reshape(1, -1)\n",
    "        test_state = torch.clip(test_state, states_low, states_high)\n",
    "        \n",
    "        # Predict next state quantiles\n",
    "        preds = model(test_state, test_action)  # Shape: (1, num_quantiles, state_dim)\n",
    "        # lower_quantile = predicted_quantiles[:, 0, :]  # Shape: (1, state_dim)\n",
    "        # mid_quantile = predicted_quantiles[:, int(num_quantiles/2), :].detach().numpy()  # Shape: (1, state_dim)\n",
    "        # upper_quantile = predicted_quantiles[:, -1, :]  # Shape: (1, state_dim)\n",
    "        # print(\"predicted_quantiles \", predicted_quantiles, \"\\n\")\n",
    "        # print(\"Lower Quantile:\", lower_quantile, \"\\n\")\n",
    "        # print(\"Mid Quantile:\", mid_quantile, \"\\n\")\n",
    "        # print(\"Upper Quantile:\", upper_quantile, \"\\n\")\n",
    "        \n",
    "        pred_x = np.append(pred_x, preds[0].detach().numpy())\n",
    "        pred_v = np.append(pred_v, preds[1].detach().numpy())\n",
    "        pred_theta = np.append(pred_theta, preds[2].detach().numpy()) \n",
    "        pred_omega = np.append(pred_omega, preds[3].detach().numpy())\n",
    "        # # pred_theta2 = np.append(pred_sintheta2, preds[3].detach().numpy())  \n",
    "        # pred_omega1 = np.append(pred_omega1, preds[4].detach().numpy())\n",
    "        # pred_omega2 = np.append(pred_omega2, preds[5].detach().numpy())\n",
    "        \n",
    "        deltax = test_next_state[0] - preds[0]\n",
    "        deltav = test_next_state[1] - preds[1]\n",
    "        deltatheta = test_next_state[2] - preds[2]\n",
    "        deltaomega = test_next_state[3] - preds[3]\n",
    "        # deltaomega1 = test_next_state[4] - preds[4]\n",
    "        # deltaomega2 = test_next_state[5] - preds[5]\n",
    "\n",
    "        # delta = env_test_state - mean_next_state.flatten()#.detach().numpy()\n",
    "        # print(\"delta \", delta, \"\\n\") # 6\n",
    "        # print(\"delta_x \", deltax, \"\\n\") # 7\n",
    "        # error_magnitude = np.linalg.norm(delta)\n",
    "        # error_magnitudes.append(error_magnitude)\n",
    "        error_magnitudes_x.append(np.abs(deltax.detach().numpy())) # .detach().numpy()\n",
    "        error_magnitudes_v.append(np.abs(deltav.detach().numpy())) # .detach().numpy()\n",
    "        error_magnitudes_theta.append(np.abs(deltatheta.detach().numpy())) # .detach().numpy()\n",
    "        error_magnitudes_omega.append(np.abs(deltaomega.detach().numpy())) # .detach().numpy()\n",
    "        # error_magnitudes_omega1.append(np.abs(deltaomega1.detach().numpy())) # .detach().numpy()\n",
    "        # error_magnitudes_omega2.append(np.abs(deltaomega2.detach().numpy())) # .detach().numpy()\n",
    "        # env_next_states.append(env_test_state)\n",
    "        env_x.append(test_next_state[0])\n",
    "        env_v.append(test_next_state[1])\n",
    "        env_theta.append(test_next_state[2])\n",
    "        env_omega.append(test_next_state[3])\n",
    "        # env_omega1.append(test_next_state[4])\n",
    "        # env_omega2.append(test_next_state[5])\n",
    "    \n",
    "    # next_state = env.state.copy()\n",
    "    # Store experience in replay buffer\n",
    "    if discrete:\n",
    "        replay_buffer.append((state, np.array([action]), reward, next_state, done))\n",
    "    else:\n",
    "        replay_buffer.append((state, np.array(action), reward, next_state, done))\n",
    "        \n",
    "    if len(replay_buffer) < batch_size:\n",
    "        pass\n",
    "    else:\n",
    "        batch = random.sample(replay_buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        states = torch.tensor(states, dtype=torch.float32)\n",
    "        actions = torch.tensor(actions, dtype=torch.float32)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "        next_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "        dones = torch.tensor(dones, dtype=torch.float32)\n",
    "        \n",
    "        states = torch.clip(states, states_low, states_high)\n",
    "        \n",
    "        # Predict next state quantiles\n",
    "        predicted_quantiles = model(states, actions)  # Shape: (batch_size, num_quantiles, state_dim)\n",
    "        \n",
    "        # Use next state as target (can be improved with target policy)\n",
    "        target_quantiles = next_states\n",
    "        \n",
    "        # Compute the target quantiles (e.g., replicate next state across the quantile dimension)\n",
    "        # target_quantiles = next_states.unsqueeze(-1).repeat(1, 1, num_quantiles)\n",
    "\n",
    "        # # Compute Quantile Huber Loss\n",
    "        # loss = quantile_huber_loss(predicted_quantiles, target_quantiles, quantiles)\n",
    "\n",
    "        loss = loss_func(predicted_quantiles, target_quantiles)\n",
    "        \n",
    "        # # Compute Quantile Huber Loss\n",
    "        # loss = quantile_huber_loss(predicted_quantiles, target_quantiles, quantiles)\n",
    "        \n",
    "        # Optimize the model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    state = next_state\n",
    "    \n",
    "    if done or truncated:\n",
    "        state, _ = env.reset(seed=seed)\n",
    "        episode_reward = 0\n",
    "        actions_list = []\n",
    "        done = False\n",
    "        truncated = False\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 100 steps\n",
      "x comparison: 0.0019126614555716515\n",
      "v comparison: 0.002998171038925648\n",
      "$\\theta$ comparison: 0.0019786137917253655\n",
      "$\\omega$ comparison: 0.0036475223302841185\n"
     ]
    }
   ],
   "source": [
    "print(\"Last 100 steps\")\n",
    "print(f\"x comparison:\",\n",
    "np.mean(np.abs(np.array(pred_x[-100:])-np.array(env_x[-100:]))))\n",
    "\n",
    "print(f\"v comparison:\",\n",
    "np.mean(np.abs(np.array(pred_v[-100:])-np.array(env_v[-100:]))))\n",
    "\n",
    "print(f\"$\\\\theta$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_theta[-100:])-np.array(env_theta[-100:]))))\n",
    "\n",
    "print(f\"$\\\\omega$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_omega[-100:])-np.array(env_omega[-100:]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All steps\n",
      "x comparison: 0.0038350483717210313\n",
      "v comparison: 0.0065421207920617775\n",
      "$\\theta$ comparison: 0.003981228624058303\n",
      "$\\omega$ comparison: 0.008072514589778182\n"
     ]
    }
   ],
   "source": [
    "print(\"All steps\")\n",
    "print(f\"x comparison:\",\n",
    "np.mean(np.abs(np.array(pred_x)-np.array(env_x))))\n",
    "\n",
    "print(f\"v comparison:\",\n",
    "np.mean(np.abs(np.array(pred_v)-np.array(env_v))))\n",
    "\n",
    "print(f\"$\\\\theta$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_theta)-np.array(env_theta))))\n",
    "\n",
    "print(f\"$\\\\omega$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_omega)-np.array(env_omega))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots for cart pole env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot training results\n",
    "# import matplotlib.pyplot as plt\n",
    "# # Plot the rewards\n",
    "# plt.figure(1)\n",
    "# # plt.legend()\n",
    "# # plt.grid()\n",
    "# plt.plot(episode_reward_list)\n",
    "# plt.xlabel('Nb of episodes')\n",
    "# plt.ylabel('episode reward')\n",
    "# # plt.title('MPC_Pendulum with Optimized Action Sequences')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\Graphs\\\\episode_rewards_withCPUforQRNN_{timestamp}.png')\n",
    "# # # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\episode_rewards_withGPUforGP_{timestamp}.png')\n",
    "# plt.yscale('log')\n",
    "\n",
    "# plt.figure(2)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.plot(error_magnitudes_x)\n",
    "# plt.ylabel('error_magnitudes_x')\n",
    "# # plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_1_{timestamp}.png')\n",
    "# plt.yscale('log')\n",
    "\n",
    "# plt.figure(3)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.plot(error_magnitudes_v)\n",
    "# plt.ylabel('error_magnitudes_v')\n",
    "# # plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_2_{timestamp}.png')\n",
    "# plt.yscale('log')\n",
    "\n",
    "# plt.figure(4)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.plot(error_magnitudes_theta)\n",
    "# plt.ylabel('error_magnitudes_theta')\n",
    "# # plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_1_{timestamp}.png')\n",
    "# plt.yscale('log')\n",
    "\n",
    "# plt.figure(5)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.plot(error_magnitudes_omega)\n",
    "# plt.ylabel('error_magnitudes_omega')\n",
    "# # plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_2_{timestamp}.png')\n",
    "# plt.yscale('log')\n",
    "\n",
    "# plt.figure(6)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.ylabel('x comparison between env and QRNN')\n",
    "# plt.plot(env_x, label='env_next_states')\n",
    "# plt.plot(pred_x, label='pred_next_states')\n",
    "# plt.fill_between(np.arange(len(pred_x)), pred_x - pred_x_bottom_1std, pred_x + pred_x_top_2std, alpha=0.5, label='1 std', color='green')\n",
    "# plt.fill_between(np.arange(len(pred_x)), pred_x - pred_x_bottom_2std, pred_x + pred_x_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\angles_comparison_GP_env_{timestamp}.png')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure(7)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.ylabel('v comparison between env and QRNN')\n",
    "# plt.plot(env_v, label='env_next_states')\n",
    "# plt.plot(pred_v, label='pred_next_states')\n",
    "# plt.fill_between(np.arange(len(pred_v)), pred_v - pred_v_bottom_1std, pred_v + pred_v_top_1std, alpha=0.5, label='1 std', color='green')\n",
    "# plt.fill_between(np.arange(len(pred_v)), pred_v - pred_v_bottom_2std, pred_v + pred_v_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\omegas_comparison_GP_env_{timestamp}.png')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure(8)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.ylabel('theta comparison between env and QRNN')\n",
    "# plt.plot(env_theta, label='env_next_states')\n",
    "# plt.plot(pred_theta, label='pred_next_states')\n",
    "# plt.fill_between(np.arange(len(pred_theta)), pred_theta - pred_theta_bottom_1std, pred_theta + pred_theta_top_2std, alpha=0.5, label='1 std', color='green')\n",
    "# plt.fill_between(np.arange(len(pred_theta)), pred_theta - pred_theta_bottom_2std, pred_theta + pred_theta_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\angles_comparison_GP_env_{timestamp}.png')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure(9)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.ylabel('omega comparison between env and QRNN')\n",
    "# plt.plot(env_omega, label='env_next_states')\n",
    "# plt.plot(pred_omega, label='pred_next_states')\n",
    "# plt.fill_between(np.arange(len(pred_omega)), pred_omega - pred_omega_bottom_1std, pred_omega + pred_omega_top_1std, alpha=0.5, label='1 std', color='green')\n",
    "# plt.fill_between(np.arange(len(pred_omega)), pred_omega - pred_omega_bottom_2std, pred_omega + pred_omega_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\omegas_comparison_GP_env_{timestamp}.png')\n",
    "# plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pendulum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_magnitudes_x = []\n",
    "error_magnitudes_y = []\n",
    "error_magnitudes_omega = []\n",
    "\n",
    "env_x = []\n",
    "env_y = []\n",
    "env_omega = []\n",
    "\n",
    "pred_x = []\n",
    "pred_y = []\n",
    "pred_omega = []\n",
    "\n",
    "seed = 0\n",
    "discrete = False\n",
    "env = gym.make('Pendulum-v1')#.unwrapped\n",
    "# sim_env = gym.make('Pendulum-v1')#.unwrapped  # Additional simulation model for MPC\n",
    "# max_episode_steps = 500\n",
    "# env = gym.make('CartPole-v1').unwrapped\n",
    "# sim_env = gym.make('CartPole-v1').unwrapped  # Additional simulation model for MPC\n",
    "sim_env.reset(seed=seed)\n",
    "env.reset(seed=seed)\n",
    "\n",
    "# Hyperparameters\n",
    "state_dim = env.observation_space.shape[0]#-2#-1 # Since we only care about angle and omega which are given using env.state\n",
    "# action_dim = env.action_space.shape[0]  # For Pendulum, it's continuous\n",
    "action_dim=1\n",
    "\n",
    "# Initialize the Next-State Prediction Network\n",
    "model = NextStateMedianNetwork(state_dim, action_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_func = quantile_loss_median\n",
    "\n",
    "states_low = torch.tensor([-1, -1, -8])\n",
    "states_high = torch.tensor([1, 1, 8])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Experience replay buffer\n",
    "replay_buffer = []\n",
    "\n",
    "num_test_steps = 20000\n",
    "\n",
    "state, _ = env.reset(seed=seed)\n",
    "episode_reward = 0\n",
    "actions_list = []\n",
    "done = False\n",
    "truncated = False\n",
    "\n",
    "actions_taken = np.zeros(num_test_steps)\n",
    "env.action_space.seed(seed)\n",
    "\n",
    "for step in range(num_test_steps):\n",
    "    # state = env.state\n",
    "    action = env.action_space.sample()\n",
    "    actions_taken[step] = action\n",
    "    \n",
    "    # Apply the first action from the optimized sequence\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    # next_state = env.state\n",
    "    episode_reward += reward\n",
    "    actions_list.append(action)\n",
    "    \n",
    "    if step >= 1:\n",
    "        # test_env = env.copy()\n",
    "        # test_action = test_env.action_space.sample()\n",
    "        # test_next_state, _, _, _, _ = test_env.step(test_action)\n",
    "        # test_next_state = test_next_state['observation'][:3]\n",
    "        \n",
    "        test_next_state = torch.tensor(next_state, dtype=torch.float32)\n",
    "        # test_next_state = torch.clip(test_next_state, states_low, states_high)\n",
    "        # print(\"test_next_state \", test_next_state, \"\\n\")\n",
    "        \n",
    "        if discrete:\n",
    "            test_action = torch.tensor(np.array([action]), dtype=torch.float32)#.unsqueeze(1)  # Example action\n",
    "        else:\n",
    "            test_action = torch.tensor(action, dtype=torch.float32)#.unsqueeze(1)\n",
    "        test_state = torch.tensor(state, dtype=torch.float32)#.reshape(1, -1)\n",
    "        test_state = torch.clip(test_state, states_low, states_high)\n",
    "        \n",
    "        # Predict next state quantiles\n",
    "        preds = model(test_state, test_action)  # Shape: (1, num_quantiles, state_dim)\n",
    "        # lower_quantile = predicted_quantiles[:, 0, :]  # Shape: (1, state_dim)\n",
    "        # mid_quantile = predicted_quantiles[:, int(num_quantiles/2), :].detach().numpy()  # Shape: (1, state_dim)\n",
    "        # upper_quantile = predicted_quantiles[:, -1, :]  # Shape: (1, state_dim)\n",
    "        # print(\"predicted_quantiles \", predicted_quantiles, \"\\n\")\n",
    "        # print(\"Lower Quantile:\", lower_quantile, \"\\n\")\n",
    "        # print(\"Mid Quantile:\", mid_quantile, \"\\n\")\n",
    "        # print(\"Upper Quantile:\", upper_quantile, \"\\n\")\n",
    "        \n",
    "        pred_x = np.append(pred_x, preds[0].detach().numpy())\n",
    "        pred_y = np.append(pred_y, preds[1].detach().numpy())\n",
    "        pred_omega = np.append(pred_omega, preds[2].detach().numpy())\n",
    "        # # pred_theta2 = np.append(pred_sintheta2, preds[3].detach().numpy())  \n",
    "        # pred_omega1 = np.append(pred_omega1, preds[4].detach().numpy())\n",
    "        # pred_omega2 = np.append(pred_omega2, preds[5].detach().numpy())\n",
    "        \n",
    "        deltax = test_next_state[0] - preds[0]\n",
    "        deltay = test_next_state[1] - preds[1]\n",
    "        deltaomega = test_next_state[2] - preds[2]\n",
    "        # deltaomega = test_next_state[3] - preds[3]\n",
    "        # deltaomega1 = test_next_state[4] - preds[4]\n",
    "        # deltaomega2 = test_next_state[5] - preds[5]\n",
    "\n",
    "        # delta = env_test_state - mean_next_state.flatten()#.detach().numpy()\n",
    "        # print(\"delta \", delta, \"\\n\") # 6\n",
    "        # print(\"delta_x \", deltax, \"\\n\") # 7\n",
    "        # error_magnitude = np.linalg.norm(delta)\n",
    "        # error_magnitudes.append(error_magnitude)\n",
    "        error_magnitudes_x.append(np.abs(deltax.detach().numpy())) # .detach().numpy()\n",
    "        error_magnitudes_y.append(np.abs(deltay.detach().numpy())) # .detach().numpy()\n",
    "        # error_magnitudes_theta.append(np.abs(deltatheta.detach().numpy())) # .detach().numpy()\n",
    "        error_magnitudes_omega.append(np.abs(deltaomega.detach().numpy())) # .detach().numpy()\n",
    "        # error_magnitudes_omega1.append(np.abs(deltaomega1.detach().numpy())) # .detach().numpy()\n",
    "        # error_magnitudes_omega2.append(np.abs(deltaomega2.detach().numpy())) # .detach().numpy()\n",
    "        # env_next_states.append(env_test_state)\n",
    "        env_x.append(test_next_state[0])\n",
    "        env_y.append(test_next_state[1])\n",
    "        env_omega.append(test_next_state[2])\n",
    "        # env_omega.append(test_next_state[3])\n",
    "        # env_omega1.append(test_next_state[4])\n",
    "        # env_omega2.append(test_next_state[5])\n",
    "    \n",
    "    # next_state = env.state.copy()\n",
    "    # Store experience in replay buffer\n",
    "    if discrete:\n",
    "        replay_buffer.append((state, np.array([action]), reward, next_state, done))\n",
    "    else:\n",
    "        replay_buffer.append((state, np.array(action), reward, next_state, done))\n",
    "    if len(replay_buffer) < batch_size:\n",
    "        pass\n",
    "    else:\n",
    "        batch = random.sample(replay_buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        states = torch.tensor(states, dtype=torch.float32)\n",
    "        actions = torch.tensor(actions, dtype=torch.float32)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "        next_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "        dones = torch.tensor(dones, dtype=torch.float32)\n",
    "        \n",
    "        states = torch.clip(states, states_low, states_high)\n",
    "        \n",
    "        # Predict next state quantiles\n",
    "        predicted_quantiles = model(states, actions)  # Shape: (batch_size, num_quantiles, state_dim)\n",
    "        \n",
    "        # Use next state as target (can be improved with target policy)\n",
    "        target_quantiles = next_states\n",
    "        \n",
    "        # Compute the target quantiles (e.g., replicate next state across the quantile dimension)\n",
    "        # target_quantiles = next_states.unsqueeze(-1).repeat(1, 1, num_quantiles)\n",
    "\n",
    "        # # Compute Quantile Huber Loss\n",
    "        # loss = quantile_huber_loss(predicted_quantiles, target_quantiles, quantiles)\n",
    "\n",
    "        loss = loss_func(predicted_quantiles, target_quantiles)\n",
    "        \n",
    "        # # Compute Quantile Huber Loss\n",
    "        # loss = quantile_huber_loss(predicted_quantiles, target_quantiles, quantiles)\n",
    "        \n",
    "        # Optimize the model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    state = next_state\n",
    "    \n",
    "    if done or truncated:\n",
    "        state, _ = env.reset(seed=seed)\n",
    "        episode_reward = 0\n",
    "        actions_list = []\n",
    "        done = False\n",
    "        truncated = False\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Last 100 steps\")\n",
    "print(f\"x comparison:\",\n",
    "np.mean(np.abs(np.array(pred_x[-100:])-np.array(env_x[-100:]))))\n",
    "\n",
    "print(f\"y comparison:\",\n",
    "np.mean(np.abs(np.array(pred_y[-100:])-np.array(env_y[-100:]))))\n",
    "\n",
    "print(f\"$\\omega$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_omega[-100:])-np.array(env_omega[-100:]))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All steps\")\n",
    "print(f\"x comparison:\",\n",
    "np.mean(np.abs(np.array(pred_x)-np.array(env_x))))\n",
    "\n",
    "print(f\"y comparison:\",\n",
    "np.mean(np.abs(np.array(pred_y)-np.array(env_y))))\n",
    "\n",
    "print(f\"$\\omega$ comparison:\",\n",
    "np.mean(np.abs(np.array(pred_omega)-np.array(env_omega))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots for the pendulum env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # # Plot the rewards\n",
    "# # plt.figure(1)\n",
    "# # # plt.legend()\n",
    "# # # plt.grid()\n",
    "# # plt.plot(episode_reward_list)\n",
    "# # plt.xlabel('Nb of episodes')\n",
    "# # plt.ylabel('episode reward')\n",
    "# # # plt.title('MPC_Pendulum with Optimized Action Sequences')\n",
    "# # # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\Graphs\\\\episode_rewards_withCPUforQRNN_{timestamp}.png')\n",
    "# # # # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\episode_rewards_withGPUforGP_{timestamp}.png')\n",
    "\n",
    "# plt.figure(1)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.plot(error_magnitudes_x)\n",
    "# plt.ylabel('error_magnitudes_x')\n",
    "# plt.yscale('log')\n",
    "# # plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_1_{timestamp}.png')\n",
    "\n",
    "# plt.figure(2)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.plot(error_magnitudes_y)\n",
    "# plt.ylabel('error_magnitudes_y')\n",
    "# plt.yscale('log')\n",
    "# # plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_1_{timestamp}.png')\n",
    "\n",
    "# plt.figure(3)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.plot(error_magnitudes_omega)\n",
    "# plt.ylabel('error_magnitudes_omega')\n",
    "# plt.yscale('log')\n",
    "# # plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_2_{timestamp}.png')\n",
    "\n",
    "\n",
    "# plt.figure(4)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.ylabel('x comparison between env and QRNN')\n",
    "# plt.plot(env_x, label='env_next_states')\n",
    "# plt.plot(pred_x, label='pred_next_states')\n",
    "# # plt.fill_between(np.arange(len(pred_theta)), pred_theta - pred_theta_bottom_1std, pred_theta + pred_theta_top_2std, alpha=0.5, label='1 std', color='green')\n",
    "# # plt.fill_between(np.arange(len(pred_theta)), pred_theta - pred_theta_bottom_2std, pred_theta + pred_theta_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\angles_comparison_GP_env_{timestamp}.png')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure(5)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.ylabel('y comparison between env and QRNN')\n",
    "# plt.plot(env_y, label='env_next_states')\n",
    "# plt.plot(pred_y, label='pred_next_states')\n",
    "# # plt.fill_between(np.arange(len(pred_theta)), pred_theta - pred_theta_bottom_1std, pred_theta + pred_theta_top_2std, alpha=0.5, label='1 std', color='green')\n",
    "# # plt.fill_between(np.arange(len(pred_theta)), pred_theta - pred_theta_bottom_2std, pred_theta + pred_theta_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\angles_comparison_GP_env_{timestamp}.png')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure(6)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.ylabel('omega comparison between env and QRNN')\n",
    "# plt.plot(env_omega, label='env_next_states')\n",
    "# plt.plot(pred_omega, label='pred_next_states')\n",
    "# # plt.fill_between(np.arange(len(pred_omega)), pred_omega - pred_omega_bottom_1std, pred_omega + pred_omega_top_1std, alpha=0.5, label='1 std', color='green')\n",
    "# # plt.fill_between(np.arange(len(pred_omega)), pred_omega - pred_omega_bottom_2std, pred_omega + pred_omega_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\omegas_comparison_GP_env_{timestamp}.png')\n",
    "# plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mountain car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicle\\AppData\\Local\\Temp\\ipykernel_82932\\2607805588.py:53: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  actions_taken[step] = action\n"
     ]
    }
   ],
   "source": [
    "error_magnitudes_x = []\n",
    "error_magnitudes_v = []\n",
    "\n",
    "env_x = []\n",
    "env_v = []\n",
    "\n",
    "pred_x = []\n",
    "pred_v = []\n",
    "\n",
    "seed = 0\n",
    "discrete = False\n",
    "env = gym.make('MountainCarContinuous-v0')#.unwrapped\n",
    "# sim_env = gym.make('Pendulum-v1')#.unwrapped  # Additional simulation model for MPC\n",
    "# max_episode_steps = 500\n",
    "# env = gym.make('CartPole-v1').unwrapped\n",
    "# sim_env = gym.make('CartPole-v1').unwrapped  # Additional simulation model for MPC\n",
    "sim_env.reset(seed=seed)\n",
    "env.reset(seed=seed)\n",
    "\n",
    "# Hyperparameters\n",
    "state_dim = env.observation_space.shape[0]#-2#-1 # Since we only care about angle and omega which are given using env.state\n",
    "# action_dim = env.action_space.shape[0]  # For Pendulum, it's continuous\n",
    "action_dim=1\n",
    "\n",
    "# Initialize the Next-State Prediction Network\n",
    "model = NextStateMedianNetwork(state_dim, action_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_func = quantile_loss_median\n",
    "\n",
    "states_low = torch.tensor([-1.2, -0.07])\n",
    "states_high = torch.tensor([0.6, 0.07])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Experience replay buffer\n",
    "replay_buffer = []\n",
    "\n",
    "num_test_steps = 20000\n",
    "\n",
    "state, _ = env.reset(seed=seed)\n",
    "episode_reward = 0\n",
    "actions_list = []\n",
    "done = False\n",
    "truncated = False\n",
    "\n",
    "actions_taken = np.zeros(num_test_steps)\n",
    "env.action_space.seed(seed)\n",
    "\n",
    "for step in range(num_test_steps):\n",
    "    # state = env.state\n",
    "    action = env.action_space.sample()\n",
    "    actions_taken[step] = action\n",
    "    \n",
    "    # Apply the first action from the optimized sequence\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    # next_state = env.state\n",
    "    episode_reward += reward\n",
    "    actions_list.append(action)\n",
    "    \n",
    "    if step >= 1:\n",
    "        # test_env = env.copy()\n",
    "        # test_action = test_env.action_space.sample()\n",
    "        # test_next_state, _, _, _, _ = test_env.step(test_action)\n",
    "        # test_next_state = test_next_state['observation'][:3]\n",
    "        \n",
    "        test_next_state = torch.tensor(next_state, dtype=torch.float32)\n",
    "        # test_next_state = torch.clip(test_next_state, states_low, states_high)\n",
    "        # print(\"test_next_state \", test_next_state, \"\\n\")\n",
    "        \n",
    "        if discrete:\n",
    "            test_action = torch.tensor(np.array([action]), dtype=torch.float32)#.unsqueeze(1)  # Example action\n",
    "        else:\n",
    "            test_action = torch.tensor(action, dtype=torch.float32)#.unsqueeze(1)\n",
    "        test_state = torch.tensor(state, dtype=torch.float32)#.reshape(1, -1)\n",
    "        test_state = torch.clip(test_state, states_low, states_high)\n",
    "        \n",
    "        # Predict next state quantiles\n",
    "        preds = model(test_state, test_action)  # Shape: (1, num_quantiles, state_dim)\n",
    "        # lower_quantile = predicted_quantiles[:, 0, :]  # Shape: (1, state_dim)\n",
    "        # mid_quantile = predicted_quantiles[:, int(num_quantiles/2), :].detach().numpy()  # Shape: (1, state_dim)\n",
    "        # upper_quantile = predicted_quantiles[:, -1, :]  # Shape: (1, state_dim)\n",
    "        # print(\"predicted_quantiles \", predicted_quantiles, \"\\n\")\n",
    "        # print(\"Lower Quantile:\", lower_quantile, \"\\n\")\n",
    "        # print(\"Mid Quantile:\", mid_quantile, \"\\n\")\n",
    "        # print(\"Upper Quantile:\", upper_quantile, \"\\n\")\n",
    "        \n",
    "        pred_x = np.append(pred_x, preds[0].detach().numpy())\n",
    "        pred_v = np.append(pred_v, preds[1].detach().numpy())\n",
    "        # pred_omega = np.append(pred_omega, preds[2].detach().numpy())\n",
    "        # # pred_theta2 = np.append(pred_sintheta2, preds[3].detach().numpy())  \n",
    "        # pred_omega1 = np.append(pred_omega1, preds[4].detach().numpy())\n",
    "        # pred_omega2 = np.append(pred_omega2, preds[5].detach().numpy())\n",
    "        \n",
    "        deltax = test_next_state[0] - preds[0]\n",
    "        deltav = test_next_state[1] - preds[1]\n",
    "        # deltaomega = test_next_state[2] - preds[2]\n",
    "        # deltaomega = test_next_state[3] - preds[3]\n",
    "        # deltaomega1 = test_next_state[4] - preds[4]\n",
    "        # deltaomega2 = test_next_state[5] - preds[5]\n",
    "\n",
    "        # delta = env_test_state - mean_next_state.flatten()#.detach().numpy()\n",
    "        # print(\"delta \", delta, \"\\n\") # 6\n",
    "        # print(\"delta_x \", deltax, \"\\n\") # 7\n",
    "        # error_magnitude = np.linalg.norm(delta)\n",
    "        # error_magnitudes.append(error_magnitude)\n",
    "        error_magnitudes_x.append(np.abs(deltax.detach().numpy())) # .detach().numpy()\n",
    "        error_magnitudes_v.append(np.abs(deltav.detach().numpy())) # .detach().numpy()\n",
    "        # error_magnitudes_theta.append(np.abs(deltatheta.detach().numpy())) # .detach().numpy()\n",
    "        # error_magnitudes_omega.append(np.abs(deltaomega.detach().numpy())) # .detach().numpy()\n",
    "        # error_magnitudes_omega1.append(np.abs(deltaomega1.detach().numpy())) # .detach().numpy()\n",
    "        # error_magnitudes_omega2.append(np.abs(deltaomega2.detach().numpy())) # .detach().numpy()\n",
    "        # env_next_states.append(env_test_state)\n",
    "        env_x.append(test_next_state[0])\n",
    "        env_v.append(test_next_state[1])\n",
    "        # env_omega.append(test_next_state[2])\n",
    "        # env_omega.append(test_next_state[3])\n",
    "        # env_omega1.append(test_next_state[4])\n",
    "        # env_omega2.append(test_next_state[5])\n",
    "    \n",
    "    # next_state = env.state.copy()\n",
    "    # Store experience in replay buffer\n",
    "    if discrete:\n",
    "        replay_buffer.append((state, np.array([action]), reward, next_state, done))\n",
    "    else:\n",
    "        replay_buffer.append((state, np.array(action), reward, next_state, done))\n",
    "    if len(replay_buffer) < batch_size:\n",
    "        pass\n",
    "    else:\n",
    "        batch = random.sample(replay_buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        states = torch.tensor(states, dtype=torch.float32)\n",
    "        actions = torch.tensor(actions, dtype=torch.float32)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "        next_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "        dones = torch.tensor(dones, dtype=torch.float32)\n",
    "        \n",
    "        states = torch.clip(states, states_low, states_high)\n",
    "        \n",
    "        # Predict next state quantiles\n",
    "        predicted_quantiles = model(states, actions)  # Shape: (batch_size, num_quantiles, state_dim)\n",
    "        \n",
    "        # Use next state as target (can be improved with target policy)\n",
    "        target_quantiles = next_states\n",
    "        \n",
    "        # Compute the target quantiles (e.g., replicate next state across the quantile dimension)\n",
    "        # target_quantiles = next_states.unsqueeze(-1).repeat(1, 1, num_quantiles)\n",
    "\n",
    "        # # Compute Quantile Huber Loss\n",
    "        # loss = quantile_huber_loss(predicted_quantiles, target_quantiles, quantiles)\n",
    "\n",
    "        loss = loss_func(predicted_quantiles, target_quantiles)\n",
    "        \n",
    "        # # Compute Quantile Huber Loss\n",
    "        # loss = quantile_huber_loss(predicted_quantiles, target_quantiles, quantiles)\n",
    "        \n",
    "        # Optimize the model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    state = next_state\n",
    "    \n",
    "    if done or truncated:\n",
    "        state, _ = env.reset(seed=seed)\n",
    "        episode_reward = 0\n",
    "        actions_list = []\n",
    "        done = False\n",
    "        truncated = False\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 100 steps\n",
      "x comparison: 0.004326746240694774\n",
      "v comparison: 0.0019265120293130167\n"
     ]
    }
   ],
   "source": [
    "print(\"Last 100 steps\")\n",
    "print(f\"x comparison:\",\n",
    "np.mean(np.abs(np.array(pred_x[-100:])-np.array(env_x[-100:]))))\n",
    "\n",
    "print(f\"v comparison:\",\n",
    "np.mean(np.abs(np.array(pred_v[-100:])-np.array(env_v[-100:]))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All steps\n",
      "x comparison: 0.00467161702373151\n",
      "v comparison: 0.0018117953140153035\n"
     ]
    }
   ],
   "source": [
    "print(\"All steps\")\n",
    "print(f\"x comparison:\",\n",
    "np.mean(np.abs(np.array(pred_x)-np.array(env_x))))\n",
    "\n",
    "print(f\"v comparison:\",\n",
    "np.mean(np.abs(np.array(pred_v)-np.array(env_v))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # # Plot the rewards\n",
    "# # plt.figure(1)\n",
    "# # # plt.legend()\n",
    "# # # plt.grid()\n",
    "# # plt.plot(episode_reward_list)\n",
    "# # plt.xlabel('Nb of episodes')\n",
    "# # plt.ylabel('episode reward')\n",
    "# # # plt.title('MPC_Pendulum with Optimized Action Sequences')\n",
    "# # # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\Graphs\\\\episode_rewards_withCPUforQRNN_{timestamp}.png')\n",
    "# # # # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\episode_rewards_withGPUforGP_{timestamp}.png')\n",
    "\n",
    "# plt.figure(2)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.plot(error_magnitudes_x)\n",
    "# plt.ylabel('error_magnitudes_x')\n",
    "# plt.yscale('log')\n",
    "# # plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_1_{timestamp}.png')\n",
    "\n",
    "# plt.figure(3)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.plot(error_magnitudes_v)\n",
    "# plt.ylabel('error_magnitudes_v')\n",
    "# plt.yscale('log')\n",
    "# # plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_2_{timestamp}.png')\n",
    "\n",
    "\n",
    "# plt.figure(4)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.ylabel('x comparison between env and QRNN')\n",
    "# plt.plot(env_x, label='env_next_states')\n",
    "# plt.plot(pred_x, label='pred_next_states')\n",
    "# # plt.fill_between(np.arange(len(pred_theta)), pred_theta - pred_theta_bottom_1std, pred_theta + pred_theta_top_2std, alpha=0.5, label='1 std', color='green')\n",
    "# # plt.fill_between(np.arange(len(pred_theta)), pred_theta - pred_theta_bottom_2std, pred_theta + pred_theta_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\angles_comparison_GP_env_{timestamp}.png')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure(5)\n",
    "# plt.xlabel('Nb of steps')\n",
    "# plt.ylabel('v comparison between env and QRNN')\n",
    "# plt.plot(env_v, label='env_next_states')\n",
    "# plt.plot(pred_v, label='pred_next_states')\n",
    "# # plt.fill_between(np.arange(len(pred_omega)), pred_omega - pred_omega_bottom_1std, pred_omega + pred_omega_top_1std, alpha=0.5, label='1 std', color='green')\n",
    "# # plt.fill_between(np.arange(len(pred_omega)), pred_omega - pred_omega_bottom_2std, pred_omega + pred_omega_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\omegas_comparison_GP_env_{timestamp}.png')\n",
    "# plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panda Dense reward Reach (3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using states and velocities of env as input and output of QRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panda_gym\n",
    "%matplotlib inline\n",
    "\n",
    "horizon = 15\n",
    "\n",
    "seed = 42\n",
    "max_episodes = 100 # 300\n",
    "max_episode_steps = 50 #1000\n",
    "env = gym.make('PandaReachDense-v3').unwrapped # , render_mode='human'\n",
    "sim_env = gym.make('PandaReachDense-v3').unwrapped  # Additional simulation model for MPC\n",
    "sim_env.reset(seed=seed)\n",
    "env.reset(seed=seed)\n",
    "# np.random.seed(seed)\n",
    "# random.seed(seed)\n",
    "\n",
    "error_magnitudes_x = []\n",
    "error_magnitudes_y = []\n",
    "error_magnitudes_z = []\n",
    "\n",
    "env_x = []\n",
    "env_y = []\n",
    "env_z = []\n",
    "pred_x = []\n",
    "pred_y = []\n",
    "pred_z = []\n",
    "\n",
    "error_magnitudes_vx = []\n",
    "error_magnitudes_vy = []\n",
    "error_magnitudes_vz = []\n",
    "\n",
    "env_vx = []\n",
    "env_vy = []\n",
    "env_vz = []\n",
    "pred_vx = []\n",
    "pred_vy = []\n",
    "pred_vz = []\n",
    "\n",
    "pred_x_bottom_1std = []\n",
    "pred_x_top_1std = []\n",
    "pred_x_bottom_2std = []\n",
    "pred_x_top_2std = []\n",
    "pred_y_bottom_1std = []\n",
    "pred_y_top_1std = []\n",
    "pred_y_bottom_2std = []\n",
    "pred_y_top_2std = []\n",
    "pred_z_bottom_1std = []\n",
    "pred_z_top_1std = []\n",
    "pred_z_bottom_2std = []\n",
    "pred_z_top_2std = []\n",
    "\n",
    "pred_vx_bottom_1std = []\n",
    "pred_vx_top_1std = []\n",
    "pred_vx_bottom_2std = []\n",
    "pred_vx_top_2std = []\n",
    "pred_vy_bottom_1std = []\n",
    "pred_vy_top_1std = []\n",
    "pred_vy_bottom_2std = []\n",
    "pred_vy_top_2std = []\n",
    "pred_vz_bottom_1std = []\n",
    "pred_vz_top_1std = []\n",
    "pred_vz_bottom_2std = []\n",
    "pred_vz_top_2std = []\n",
    "\n",
    "# quantile 0 data\n",
    "quantile0_x = []\n",
    "quantile0_y = []\n",
    "quantile0_z = []\n",
    "quantile0_vx = []\n",
    "quantile0_vy = []\n",
    "quantile0_vz = []\n",
    "\n",
    "\n",
    "# quantile 1 data\n",
    "quantile1_x = []\n",
    "quantile1_y = []\n",
    "quantile1_z = []\n",
    "quantile1_vx = []\n",
    "quantile1_vy = []\n",
    "quantile1_vz = []\n",
    "\n",
    "# quantile 2 data\n",
    "quantile2_x = []\n",
    "quantile2_y = []\n",
    "quantile2_z = []\n",
    "quantile2_vx = []\n",
    "quantile2_vy = []\n",
    "quantile2_vz = []\n",
    "\n",
    "# quantile 3 data\n",
    "quantile3_x = []\n",
    "quantile3_y = []\n",
    "quantile3_z = []\n",
    "quantile3_vx = []\n",
    "quantile3_vy = []\n",
    "quantile3_vz = []\n",
    "\n",
    "# quantile 4 data\n",
    "quantile4_x = []\n",
    "quantile4_y = []\n",
    "quantile4_z = []\n",
    "quantile4_vx = []\n",
    "quantile4_vy = []\n",
    "quantile4_vz = []\n",
    "\n",
    "# quantile 5 data\n",
    "quantile5_x = []\n",
    "quantile5_y = []\n",
    "quantile5_z = []\n",
    "quantile5_vx = []\n",
    "quantile5_vy = []\n",
    "quantile5_vz = []\n",
    "\n",
    "# quantile 6 data\n",
    "quantile6_x = []\n",
    "quantile6_y = []\n",
    "quantile6_z = []\n",
    "quantile6_vx = []\n",
    "quantile6_vy = []\n",
    "quantile6_vz = []\n",
    "\n",
    "# quantile 7 data\n",
    "quantile7_x = []\n",
    "quantile7_y = []\n",
    "quantile7_z = []\n",
    "quantile7_vx = []\n",
    "quantile7_vy = []\n",
    "quantile7_vz = []\n",
    "\n",
    "# quantile 8 data\n",
    "quantile8_x = []\n",
    "quantile8_y = []\n",
    "quantile8_z = []\n",
    "quantile8_vx = []\n",
    "quantile8_vy = []\n",
    "quantile8_vz = []\n",
    "\n",
    "# quantile 9 data\n",
    "quantile9_x = []\n",
    "quantile9_y = []\n",
    "quantile9_z = []\n",
    "quantile9_vx = []\n",
    "quantile9_vy = []\n",
    "quantile9_vz = []\n",
    "\n",
    "# quantile 10 data\n",
    "quantile10_x = []\n",
    "quantile10_y = []\n",
    "quantile10_z = []\n",
    "quantile10_vx = []\n",
    "quantile10_vy = []\n",
    "quantile10_vz = []\n",
    "\n",
    "\n",
    "actions_low = env.action_space.low#[:3]\n",
    "actions_high = env.action_space.high#[:3]\n",
    "states_low = env.observation_space['observation'].low#[:3]\n",
    "states_high = env.observation_space['observation'].high#[:3]\n",
    "\n",
    "# Hyperparameters\n",
    "state_dim = len(states_low)\n",
    "action_dim = len(actions_low)\n",
    "# Define your quantiles (e.g., 0.1, 0.3, 0.7, 0.9)\n",
    "# quantiles = torch.tensor([0.1, 0.3, 0.7, 0.9], dtype=torch.float32)\n",
    "quantiles = torch.tensor(np.array([0.0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]), dtype=torch.float32)\n",
    "\n",
    "# num_quantiles = 4  # Example with 4 quantiles\n",
    "num_quantiles = len(quantiles)\n",
    "\n",
    "# Initialize the Next-State Prediction Network\n",
    "model = NextStateQuantileNetwork(state_dim, action_dim, num_quantiles)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Experience replay buffer\n",
    "replay_buffer = []\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# usingEnv = True\n",
    "usingEnv = False\n",
    "\n",
    "# print(\"actions_low \", actions_low, \"\\n\")\n",
    "# print(\"actions_high \", actions_high, \"\\n\")\n",
    "\n",
    "# Initialization\n",
    "num_particles = 20 #100#0 # 20 # 100\n",
    "particles = [np.random.uniform(-actions_low[0], actions_high[0], 3*horizon) for _ in range(num_particles)] # 2*horizon_list[0]\n",
    "num_samples = 5\n",
    "noise_scale = 0.1\n",
    "\n",
    "\n",
    "# Run the simulation\n",
    "# rewards = start()\n",
    "\n",
    "# Main env loop\n",
    "# for rollout, horizon in zip(rollout_list, horizon_list):\n",
    "episode_reward_list = []\n",
    "\n",
    "num_test_steps = 20000\n",
    "state, _ = env.reset(seed=seed)\n",
    "episode_reward = 0\n",
    "actions_list = []\n",
    "done = False\n",
    "truncated = False\n",
    "\n",
    "goal_state = state['desired_goal'] # 3 components\n",
    "state = state['observation']#[:3] # 6 components\n",
    "\n",
    "for step in range(num_test_steps):\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    episode_reward += reward\n",
    "    next_state = next_state['observation']#[:3] # env.state\n",
    "    \n",
    "    if step >= 1:\n",
    "        # test_env = env.copy()\n",
    "        # test_action = test_env.action_space.sample()\n",
    "        # test_next_state, _, _, _, _ = test_env.step(test_action)\n",
    "        # test_next_state = test_next_state['observation'][:3]\n",
    "        \n",
    "        test_next_state = torch.tensor(next_state, dtype=torch.float32)\n",
    "        # print(\"test_next_state \", test_next_state, \"\\n\")\n",
    "        \n",
    "        test_action = torch.tensor(action, dtype=torch.float32)#.unsqueeze(1)  # Example action\n",
    "        test_state = torch.tensor(state, dtype=torch.float32)#.reshape(1, -1)\n",
    "        # Predict next state quantiles\n",
    "        predicted_quantiles = model(test_state, test_action)  # Shape: (1, num_quantiles, state_dim)\n",
    "        lower_quantile = predicted_quantiles[:, 0, :]  # Shape: (1, state_dim)\n",
    "        mid_quantile = predicted_quantiles[:, int(num_quantiles/2), :].detach().numpy()  # Shape: (1, state_dim)\n",
    "        upper_quantile = predicted_quantiles[:, -1, :]  # Shape: (1, state_dim)\n",
    "        # print(\"predicted_quantiles \", predicted_quantiles, \"\\n\")\n",
    "        # print(\"Lower Quantile:\", lower_quantile, \"\\n\")\n",
    "        # print(\"Mid Quantile:\", mid_quantile, \"\\n\")\n",
    "        # print(\"Upper Quantile:\", upper_quantile, \"\\n\")\n",
    "        \n",
    "        pred_x = np.append(pred_x, mid_quantile[0][0])\n",
    "        pred_y = np.append(pred_y, mid_quantile[0][1])\n",
    "        pred_z = np.append(pred_z, mid_quantile[0][2])\n",
    "        pred_vx = np.append(pred_x, mid_quantile[0][3])\n",
    "        pred_vy = np.append(pred_y, mid_quantile[0][4])\n",
    "        pred_vz = np.append(pred_z, mid_quantile[0][5])\n",
    "        \n",
    "        # Quantile 0 data\n",
    "        quantile0_x = np.append(quantile0_x, predicted_quantiles[0][0][0].item())\n",
    "        quantile0_y = np.append(quantile0_y, predicted_quantiles[0][0][1].item())\n",
    "        quantile0_z = np.append(quantile0_z, predicted_quantiles[0][0][2].item())\n",
    "        quantile0_vx = np.append(quantile0_vx, predicted_quantiles[0][0][3].item())\n",
    "        quantile0_vy = np.append(quantile0_vy, predicted_quantiles[0][0][4].item())\n",
    "        quantile0_vz = np.append(quantile0_vz, predicted_quantiles[0][0][5].item())\n",
    "        \n",
    "        # Quantile 1 data\n",
    "        quantile1_x = np.append(quantile1_x, predicted_quantiles[0][1][0].item())\n",
    "        quantile1_y = np.append(quantile1_y, predicted_quantiles[0][1][1].item())\n",
    "        quantile1_z = np.append(quantile1_z, predicted_quantiles[0][1][2].item())\n",
    "        quantile1_vx = np.append(quantile1_vx, predicted_quantiles[0][1][3].item())\n",
    "        quantile1_vy = np.append(quantile1_vy, predicted_quantiles[0][1][4].item())\n",
    "        quantile1_vz = np.append(quantile1_vz, predicted_quantiles[0][1][5].item())\n",
    "        \n",
    "        # Quantile 2 data\n",
    "        quantile2_x = np.append(quantile2_x, predicted_quantiles[0][2][0].item())\n",
    "        quantile2_y = np.append(quantile2_y, predicted_quantiles[0][2][1].item())\n",
    "        quantile2_z = np.append(quantile2_z, predicted_quantiles[0][2][2].item())\n",
    "        quantile2_vx = np.append(quantile2_vx, predicted_quantiles[0][2][3].item())\n",
    "        quantile2_vy = np.append(quantile2_vy, predicted_quantiles[0][2][4].item())\n",
    "        quantile2_vz = np.append(quantile2_vz, predicted_quantiles[0][2][5].item())\n",
    "        \n",
    "        # Quantile 3 data\n",
    "        quantile3_x = np.append(quantile3_x, predicted_quantiles[0][3][0].item())\n",
    "        quantile3_y = np.append(quantile3_y, predicted_quantiles[0][3][1].item())\n",
    "        quantile3_z = np.append(quantile3_z, predicted_quantiles[0][3][2].item())\n",
    "        quantile3_vx = np.append(quantile3_vx, predicted_quantiles[0][3][3].item())\n",
    "        quantile3_vy = np.append(quantile3_vy, predicted_quantiles[0][3][4].item())\n",
    "        quantile3_vz = np.append(quantile3_vz, predicted_quantiles[0][3][5].item())\n",
    "        \n",
    "        # Quantile 4 data\n",
    "        quantile4_x = np.append(quantile4_x, predicted_quantiles[0][4][0].item())\n",
    "        quantile4_y = np.append(quantile4_y, predicted_quantiles[0][4][1].item())\n",
    "        quantile4_z = np.append(quantile4_z, predicted_quantiles[0][4][2].item())\n",
    "        quantile4_vx = np.append(quantile4_vx, predicted_quantiles[0][4][3].item())\n",
    "        quantile4_vy = np.append(quantile4_vy, predicted_quantiles[0][4][4].item())\n",
    "        quantile4_vz = np.append(quantile4_vz, predicted_quantiles[0][4][5].item())\n",
    "        \n",
    "        # Quantile 5 data\n",
    "        quantile5_x = np.append(quantile5_x, predicted_quantiles[0][5][0].item())\n",
    "        quantile5_y = np.append(quantile5_y, predicted_quantiles[0][5][1].item())\n",
    "        quantile5_z = np.append(quantile5_z, predicted_quantiles[0][5][2].item())\n",
    "        quantile5_vx = np.append(quantile5_vx, predicted_quantiles[0][5][3].item())\n",
    "        quantile5_vy = np.append(quantile5_vy, predicted_quantiles[0][5][4].item())\n",
    "        quantile5_vz = np.append(quantile5_vz, predicted_quantiles[0][5][5].item())\n",
    "        \n",
    "        # Quantile 6 data\n",
    "        quantile6_x = np.append(quantile6_x, predicted_quantiles[0][6][0].item())\n",
    "        quantile6_y = np.append(quantile6_y, predicted_quantiles[0][6][1].item())\n",
    "        quantile6_z = np.append(quantile6_z, predicted_quantiles[0][6][2].item())\n",
    "        quantile6_vx = np.append(quantile6_vx, predicted_quantiles[0][6][3].item())\n",
    "        quantile6_vy = np.append(quantile6_vy, predicted_quantiles[0][6][4].item())\n",
    "        quantile6_vz = np.append(quantile6_vz, predicted_quantiles[0][6][5].item())\n",
    "        \n",
    "        # Quantile 7 data\n",
    "        quantile7_x = np.append(quantile7_x, predicted_quantiles[0][7][0].item())\n",
    "        quantile7_y = np.append(quantile7_y, predicted_quantiles[0][7][1].item())\n",
    "        quantile7_z = np.append(quantile7_z, predicted_quantiles[0][7][2].item())\n",
    "        quantile7_vx = np.append(quantile7_vx, predicted_quantiles[0][7][3].item())\n",
    "        quantile7_vy = np.append(quantile7_vy, predicted_quantiles[0][7][4].item())\n",
    "        quantile7_vz = np.append(quantile7_vz, predicted_quantiles[0][7][5].item())\n",
    "        \n",
    "        # Quantile 8 data\n",
    "        quantile8_x = np.append(quantile8_x, predicted_quantiles[0][8][0].item())\n",
    "        quantile8_y = np.append(quantile8_y, predicted_quantiles[0][8][1].item())\n",
    "        quantile8_z = np.append(quantile8_z, predicted_quantiles[0][8][2].item())\n",
    "        quantile8_vx = np.append(quantile8_vx, predicted_quantiles[0][8][3].item())\n",
    "        quantile8_vy = np.append(quantile8_vy, predicted_quantiles[0][8][4].item())\n",
    "        quantile8_vz = np.append(quantile8_vz, predicted_quantiles[0][8][5].item())\n",
    "        \n",
    "        # Quantile 9 data\n",
    "        quantile9_x = np.append(quantile9_x, predicted_quantiles[0][9][0].item())\n",
    "        quantile9_y = np.append(quantile9_y, predicted_quantiles[0][9][1].item())\n",
    "        quantile9_z = np.append(quantile9_z, predicted_quantiles[0][9][2].item())\n",
    "        quantile9_vx = np.append(quantile9_vx, predicted_quantiles[0][9][3].item())\n",
    "        quantile9_vy = np.append(quantile9_vy, predicted_quantiles[0][9][4].item())\n",
    "        quantile9_vz = np.append(quantile9_vz, predicted_quantiles[0][9][5].item())\n",
    "        \n",
    "        # Quantile 10 data\n",
    "        quantile10_x = np.append(quantile10_x, predicted_quantiles[0][10][0].item())\n",
    "        quantile10_y = np.append(quantile10_y, predicted_quantiles[0][10][1].item())\n",
    "        quantile10_z = np.append(quantile10_z, predicted_quantiles[0][10][2].item())\n",
    "        quantile10_vx = np.append(quantile10_vx, predicted_quantiles[0][10][3].item())\n",
    "        quantile10_vy = np.append(quantile10_vy, predicted_quantiles[0][10][4].item())\n",
    "        quantile10_vz = np.append(quantile10_vz, predicted_quantiles[0][10][5].item())\n",
    "        \n",
    "        # pred_x_bottom_1std = []\n",
    "        # pred_x_top_1std = []\n",
    "        # pred_x_bottom_2std = []\n",
    "        # pred_x_top_2std = []\n",
    "        # pred_y_bottom_1std = []\n",
    "        # pred_y_top_1std = []\n",
    "        # pred_y_bottom_2std = []\n",
    "        # pred_y_top_2std = []\n",
    "        # pred_z_bottom_1std = []\n",
    "        # pred_z_top_1std = []\n",
    "        # pred_z_bottom_2std = []\n",
    "        # pred_z_top_2std = []\n",
    "        \n",
    "        ### x ###\n",
    "        # Top of 1 std is the average of 0.6 and 0.7 quantiles\n",
    "        pred_x_top_1std = np.append(pred_x_top_1std, (predicted_quantiles[0][6][0].item()+predicted_quantiles[0][7][0].item())/2)\n",
    "        # Bottom of 1 std is the average of 0.3 and 0.4 quantiles\n",
    "        pred_x_bottom_1std = np.append(pred_x_bottom_1std, (predicted_quantiles[0][3][0].item()+predicted_quantiles[0][4][0].item())/2)\n",
    "        \n",
    "        # Top of 2 std is the average between 0.9 and 1.0 quantiles\n",
    "        pred_x_top_2std = np.append(pred_x_top_2std, (predicted_quantiles[0][9][0].item()+predicted_quantiles[0][10][0].item())/2)\n",
    "        # Bottom of 2 std is the average between 0.0 and 0.1 quantiles\n",
    "        pred_x_bottom_2std = np.append(pred_x_bottom_2std, (predicted_quantiles[0][0][0].item()+predicted_quantiles[0][1][0].item())/2)\n",
    "            \n",
    "            \n",
    "        ### y ###\n",
    "        # Top of 1 std is the average of 0.6 and 0.7 quantiles\n",
    "        pred_y_top_1std = np.append(pred_y_top_1std, (predicted_quantiles[0][6][1].item()+predicted_quantiles[0][7][1].item())/2)\n",
    "        # Bottom of 1 std is the average of 0.3 and 0.4 quantiles\n",
    "        pred_y_bottom_1std = np.append(pred_y_bottom_1std, (predicted_quantiles[0][3][1].item()+predicted_quantiles[0][4][1].item())/2)\n",
    "        \n",
    "        # Top of 2 std is the average between 0.9 and 1.0 quantiles\n",
    "        pred_y_top_2std = np.append(pred_y_top_2std, (predicted_quantiles[0][9][1].item()+predicted_quantiles[0][10][1].item())/2)\n",
    "        # Bottom of 2 std is the average between 0.0 and 0.1 quantiles\n",
    "        pred_y_bottom_2std = np.append(pred_y_bottom_2std, (predicted_quantiles[0][0][1].item()+predicted_quantiles[0][1][1].item())/2)\n",
    "            \n",
    "            \n",
    "        ### z ###\n",
    "        # Top of 1 std is the average of 0.6 and 0.7 quantiles\n",
    "        pred_z_top_1std = np.append(pred_z_top_1std, (predicted_quantiles[0][6][2].item()+predicted_quantiles[0][7][2].item())/2)\n",
    "        # Bottom of 1 std is the average of 0.3 and 0.4 quantiles\n",
    "        pred_z_bottom_1std = np.append(pred_z_bottom_1std, (predicted_quantiles[0][3][2].item()+predicted_quantiles[0][4][2].item())/2)\n",
    "        \n",
    "        # Top of 2 std is the average between 0.9 and 1.0 quantiles\n",
    "        pred_z_top_2std = np.append(pred_z_top_2std, (predicted_quantiles[0][9][2].item()+predicted_quantiles[0][10][2].item())/2)\n",
    "        # Bottom of 2 std is the average between 0.0 and 0.1 quantiles\n",
    "        pred_z_bottom_2std = np.append(pred_z_bottom_2std, (predicted_quantiles[0][0][2].item()+predicted_quantiles[0][1][2].item())/2)\n",
    "            \n",
    "        ### vx ###\n",
    "        # Top of 1 std is the average of 0.6 and 0.7 quantiles\n",
    "        pred_vx_top_1std = np.append(pred_x_top_1std, (predicted_quantiles[0][6][3].item()+predicted_quantiles[0][7][3].item())/2)\n",
    "        # Bottom of 1 std is the average of 0.3 and 0.4 quantiles\n",
    "        pred_vx_bottom_1std = np.append(pred_x_bottom_1std, (predicted_quantiles[0][3][3].item()+predicted_quantiles[0][4][3].item())/2)\n",
    "        \n",
    "        # Top of 2 std is the average between 0.9 and 1.0 quantiles\n",
    "        pred_vx_top_2std = np.append(pred_vx_top_2std, (predicted_quantiles[0][9][3].item()+predicted_quantiles[0][10][3].item())/2)\n",
    "        # Bottom of 2 std is the average between 0.0 and 0.1 quantiles\n",
    "        pred_vx_bottom_2std = np.append(pred_vx_bottom_2std, (predicted_quantiles[0][0][3].item()+predicted_quantiles[0][1][3].item())/2)\n",
    "            \n",
    "            \n",
    "        ### vy ###\n",
    "        # Top of 1 std is the average of 0.6 and 0.7 quantiles\n",
    "        pred_vy_top_1std = np.append(pred_vy_top_1std, (predicted_quantiles[0][6][4].item()+predicted_quantiles[0][7][4].item())/2)\n",
    "        # Bottom of 1 std is the average of 0.3 and 0.4 quantiles\n",
    "        pred_vy_bottom_1std = np.append(pred_vy_bottom_1std, (predicted_quantiles[0][3][4].item()+predicted_quantiles[0][4][4].item())/2)\n",
    "        \n",
    "        # Top of 2 std is the average between 0.9 and 1.0 quantiles\n",
    "        pred_vy_top_2std = np.append(pred_vy_top_2std, (predicted_quantiles[0][9][4].item()+predicted_quantiles[0][10][4].item())/2)\n",
    "        # Bottom of 2 std is the average between 0.0 and 0.1 quantiles\n",
    "        pred_vy_bottom_2std = np.append(pred_vy_bottom_2std, (predicted_quantiles[0][0][4].item()+predicted_quantiles[0][1][4].item())/2)\n",
    "            \n",
    "            \n",
    "        ### z ###\n",
    "        # Top of 1 std is the average of 0.6 and 0.7 quantiles\n",
    "        pred_vz_top_1std = np.append(pred_vz_top_1std, (predicted_quantiles[0][6][5].item()+predicted_quantiles[0][7][5].item())/2)\n",
    "        # Bottom of 1 std is the average of 0.3 and 0.4 quantiles\n",
    "        pred_vz_bottom_1std = np.append(pred_vz_bottom_1std, (predicted_quantiles[0][3][5].item()+predicted_quantiles[0][4][5].item())/2)\n",
    "        \n",
    "        # Top of 2 std is the average between 0.9 and 1.0 quantiles\n",
    "        pred_vz_top_2std = np.append(pred_vz_top_2std, (predicted_quantiles[0][9][5].item()+predicted_quantiles[0][10][5].item())/2)\n",
    "        # Bottom of 2 std is the average between 0.0 and 0.1 quantiles\n",
    "        pred_vz_bottom_2std = np.append(pred_vz_bottom_2std, (predicted_quantiles[0][0][5].item()+predicted_quantiles[0][1][5].item())/2)\n",
    "            \n",
    "        \n",
    "        # pred_x_var = np.append(pred_x_var, covariance_next_state[0][0].item())\n",
    "        # pred_y_var = np.append(pred_y_var, covariance_next_state[1][1].item())\n",
    "        # pred_z_var = np.append(pred_z_var, covariance_next_state[2][2].item())\n",
    "        \n",
    "        \n",
    "        deltax = test_next_state[0] - mid_quantile[0][0]\n",
    "        deltay = test_next_state[1] - mid_quantile[0][1]\n",
    "        deltaz = test_next_state[2] - mid_quantile[0][2]\n",
    "        # delta = env_test_state - mean_next_state.flatten()#.detach().numpy()\n",
    "        # print(\"delta \", delta, \"\\n\") # 6\n",
    "        # print(\"delta_x \", deltax, \"\\n\") # 7\n",
    "        # error_magnitude = np.linalg.norm(delta)\n",
    "        # error_magnitudes.append(error_magnitude)\n",
    "        error_magnitudes_x.append(np.abs(deltax)) # .detach().numpy()\n",
    "        error_magnitudes_y.append(np.abs(deltay)) # .detach().numpy()\n",
    "        error_magnitudes_z.append(np.abs(deltaz)) # .detach().numpy()\n",
    "        # env_next_states.append(env_test_state)\n",
    "        env_x.append(test_next_state[0])\n",
    "        env_y.append(test_next_state[1])\n",
    "        env_z.append(test_next_state[2])\n",
    "        \n",
    "        \n",
    "        deltavx = test_next_state[3] - mid_quantile[0][3]\n",
    "        deltavy = test_next_state[4] - mid_quantile[0][4]\n",
    "        deltavz = test_next_state[5] - mid_quantile[0][5]\n",
    "        # delta = env_test_state - mean_next_state.flatten()#.detach().numpy()\n",
    "        # print(\"delta \", delta, \"\\n\") # 6\n",
    "        # print(\"delta_x \", deltax, \"\\n\") # 7\n",
    "        # error_magnitude = np.linalg.norm(delta)\n",
    "        # error_magnitudes.append(error_magnitude)\n",
    "        error_magnitudes_vx.append(np.abs(deltavx)) # .detach().numpy()\n",
    "        error_magnitudes_vy.append(np.abs(deltavy)) # .detach().numpy()\n",
    "        error_magnitudes_vz.append(np.abs(deltavz)) # .detach().numpy()\n",
    "        # env_next_states.append(env_test_state)\n",
    "        env_vx.append(test_next_state[3])\n",
    "        env_vy.append(test_next_state[4])\n",
    "        env_vz.append(test_next_state[5])\n",
    "    \n",
    "    # next_state = env.state.copy()\n",
    "    # Store experience in replay buffer\n",
    "    replay_buffer.append((state, action, reward, next_state, done))\n",
    "    if len(replay_buffer) < batch_size:\n",
    "        pass\n",
    "    else:\n",
    "        batch = random.sample(replay_buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        states = torch.tensor(states, dtype=torch.float32)\n",
    "        actions = torch.tensor(actions, dtype=torch.float32)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "        next_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "        dones = torch.tensor(dones, dtype=torch.float32)\n",
    "        \n",
    "        # Predict next state quantiles\n",
    "        predicted_quantiles = model(states, actions)  # Shape: (batch_size, num_quantiles, state_dim)\n",
    "        \n",
    "        # Use next state as target (can be improved with target policy)\n",
    "        target_quantiles = next_states\n",
    "        \n",
    "        # Compute the target quantiles (e.g., replicate next state across the quantile dimension)\n",
    "        # target_quantiles = next_states.unsqueeze(-1).repeat(1, 1, num_quantiles)\n",
    "\n",
    "        # Compute Quantile Huber Loss\n",
    "        loss = quantile_huber_loss(predicted_quantiles, target_quantiles, quantiles)\n",
    "\n",
    "        \n",
    "        # Compute Quantile Huber Loss\n",
    "        loss = quantile_huber_loss(predicted_quantiles, target_quantiles, quantiles)\n",
    "        \n",
    "        # Optimize the model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    state = next_state\n",
    "\n",
    "    if done or truncated:\n",
    "        state, _ = env.reset(seed=seed)\n",
    "        episode_reward = 0\n",
    "        actions_list = []\n",
    "        done = False\n",
    "        truncated = False\n",
    "        \n",
    "        goal_state = state['desired_goal'] # 3 components\n",
    "        state = state['observation']#[:3] # 6 components\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the rewards\n",
    "plt.figure(1)\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "plt.plot(episode_reward_list)\n",
    "plt.xlabel('Nb of episodes')\n",
    "plt.ylabel('episode reward')\n",
    "# plt.title('MPC_Pendulum with Optimized Action Sequences')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\Graphs\\\\episode_rewards_withCPUforQRNN_{timestamp}.png')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\episode_rewards_withGPUforGP_{timestamp}.png')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.plot(error_magnitudes_x)\n",
    "plt.ylabel('error_magnitudes_x')\n",
    "# plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_1_{timestamp}.png')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure(3)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.plot(error_magnitudes_y)\n",
    "plt.ylabel('error_magnitudes_y')\n",
    "# plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_2_{timestamp}.png')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure(4)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.plot(error_magnitudes_z)\n",
    "plt.ylabel('error_magnitudes_z')\n",
    "# plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_2_{timestamp}.png')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure(5)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.ylabel('x comparison between env and QRNN')\n",
    "plt.plot(env_x, label='env_next_states')\n",
    "plt.plot(pred_x, label='pred_next_states')\n",
    "# plt.fill_between(np.arange(len(pred_x)), pred_x - pred_x_bottom_1std, pred_x + pred_x_top_2std, alpha=0.5, label='1 std', color='green')\n",
    "# plt.fill_between(np.arange(len(pred_x)), pred_x - pred_x_bottom_2std, pred_x + pred_x_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\angles_comparison_GP_env_{timestamp}.png')\n",
    "# plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(6)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.ylabel('y comparison between env and QRNN')\n",
    "plt.plot(env_y, label='env_next_states')\n",
    "plt.plot(pred_y, label='pred_next_states')\n",
    "# plt.fill_between(np.arange(len(pred_y)), pred_y - pred_y_bottom_1std, pred_y + pred_y_top_1std, alpha=0.5, label='1 std', color='green')\n",
    "# plt.fill_between(np.arange(len(pred_y)), pred_y - pred_y_bottom_2std, pred_y + pred_y_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\omegas_comparison_GP_env_{timestamp}.png')\n",
    "# plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(7)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.ylabel('z comparison between env and QRNN')\n",
    "plt.plot(env_z, label='env_next_states')\n",
    "plt.plot(pred_z, label='pred_next_states')\n",
    "# plt.fill_between(np.arange(len(pred_z)), pred_z - pred_z_bottom_1std, pred_z + pred_z_top_1std, alpha=0.5, label='1 std', color='green')\n",
    "# plt.fill_between(np.arange(len(pred_z)), pred_z - pred_z_bottom_2std, pred_z + pred_z_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\omegas_comparison_GP_env_{timestamp}.png')\n",
    "# plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(8)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.plot(error_magnitudes_vx)\n",
    "plt.ylabel('error_magnitudes_vx')\n",
    "# plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_1_{timestamp}.png')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure(9)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.plot(error_magnitudes_vy)\n",
    "plt.ylabel('error_magnitudes_vy')\n",
    "# plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_2_{timestamp}.png')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure(10)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.plot(error_magnitudes_vz)\n",
    "plt.ylabel('error_magnitudes_vz')\n",
    "# plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_2_{timestamp}.png')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure(11)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.ylabel('vx comparison between env and QRNN')\n",
    "plt.plot(env_vx, label='env_next_states')\n",
    "plt.plot(pred_vx, label='pred_next_states')\n",
    "# plt.fill_between(np.arange(len(pred_x)), pred_x - pred_x_bottom_1std, pred_x + pred_x_top_2std, alpha=0.5, label='1 std', color='green')\n",
    "# plt.fill_between(np.arange(len(pred_x)), pred_x - pred_x_bottom_2std, pred_x + pred_x_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\angles_comparison_GP_env_{timestamp}.png')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(12)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.ylabel('vy comparison between env and QRNN')\n",
    "plt.plot(env_vy, label='env_next_states')\n",
    "plt.plot(pred_vy, label='pred_next_states')\n",
    "# plt.fill_between(np.arange(len(pred_y)), pred_y - pred_y_bottom_1std, pred_y + pred_y_top_1std, alpha=0.5, label='1 std', color='green')\n",
    "# plt.fill_between(np.arange(len(pred_y)), pred_y - pred_y_bottom_2std, pred_y + pred_y_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\omegas_comparison_GP_env_{timestamp}.png')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(13)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.ylabel('vz comparison between env and QRNN')\n",
    "plt.plot(env_vz, label='env_next_states')\n",
    "plt.plot(pred_vz, label='pred_next_states')\n",
    "# plt.fill_between(np.arange(len(pred_z)), pred_z - pred_z_bottom_1std, pred_z + pred_z_top_1std, alpha=0.5, label='1 std', color='green')\n",
    "# plt.fill_between(np.arange(len(pred_z)), pred_z - pred_z_bottom_2std, pred_z + pred_z_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\omegas_comparison_GP_env_{timestamp}.png')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph of number of values below the different quantiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x \n",
    "variable = \"x\"\n",
    "nb_belowq1_list_x, nb_belowq2_list_x, nb_belowq3_list_x, nb_belowq4_list_x, nb_belowq5_list_x, nb_belowq6_list_x, nb_belowq7_list_x, nb_belowq8_list_x, nb_belowq9_list_x, nb_belowq10_list_x = nb_below_quantile(env_x, quantile0_x, quantile1_x, quantile2_x, quantile3_x, quantile4_x, quantile5_x, quantile6_x, quantile7_x, quantile8_x, quantile9_x, quantile10_x)\n",
    "plot_nb_below_quantiles(nb_belowq1_list_x, nb_belowq2_list_x, nb_belowq3_list_x, nb_belowq4_list_x, nb_belowq5_list_x, nb_belowq6_list_x, nb_belowq7_list_x, nb_belowq8_list_x, nb_belowq9_list_x, nb_belowq10_list_x, variable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vx\n",
    "variable = \"vx\"\n",
    "nb_belowq1_list_vx, nb_belowq2_list_vx, nb_belowq3_list_vx, nb_belowq4_list_vx, nb_belowq5_list_vx, nb_belowq6_list_vx, nb_belowq7_list_vx, nb_belowq8_list_vx, nb_belowq9_list_vx, nb_belowq10_list_vx = nb_below_quantile(env_vx, quantile0_vx, quantile1_vx, quantile2_vx, quantile3_vx, quantile4_vx, quantile5_vx, quantile6_vx, quantile7_vx, quantile8_vx, quantile9_vx, quantile10_vx)\n",
    "plot_nb_below_quantiles(nb_belowq1_list_vx, nb_belowq2_list_vx, nb_belowq3_list_vx, nb_belowq4_list_vx, nb_belowq5_list_vx, nb_belowq6_list_vx, nb_belowq7_list_vx, nb_belowq8_list_vx, nb_belowq9_list_vx, nb_belowq10_list_vx, variable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to change the one below to y's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x \n",
    "variable = \"x\"\n",
    "nb_belowq1_list_x, nb_belowq2_list_x, nb_belowq3_list_x, nb_belowq4_list_x, nb_belowq5_list_x, nb_belowq6_list_x, nb_belowq7_list_x, nb_belowq8_list_x, nb_belowq9_list_x, nb_belowq10_list_x = nb_below_quantile(env_x, quantile0_x, quantile1_x, quantile2_x, quantile3_x, quantile4_x, quantile5_x, quantile6_x, quantile7_x, quantile8_x, quantile9_x, quantile10_x)\n",
    "plot_nb_below_quantiles(nb_belowq1_list_x, nb_belowq2_list_x, nb_belowq3_list_x, nb_belowq4_list_x, nb_belowq5_list_x, nb_belowq6_list_x, nb_belowq7_list_x, nb_belowq8_list_x, nb_belowq9_list_x, nb_belowq10_list_x, variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vy\n",
    "variable = \"vx\"\n",
    "nb_belowq1_list_vy, nb_belowq2_list_vy, nb_belowq3_list_vy, nb_belowq4_list_vy, nb_belowq5_list_vy, nb_belowq6_list_vy, nb_belowq7_list_vy, nb_belowq8_list_vy, nb_belowq9_list_vy, nb_belowq10_list_vy = nb_below_quantile(env_vy, quantile0_vy, quantile1_vy, quantile2_vy, quantile3_vy, quantile4_vy, quantile5_vy, quantile6_vy, quantile7_vy, quantile8_vy, quantile9_vy, quantile10_vy)\n",
    "plot_nb_below_quantiles(nb_belowq1_list_vy, nb_belowq2_list_vy, nb_belowq3_list_vy, nb_belowq4_list_vy, nb_belowq5_list_vy, nb_belowq6_list_vy, nb_belowq7_list_vy, nb_belowq8_list_vy, nb_belowq9_list_vy, nb_belowq10_list_vy, variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z\n",
    "variable = \"z\"\n",
    "nb_belowq1_list_z, nb_belowq2_list_z, nb_belowq3_list_z, nb_belowq4_list_z, nb_belowq5_list_z, nb_belowq6_list_z, nb_belowq7_list_z, nb_belowq8_list_z, nb_belowq9_list_z, nb_belowq10_list_z = nb_below_quantile(env_z, quantile0_z, quantile1_z, quantile2_z, quantile3_z, quantile4_z, quantile5_z, quantile6_z, quantile7_z, quantile8_z, quantile9_z, quantile10_z)\n",
    "plot_nb_below_quantiles(nb_belowq1_list_z, nb_belowq2_list_z, nb_belowq3_list_z, nb_belowq4_list_z, nb_belowq5_list_z, nb_belowq6_list_z, nb_belowq7_list_z, nb_belowq8_list_z, nb_belowq9_list_z, nb_belowq10_list_z, variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vz\n",
    "variable = \"vz\"\n",
    "nb_belowq1_list_vz, nb_belowq2_list_vz, nb_belowq3_list_vz, nb_belowq4_list_vz, nb_belowq5_list_vz, nb_belowq6_list_vz, nb_belowq7_list_vz, nb_belowq8_list_vz, nb_belowq9_list_vz, nb_belowq10_list_vz = nb_below_quantile(env_vz, quantile0_vz, quantile1_vz, quantile2_vz, quantile3_vz, quantile4_vz, quantile5_vz, quantile6_vz, quantile7_vz, quantile8_vz, quantile9_vz, quantile10_vz)\n",
    "plot_nb_below_quantiles(nb_belowq1_list_vz, nb_belowq2_list_vz, nb_belowq3_list_vz, nb_belowq4_list_vz, nb_belowq5_list_vz, nb_belowq6_list_vz, nb_belowq7_list_vz, nb_belowq8_list_vz, nb_belowq9_list_vz, nb_belowq10_list_vz, variable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MuJoCo Reacher (2D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panda_gym\n",
    "%matplotlib inline\n",
    "\n",
    "horizon = 15\n",
    "\n",
    "seed = 42\n",
    "max_episodes = 100 # 300\n",
    "max_episode_steps = 50 #1000\n",
    "env = gym.make('Reacher-v5').unwrapped # , render_mode='human'\n",
    "sim_env = gym.make('Reacher-v5').unwrapped  # Additional simulation model for MPC\n",
    "sim_env.reset(seed=seed)\n",
    "env.reset(seed=seed)\n",
    "# np.random.seed(seed)\n",
    "# random.seed(seed)\n",
    "\n",
    "error_magnitudes_cos1 = []\n",
    "error_magnitudes_cos2 = []\n",
    "error_magnitudes_sin1 = []\n",
    "error_magnitudes_sin2 = []\n",
    "error_magnitudes_omega1 = []\n",
    "error_magnitudes_omega2 = []\n",
    "error_magnitudes_xdist = []\n",
    "error_magnitudes_ydist = []\n",
    "\n",
    "env_cos1 = []\n",
    "env_cos2 = []\n",
    "env_sin1 = []\n",
    "env_sin2 = []\n",
    "env_omega1 = []\n",
    "env_omega2 = []\n",
    "env_xdist = []\n",
    "env_ydist = []\n",
    "\n",
    "pred_cos1 = []\n",
    "pred_cos2 = []\n",
    "pred_sin1 = []\n",
    "pred_sin2 = []\n",
    "pred_omega1 = []\n",
    "pred_omega2 = []\n",
    "pred_xdist = []\n",
    "pred_ydist = []\n",
    "\n",
    "pred_cos1_bottom_1std = []\n",
    "pred_cos1_top_1std = []\n",
    "pred_cos1_bottom_2std = []\n",
    "pred_cos1_top_2std = []\n",
    "\n",
    "pred_cos2_bottom_1std = []\n",
    "pred_cos2_top_1std = []\n",
    "pred_cos2_bottom_2std = []\n",
    "pred_cos2_top_2std = []\n",
    "\n",
    "pred_sin1_bottom_1std = []\n",
    "pred_sin1_top_1std = []\n",
    "pred_sin1_bottom_2std = []\n",
    "pred_sin1_top_2std = []\n",
    "\n",
    "pred_sin2_bottom_1std = []\n",
    "pred_sin2_top_1std = []\n",
    "pred_sin2_bottom_2std = []\n",
    "pred_sin2_top_2std = []\n",
    "\n",
    "pred_omega1_bottom_1std = []\n",
    "pred_omega1_top_1std = []\n",
    "pred_omega1_bottom_2std = []\n",
    "pred_omega1_top_2std = []\n",
    "\n",
    "pred_omega2_bottom_1std = []\n",
    "pred_omega2_top_1std = []\n",
    "pred_omega2_bottom_2std = []\n",
    "pred_omega2_top_2std = []\n",
    "\n",
    "pred_xdist_bottom_1std = []\n",
    "pred_xdist_top_1std = []\n",
    "pred_xdist_bottom_2std = []\n",
    "pred_xdist_top_2std = []\n",
    "\n",
    "pred_ydist_bottom_1std = []\n",
    "pred_ydist_top_1std = []\n",
    "pred_ydist_bottom_2std = []\n",
    "pred_ydist_top_2std = []\n",
    "\n",
    "# quantile 0 data\n",
    "quantile0_cos1 = []\n",
    "quantile0_cos2 = []\n",
    "quantile0_sin1 = []\n",
    "quantile0_sin2 = []\n",
    "quantile0_omega1 = []\n",
    "quantile0_omega2 = []\n",
    "quantile0_xdist = []\n",
    "quantile0_ydist = []\n",
    "\n",
    "# quantile 1 data\n",
    "quantile1_cos1 = []\n",
    "quantile1_cos2 = []\n",
    "quantile1_sin1 = []\n",
    "quantile1_sin2 = []\n",
    "quantile1_omega1 = []\n",
    "quantile1_omega2 = []\n",
    "quantile1_xdist = []\n",
    "quantile1_ydist = []\n",
    "\n",
    "# quantile 2 data\n",
    "quantile2_cos1 = []\n",
    "quantile2_cos2 = []\n",
    "quantile2_sin1 = []\n",
    "quantile2_sin2 = []\n",
    "quantile2_omega1 = []\n",
    "quantile2_omega2 = []\n",
    "quantile2_xdist = []\n",
    "quantile2_ydist = []\n",
    "\n",
    "# quantile 3 data\n",
    "quantile3_cos1 = []\n",
    "quantile3_cos2 = []\n",
    "quantile3_sin1 = []\n",
    "quantile3_sin2 = []\n",
    "quantile3_omega1 = []\n",
    "quantile3_omega2 = []\n",
    "quantile3_xdist = []\n",
    "quantile3_ydist = []\n",
    "\n",
    "# quantile 4 data\n",
    "quantile4_cos1 = []\n",
    "quantile4_cos2 = []\n",
    "quantile4_sin1 = []\n",
    "quantile4_sin2 = []\n",
    "quantile4_omega1 = []\n",
    "quantile4_omega2 = []\n",
    "quantile4_xdist = []\n",
    "quantile4_ydist = []\n",
    "\n",
    "# quantile 5 data\n",
    "quantile5_cos1 = []\n",
    "quantile5_cos2 = []\n",
    "quantile5_sin1 = []\n",
    "quantile5_sin2 = []\n",
    "quantile5_omega1 = []\n",
    "quantile5_omega2 = []\n",
    "quantile5_xdist = []\n",
    "quantile5_ydist = []\n",
    "\n",
    "# quantile 6 data\n",
    "quantile6_cos1 = []\n",
    "quantile6_cos2 = []\n",
    "quantile6_sin1 = []\n",
    "quantile6_sin2 = []\n",
    "quantile6_omega1 = []\n",
    "quantile6_omega2 = []\n",
    "quantile6_xdist = []\n",
    "quantile6_ydist = []\n",
    "\n",
    "# quantile 7 data\n",
    "quantile7_cos1 = []\n",
    "quantile7_cos2 = []\n",
    "quantile7_sin1 = []\n",
    "quantile7_sin2 = []\n",
    "quantile7_omega1 = []\n",
    "quantile7_omega2 = []\n",
    "quantile7_xdist = []\n",
    "quantile7_ydist = []\n",
    "\n",
    "# quantile 8 data\n",
    "quantile8_cos1 = []\n",
    "quantile8_cos2 = []\n",
    "quantile8_sin1 = []\n",
    "quantile8_sin2 = []\n",
    "quantile8_omega1 = []\n",
    "quantile8_omega2 = []\n",
    "quantile8_xdist = []\n",
    "quantile8_ydist = []\n",
    "\n",
    "# quantile 9 data\n",
    "quantile9_cos1 = []\n",
    "quantile9_cos2 = []\n",
    "quantile9_sin1 = []\n",
    "quantile9_sin2 = []\n",
    "quantile9_omega1 = []\n",
    "quantile9_omega2 = []\n",
    "quantile9_xdist = []\n",
    "quantile9_ydist = []\n",
    "\n",
    "# quantile 10 data\n",
    "quantile10_cos1 = []\n",
    "quantile10_cos2 = []\n",
    "quantile10_sin1 = []\n",
    "quantile10_sin2 = []\n",
    "quantile10_omega1 = []\n",
    "quantile10_omega2 = []\n",
    "quantile10_xdist = []\n",
    "quantile10_ydist = []\n",
    "\n",
    "\n",
    "actions_lows = env.action_space.low#[:3]\n",
    "actions_highs = env.action_space.high#[:3]\n",
    "# states_low = env.observation_space['observation'].low#[:3]\n",
    "# states_high = env.observation_space['observation'].high#[:3]\n",
    "state_dim = 8\n",
    "action_dim = len(actions_lows)\n",
    "\n",
    "# # Hyperparameters\n",
    "# state_dim = len(states_low)\n",
    "# action_dim = len(actions_low)\n",
    "# Define your quantiles (e.g., 0.1, 0.3, 0.7, 0.9)\n",
    "# quantiles = torch.tensor([0.1, 0.3, 0.7, 0.9], dtype=torch.float32)\n",
    "quantiles = torch.tensor(np.array([0.0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]), dtype=torch.float32)\n",
    "\n",
    "# num_quantiles = 4  # Example with 4 quantiles\n",
    "num_quantiles = len(quantiles)\n",
    "\n",
    "# Initialize the Next-State Prediction Network\n",
    "model = NextStateQuantileNetwork(state_dim, action_dim, num_quantiles)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Experience replay buffer\n",
    "replay_buffer = []\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# usingEnv = True\n",
    "usingEnv = False\n",
    "\n",
    "# print(\"actions_low \", actions_low, \"\\n\")\n",
    "# print(\"actions_high \", actions_high, \"\\n\")\n",
    "\n",
    "# Initialization\n",
    "# num_particles = 20 #100#0 # 20 # 100\n",
    "# particles = [np.random.uniform(-actions_low[0], actions_high[0], 3*horizon) for _ in range(num_particles)] # 2*horizon_list[0]\n",
    "# num_samples = 5\n",
    "# noise_scale = 0.1\n",
    "\n",
    "\n",
    "# Run the simulation\n",
    "# rewards = start()\n",
    "\n",
    "# Main env loop\n",
    "# for rollout, horizon in zip(rollout_list, horizon_list):\n",
    "episode_reward_list = []\n",
    "\n",
    "num_test_steps = 20000\n",
    "state, _ = env.reset(seed=seed)\n",
    "episode_reward = 0\n",
    "actions_list = []\n",
    "done = False\n",
    "truncated = False\n",
    "\n",
    "# goal_state = state['desired_goal'] # 3 components\n",
    "# state = state['observation']#[:3] # 6 components\n",
    "\n",
    "goal_state = np.array([state[4], state[5]])\n",
    "state = np.array([state[0], state[1], state[2], state[3], state[6], state[7], state[8], state[9]])\n",
    "\n",
    "for step in range(num_test_steps):\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    episode_reward += reward\n",
    "    # next_state = next_state['observation']#[:3] # env.state\n",
    "    goal_state = np.array([next_state[4], next_state[5]])\n",
    "    next_state = np.array([next_state[0], next_state[1], next_state[2], next_state[3], next_state[6], next_state[7], next_state[8], next_state[9]])\n",
    "    \n",
    "    if step >= 1:\n",
    "        # test_env = env.copy()\n",
    "        # test_action = test_env.action_space.sample()\n",
    "        # test_next_state, _, _, _, _ = test_env.step(test_action)\n",
    "        # test_next_state = test_next_state['observation'][:3]\n",
    "        \n",
    "        test_next_state = torch.tensor(next_state, dtype=torch.float32)\n",
    "        # print(\"test_next_state \", test_next_state, \"\\n\")\n",
    "        \n",
    "        test_action = torch.tensor(action, dtype=torch.float32)#.unsqueeze(1)  # Example action\n",
    "        test_state = torch.tensor(state, dtype=torch.float32)#.reshape(1, -1)\n",
    "        # Predict next state quantiles\n",
    "        predicted_quantiles = model(test_state, test_action)  # Shape: (1, num_quantiles, state_dim)\n",
    "        lower_quantile = predicted_quantiles[:, 0, :]  # Shape: (1, state_dim)\n",
    "        mid_quantile = predicted_quantiles[:, int(num_quantiles/2), :].detach().numpy()  # Shape: (1, state_dim)\n",
    "        upper_quantile = predicted_quantiles[:, -1, :]  # Shape: (1, state_dim)\n",
    "        # print(\"predicted_quantiles \", predicted_quantiles, \"\\n\")\n",
    "        # print(\"Lower Quantile:\", lower_quantile, \"\\n\")\n",
    "        # print(\"Mid Quantile:\", mid_quantile, \"\\n\")\n",
    "        # print(\"Upper Quantile:\", upper_quantile, \"\\n\")\n",
    "        \n",
    "        pred_cos1 = np.append(pred_cos1, mid_quantile[0][0])\n",
    "        pred_cos2 = np.append(pred_cos2, mid_quantile[0][1])\n",
    "        pred_sin1 = np.append(pred_sin1, mid_quantile[0][2])\n",
    "        pred_sin2 = np.append(pred_sin2, mid_quantile[0][3])\n",
    "        pred_omega1 = np.append(pred_omega1, mid_quantile[0][4])\n",
    "        pred_omega2 = np.append(pred_omega2, mid_quantile[0][5])\n",
    "        pred_xdist = np.append(pred_xdist, mid_quantile[0][6])\n",
    "        pred_ydist = np.append(pred_ydist, mid_quantile[0][7])\n",
    "    \n",
    "        # Quantile 0 data\n",
    "        quantile0_cos1 = np.append(quantile0_cos1, predicted_quantiles[0][0][0].item())\n",
    "        quantile0_cos2 = np.append(quantile0_cos2, predicted_quantiles[0][0][1].item())\n",
    "        quantile0_sin1 = np.append(quantile0_sin1, predicted_quantiles[0][0][2].item())\n",
    "        quantile0_sin2 = np.append(quantile0_sin2, predicted_quantiles[0][0][3].item())\n",
    "        quantile0_omega1 = np.append(quantile0_omega1, predicted_quantiles[0][0][4].item())\n",
    "        quantile0_omega2 = np.append(quantile0_omega2, predicted_quantiles[0][0][5].item())\n",
    "        quantile0_xdist = np.append(quantile0_xdist, predicted_quantiles[0][0][6].item())\n",
    "        quantile0_ydist = np.append(quantile0_ydist, predicted_quantiles[0][0][7].item())\n",
    "        \n",
    "        # Quantile 1 data\n",
    "        quantile1_cos1 = np.append(quantile1_cos1, predicted_quantiles[0][1][0].item())\n",
    "        quantile1_cos2 = np.append(quantile1_cos2, predicted_quantiles[0][1][1].item())\n",
    "        quantile1_sin1 = np.append(quantile1_sin1, predicted_quantiles[0][1][2].item())\n",
    "        quantile1_sin2 = np.append(quantile1_sin2, predicted_quantiles[0][1][3].item())\n",
    "        quantile1_omega1 = np.append(quantile1_omega1, predicted_quantiles[0][1][4].item())\n",
    "        quantile1_omega2 = np.append(quantile1_omega2, predicted_quantiles[0][1][5].item())\n",
    "        quantile1_xdist = np.append(quantile1_xdist, predicted_quantiles[0][1][6].item())\n",
    "        quantile1_ydist = np.append(quantile1_ydist, predicted_quantiles[0][1][7].item())\n",
    "        \n",
    "        # Quantile 2 data\n",
    "        quantile2_cos1 = np.append(quantile2_cos1, predicted_quantiles[0][2][0].item())\n",
    "        quantile2_cos2 = np.append(quantile2_cos2, predicted_quantiles[0][2][1].item())\n",
    "        quantile2_sin1 = np.append(quantile2_sin1, predicted_quantiles[0][2][2].item())\n",
    "        quantile2_sin2 = np.append(quantile2_sin2, predicted_quantiles[0][2][3].item())\n",
    "        quantile2_omega1 = np.append(quantile2_omega1, predicted_quantiles[0][2][4].item())\n",
    "        quantile2_omega2 = np.append(quantile2_omega2, predicted_quantiles[0][2][5].item())\n",
    "        quantile2_xdist = np.append(quantile2_xdist, predicted_quantiles[0][2][6].item())\n",
    "        quantile2_ydist = np.append(quantile2_ydist, predicted_quantiles[0][2][7].item())\n",
    "        \n",
    "        # Quantile 3 data\n",
    "        quantile3_cos1 = np.append(quantile3_cos1, predicted_quantiles[0][3][0].item())\n",
    "        quantile3_cos2 = np.append(quantile3_cos2, predicted_quantiles[0][3][1].item())\n",
    "        quantile3_sin1 = np.append(quantile3_sin1, predicted_quantiles[0][3][2].item())\n",
    "        quantile3_sin2 = np.append(quantile3_sin2, predicted_quantiles[0][3][3].item())\n",
    "        quantile3_omega1 = np.append(quantile3_omega1, predicted_quantiles[0][3][4].item())\n",
    "        quantile3_omega2 = np.append(quantile3_omega2, predicted_quantiles[0][3][5].item())\n",
    "        quantile3_xdist = np.append(quantile3_xdist, predicted_quantiles[0][3][6].item())\n",
    "        quantile3_ydist = np.append(quantile3_ydist, predicted_quantiles[0][3][7].item())\n",
    "        \n",
    "        # Quantile 4 data\n",
    "        quantile4_cos1 = np.append(quantile4_cos1, predicted_quantiles[0][4][0].item())\n",
    "        quantile4_cos2 = np.append(quantile4_cos2, predicted_quantiles[0][4][1].item())\n",
    "        quantile4_sin1 = np.append(quantile4_sin1, predicted_quantiles[0][4][2].item())\n",
    "        quantile4_sin2 = np.append(quantile4_sin2, predicted_quantiles[0][4][3].item())\n",
    "        quantile4_omega1 = np.append(quantile4_omega1, predicted_quantiles[0][4][4].item())\n",
    "        quantile4_omega2 = np.append(quantile4_omega2, predicted_quantiles[0][4][5].item())\n",
    "        quantile4_xdist = np.append(quantile4_xdist, predicted_quantiles[0][4][6].item())\n",
    "        quantile4_ydist = np.append(quantile4_ydist, predicted_quantiles[0][4][7].item())\n",
    "        \n",
    "        # Quantile 5 data\n",
    "        quantile5_cos1 = np.append(quantile5_cos1, predicted_quantiles[0][5][0].item())\n",
    "        quantile5_cos2 = np.append(quantile5_cos2, predicted_quantiles[0][5][1].item())\n",
    "        quantile5_sin1 = np.append(quantile5_sin1, predicted_quantiles[0][5][2].item())\n",
    "        quantile5_sin2 = np.append(quantile5_sin2, predicted_quantiles[0][5][3].item())\n",
    "        quantile5_omega1 = np.append(quantile5_omega1, predicted_quantiles[0][5][4].item())\n",
    "        quantile5_omega2 = np.append(quantile5_omega2, predicted_quantiles[0][5][5].item())\n",
    "        quantile5_xdist = np.append(quantile5_xdist, predicted_quantiles[0][5][6].item())\n",
    "        quantile5_ydist = np.append(quantile5_ydist, predicted_quantiles[0][5][7].item())\n",
    "        \n",
    "        # Quantile 6 data\n",
    "        quantile6_cos1 = np.append(quantile6_cos1, predicted_quantiles[0][6][0].item())\n",
    "        quantile6_cos2 = np.append(quantile6_cos2, predicted_quantiles[0][6][1].item())\n",
    "        quantile6_sin1 = np.append(quantile6_sin1, predicted_quantiles[0][6][2].item())\n",
    "        quantile6_sin2 = np.append(quantile6_sin2, predicted_quantiles[0][6][3].item())\n",
    "        quantile6_omega1 = np.append(quantile6_omega1, predicted_quantiles[0][6][4].item())\n",
    "        quantile6_omega2 = np.append(quantile6_omega2, predicted_quantiles[0][6][5].item())\n",
    "        quantile6_xdist = np.append(quantile6_xdist, predicted_quantiles[0][6][6].item())\n",
    "        quantile6_ydist = np.append(quantile6_ydist, predicted_quantiles[0][6][7].item())\n",
    "        \n",
    "        # Quantile 7 data\n",
    "        quantile7_cos1 = np.append(quantile7_cos1, predicted_quantiles[0][7][0].item())\n",
    "        quantile7_cos2 = np.append(quantile7_cos2, predicted_quantiles[0][7][1].item())\n",
    "        quantile7_sin1 = np.append(quantile7_sin1, predicted_quantiles[0][7][2].item())\n",
    "        quantile7_sin2 = np.append(quantile7_sin2, predicted_quantiles[0][7][3].item())\n",
    "        quantile7_omega1 = np.append(quantile7_omega1, predicted_quantiles[0][7][4].item())\n",
    "        quantile7_omega2 = np.append(quantile7_omega2, predicted_quantiles[0][7][5].item())\n",
    "        quantile7_xdist = np.append(quantile7_xdist, predicted_quantiles[0][7][6].item())\n",
    "        quantile7_ydist = np.append(quantile7_ydist, predicted_quantiles[0][7][7].item())\n",
    "        \n",
    "        # Quantile 8 data\n",
    "        quantile8_cos1 = np.append(quantile8_cos1, predicted_quantiles[0][8][0].item())\n",
    "        quantile8_cos2 = np.append(quantile8_cos2, predicted_quantiles[0][8][1].item())\n",
    "        quantile8_sin1 = np.append(quantile8_sin1, predicted_quantiles[0][8][2].item())\n",
    "        quantile8_sin2 = np.append(quantile8_sin2, predicted_quantiles[0][8][3].item())\n",
    "        quantile8_omega1 = np.append(quantile8_omega1, predicted_quantiles[0][8][4].item())\n",
    "        quantile8_omega2 = np.append(quantile8_omega2, predicted_quantiles[0][8][5].item())\n",
    "        quantile8_xdist = np.append(quantile8_xdist, predicted_quantiles[0][8][6].item())\n",
    "        quantile8_ydist = np.append(quantile8_ydist, predicted_quantiles[0][8][7].item())\n",
    "        \n",
    "        # Quantile 9 data\n",
    "        quantile9_cos1 = np.append(quantile9_cos1, predicted_quantiles[0][9][0].item())\n",
    "        quantile9_cos2 = np.append(quantile9_cos2, predicted_quantiles[0][9][1].item())\n",
    "        quantile9_sin1 = np.append(quantile9_sin1, predicted_quantiles[0][9][2].item())\n",
    "        quantile9_sin2 = np.append(quantile9_sin2, predicted_quantiles[0][9][3].item())\n",
    "        quantile9_omega1 = np.append(quantile9_omega1, predicted_quantiles[0][9][4].item())\n",
    "        quantile9_omega2 = np.append(quantile9_omega2, predicted_quantiles[0][9][5].item())\n",
    "        quantile9_xdist = np.append(quantile9_xdist, predicted_quantiles[0][9][6].item())\n",
    "        quantile9_ydist = np.append(quantile9_ydist, predicted_quantiles[0][9][7].item())\n",
    "        \n",
    "        # Quantile 10 data\n",
    "        quantile10_cos1 = np.append(quantile10_cos1, predicted_quantiles[0][10][0].item())\n",
    "        quantile10_cos2 = np.append(quantile10_cos2, predicted_quantiles[0][10][1].item())\n",
    "        quantile10_sin1 = np.append(quantile10_sin1, predicted_quantiles[0][10][2].item())\n",
    "        quantile10_sin2 = np.append(quantile10_sin2, predicted_quantiles[0][10][3].item())\n",
    "        quantile10_omega1 = np.append(quantile10_omega1, predicted_quantiles[0][10][4].item())\n",
    "        quantile10_omega2 = np.append(quantile10_omega2, predicted_quantiles[0][10][5].item())\n",
    "        quantile10_xdist = np.append(quantile10_xdist, predicted_quantiles[0][10][6].item())\n",
    "        quantile10_ydist = np.append(quantile10_ydist, predicted_quantiles[0][10][7].item())\n",
    "        \n",
    "        delta_cos1 = test_next_state[0] - mid_quantile[0][0]\n",
    "        delta_cos2 = test_next_state[1] - mid_quantile[0][1]\n",
    "        delta_sin1 = test_next_state[2] - mid_quantile[0][2]\n",
    "        delta_sin2 = test_next_state[3] - mid_quantile[0][3]\n",
    "        delta_omega1 = test_next_state[4] - mid_quantile[0][4]\n",
    "        delta_omega2 = test_next_state[5] - mid_quantile[0][5]\n",
    "        delta_xdist = test_next_state[6] - mid_quantile[0][6]\n",
    "        delta_ydist = test_next_state[7] - mid_quantile[0][7]\n",
    "        \n",
    "        error_magnitudes_cos1.append(np.abs(delta_cos1)) # .detach().numpy()\n",
    "        error_magnitudes_cos2.append(np.abs(delta_cos2)) # .detach().numpy()\n",
    "        error_magnitudes_sin1.append(np.abs(delta_sin1)) # .detach().numpy()\n",
    "        error_magnitudes_sin2.append(np.abs(delta_sin2)) # .detach().numpy()\n",
    "        error_magnitudes_omega1.append(np.abs(delta_omega1)) # .detach().numpy()\n",
    "        error_magnitudes_omega2.append(np.abs(delta_omega2)) # .detach().numpy()\n",
    "        error_magnitudes_xdist.append(np.abs(delta_xdist)) # .detach().numpy()\n",
    "        error_magnitudes_ydist.append(np.abs(delta_ydist)) # .detach().numpy()\n",
    "        \n",
    "        env_cos1.append(test_next_state[0])\n",
    "        env_cos2.append(test_next_state[1])\n",
    "        env_sin1.append(test_next_state[2])\n",
    "        env_sin2.append(test_next_state[3])\n",
    "        env_omega1.append(test_next_state[4])\n",
    "        env_omega2.append(test_next_state[5])\n",
    "        env_xdist.append(test_next_state[6])\n",
    "        env_ydist.append(test_next_state[7])\n",
    "    \n",
    "    # next_state = env.state.copy()\n",
    "    # Store experience in replay buffer\n",
    "    replay_buffer.append((state, action, reward, next_state, done))\n",
    "    if len(replay_buffer) < batch_size:\n",
    "        pass\n",
    "    else:\n",
    "        batch = random.sample(replay_buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        states = torch.tensor(states, dtype=torch.float32)\n",
    "        actions = torch.tensor(actions, dtype=torch.float32)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "        next_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "        dones = torch.tensor(dones, dtype=torch.float32)\n",
    "        \n",
    "        # Predict next state quantiles\n",
    "        predicted_quantiles = model(states, actions)  # Shape: (batch_size, num_quantiles, state_dim)\n",
    "        \n",
    "        # Use next state as target (can be improved with target policy)\n",
    "        target_quantiles = next_states\n",
    "        \n",
    "        # Compute the target quantiles (e.g., replicate next state across the quantile dimension)\n",
    "        # target_quantiles = next_states.unsqueeze(-1).repeat(1, 1, num_quantiles)\n",
    "\n",
    "        # Compute Quantile Huber Loss\n",
    "        loss = quantile_huber_loss(predicted_quantiles, target_quantiles, quantiles)\n",
    "\n",
    "        \n",
    "        # Compute Quantile Huber Loss\n",
    "        loss = quantile_huber_loss(predicted_quantiles, target_quantiles, quantiles)\n",
    "        \n",
    "        # Optimize the model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    state = next_state\n",
    "\n",
    "    if done or truncated:\n",
    "        state, _ = env.reset(seed=seed)\n",
    "        episode_reward = 0\n",
    "        actions_list = []\n",
    "        done = False\n",
    "        truncated = False\n",
    "        \n",
    "        goal_state = np.array([state[4], state[5]])\n",
    "        state = np.array([state[0], state[1], state[2], state[3], state[6], state[7], state[8], state[9]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot the rewards\n",
    "# plt.figure(1)\n",
    "# # plt.legend()\n",
    "# # plt.grid()\n",
    "# plt.plot(episode_reward_list)\n",
    "# plt.xlabel('Nb of episodes')\n",
    "# plt.ylabel('episode reward')\n",
    "# # plt.title('MPC_Pendulum with Optimized Action Sequences')\n",
    "# # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\Graphs\\\\episode_rewards_withCPUforQRNN_{timestamp}.png')\n",
    "# # # plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\episode_rewards_withGPUforGP_{timestamp}.png')\n",
    "# plt.yscale('log')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.plot(error_magnitudes_cos1)\n",
    "plt.ylabel('error_magnitudes_cos1')\n",
    "# plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_1_{timestamp}.png')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure(3)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.plot(error_magnitudes_cos2)\n",
    "plt.ylabel('error_magnitudes_cos2')\n",
    "# plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_2_{timestamp}.png')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure(4)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.plot(error_magnitudes_sin1)\n",
    "plt.ylabel('error_magnitudes_sin1')\n",
    "# plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_1_{timestamp}.png')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure(5)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.plot(error_magnitudes_sin2)\n",
    "plt.ylabel('error_magnitudes_sin2')\n",
    "# plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_2_{timestamp}.png')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure(6)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.plot(error_magnitudes_omega1)\n",
    "plt.ylabel('error_magnitudes_omega1')\n",
    "# plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_1_{timestamp}.png')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure(7)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.plot(error_magnitudes_omega2)\n",
    "plt.ylabel('error_magnitudes_omega2')\n",
    "# plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_2_{timestamp}.png')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure(8)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.plot(error_magnitudes_xdist)\n",
    "plt.ylabel('error_magnitudes_xdist')\n",
    "# plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_1_{timestamp}.png')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure(9)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.plot(error_magnitudes_ydist)\n",
    "plt.ylabel('error_magnitudes_ydist')\n",
    "# plt.title('Error magnitude btw env.state and GP predicted state per step')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\error_magnitudes_2_{timestamp}.png')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure(10)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.ylabel('cos1 comparison between env and QRNN')\n",
    "plt.plot(env_cos1, label='env_next_states')\n",
    "plt.plot(pred_cos1, label='pred_next_states')\n",
    "# plt.fill_between(np.arange(len(pred_x)), pred_x - pred_x_bottom_1std, pred_x + pred_x_top_2std, alpha=0.5, label='1 std', color='green')\n",
    "# plt.fill_between(np.arange(len(pred_x)), pred_x - pred_x_bottom_2std, pred_x + pred_x_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\angles_comparison_GP_env_{timestamp}.png')\n",
    "# plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(11)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.ylabel('cos2 comparison between env and QRNN')\n",
    "plt.plot(env_cos2, label='env_next_states')\n",
    "plt.plot(pred_cos2, label='pred_next_states')\n",
    "# plt.fill_between(np.arange(len(pred_y)), pred_y - pred_y_bottom_1std, pred_y + pred_y_top_1std, alpha=0.5, label='1 std', color='green')\n",
    "# plt.fill_between(np.arange(len(pred_y)), pred_y - pred_y_bottom_2std, pred_y + pred_y_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\omegas_comparison_GP_env_{timestamp}.png')\n",
    "# plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(12)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.ylabel('sin1 comparison between env and QRNN')\n",
    "plt.plot(env_sin1, label='env_next_states')\n",
    "plt.plot(pred_sin1, label='pred_next_states')\n",
    "# plt.fill_between(np.arange(len(pred_x)), pred_x - pred_x_bottom_1std, pred_x + pred_x_top_2std, alpha=0.5, label='1 std', color='green')\n",
    "# plt.fill_between(np.arange(len(pred_x)), pred_x - pred_x_bottom_2std, pred_x + pred_x_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\angles_comparison_GP_env_{timestamp}.png')\n",
    "# plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(13)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.ylabel('sin2 comparison between env and QRNN')\n",
    "plt.plot(env_sin2, label='env_next_states')\n",
    "plt.plot(pred_sin2, label='pred_next_states')\n",
    "# plt.fill_between(np.arange(len(pred_y)), pred_y - pred_y_bottom_1std, pred_y + pred_y_top_1std, alpha=0.5, label='1 std', color='green')\n",
    "# plt.fill_between(np.arange(len(pred_y)), pred_y - pred_y_bottom_2std, pred_y + pred_y_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\omegas_comparison_GP_env_{timestamp}.png')\n",
    "# plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(14)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.ylabel('omega1 comparison between env and QRNN')\n",
    "plt.plot(env_omega1, label='env_next_states')\n",
    "plt.plot(pred_omega1, label='pred_next_states')\n",
    "# plt.fill_between(np.arange(len(pred_x)), pred_x - pred_x_bottom_1std, pred_x + pred_x_top_2std, alpha=0.5, label='1 std', color='green')\n",
    "# plt.fill_between(np.arange(len(pred_x)), pred_x - pred_x_bottom_2std, pred_x + pred_x_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\angles_comparison_GP_env_{timestamp}.png')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(15)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.ylabel('omega2 comparison between env and QRNN')\n",
    "plt.plot(env_omega2, label='env_next_states')\n",
    "plt.plot(pred_omega2, label='pred_next_states')\n",
    "# plt.fill_between(np.arange(len(pred_y)), pred_y - pred_y_bottom_1std, pred_y + pred_y_top_1std, alpha=0.5, label='1 std', color='green')\n",
    "# plt.fill_between(np.arange(len(pred_y)), pred_y - pred_y_bottom_2std, pred_y + pred_y_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\omegas_comparison_GP_env_{timestamp}.png')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(16)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.ylabel('xdist comparison between env and QRNN')\n",
    "plt.plot(env_xdist, label='env_next_states')\n",
    "plt.plot(pred_xdist, label='pred_next_states')\n",
    "# plt.fill_between(np.arange(len(pred_x)), pred_x - pred_x_bottom_1std, pred_x + pred_x_top_2std, alpha=0.5, label='1 std', color='green')\n",
    "# plt.fill_between(np.arange(len(pred_x)), pred_x - pred_x_bottom_2std, pred_x + pred_x_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\angles_comparison_GP_env_{timestamp}.png')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(17)\n",
    "plt.xlabel('Nb of steps')\n",
    "plt.ylabel('ydist comparison between env and QRNN')\n",
    "plt.plot(env_ydist, label='env_next_states')\n",
    "plt.plot(pred_ydist, label='pred_next_states')\n",
    "# plt.fill_between(np.arange(len(pred_y)), pred_y - pred_y_bottom_1std, pred_y + pred_y_top_1std, alpha=0.5, label='1 std', color='green')\n",
    "# plt.fill_between(np.arange(len(pred_y)), pred_y - pred_y_bottom_2std, pred_y + pred_y_top_2std, alpha=0.5, label='2 std', color='red')\n",
    "# plt.savefig(f'C:\\\\Users\\\\nicle\\\\Desktop\\\\GPBO-MBRL\\\\GP-MPC_NL\\\\PF_MPC_GP_Env\\\\ParallelOverParticles\\\\omegas_comparison_GP_env_{timestamp}.png')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph of number of values below the different quantiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(quantile0_cos1), len(quantile1_cos1), len(quantile2_cos1), len(quantile0_sin2), len(quantile0_omega1), len(quantile0_omega2), len(quantile0_xdist), len(quantile0_ydist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cos1 \n",
    "variable = \"cos1\"\n",
    "nb_belowq1_list_cos1, nb_below_q2_list_cos1, nb_below_q3_list_cos1, nb_below_q4_list_cos1, nb_below_q5_list_cos1, nb_below_q6_list_cos1, nb_below_q7_list_cos1, nb_below_q8_list_cos1, nb_below_q9_list_cos1, nb_below_q10_list_cos1 = nb_below_quantile(env_cos1, quantile0_cos1, quantile1_cos1, quantile2_cos1, quantile3_cos1, quantile4_cos1, quantile5_cos1, quantile6_cos1, quantile7_cos1, quantile8_cos1, quantile9_cos1, quantile10_cos1)\n",
    "plot_nb_below_quantiles(nb_belowq1_list_cos1, nb_below_q2_list_cos1, nb_below_q3_list_cos1, nb_below_q4_list_cos1, nb_below_q5_list_cos1, nb_below_q6_list_cos1, nb_below_q7_list_cos1, nb_below_q8_list_cos1, nb_below_q9_list_cos1, nb_below_q10_list_cos1, variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cos2\n",
    "variable = \"cos2\"\n",
    "nb_belowq1_list_cos2, nb_below_q2_list_cos2, nb_below_q3_list_cos2, nb_below_q4_list_cos2, nb_below_q5_list_cos2, nb_below_q6_list_cos2, nb_below_q7_list_cos2, nb_below_q8_list_cos2, nb_below_q9_list_cos2, nb_below_q10_list_cos2 = nb_below_quantile(env_cos2, quantile0_cos2, quantile1_cos2, quantile2_cos2, quantile3_cos2, quantile4_cos2, quantile5_cos2, quantile6_cos2, quantile7_cos2, quantile8_cos2, quantile9_cos2, quantile10_cos2)\n",
    "plot_nb_below_quantiles(nb_belowq1_list_cos2, nb_below_q2_list_cos2, nb_below_q3_list_cos2, nb_below_q4_list_cos2, nb_below_q5_list_cos2, nb_below_q6_list_cos2, nb_below_q7_list_cos2, nb_below_q8_list_cos2, nb_below_q9_list_cos2, nb_below_q10_list_cos2, variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sin1\n",
    "variable = \"sin1\"\n",
    "nb_belowq1_list_sin1, nb_below_q2_list_sin1, nb_below_q3_list_sin1, nb_below_q4_list_sin1, nb_below_q5_list_sin1, nb_below_q6_list_sin1, nb_below_q7_list_sin1, nb_below_q8_list_sin1, nb_below_q9_list_sin1, nb_below_q10_list_sin1 = nb_below_quantile(env_sin1, quantile0_sin1, quantile1_sin1, quantile2_sin1, quantile3_sin1, quantile4_sin1, quantile5_sin1, quantile6_sin1, quantile7_sin1, quantile8_sin1, quantile9_sin1, quantile10_sin1)\n",
    "plot_nb_below_quantiles(nb_belowq1_list_sin1, nb_below_q2_list_sin1, nb_below_q3_list_sin1, nb_below_q4_list_sin1, nb_below_q5_list_sin1, nb_below_q6_list_sin1, nb_below_q7_list_sin1, nb_below_q8_list_sin1, nb_below_q9_list_sin1, nb_below_q10_list_sin1, variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sin2\n",
    "variable = \"sin2\"\n",
    "nb_belowq1_list_sin2, nb_below_q2_list_sin2, nb_below_q3_list_sin2, nb_below_q4_list_sin2, nb_below_q5_list_sin2, nb_below_q6_list_sin2, nb_below_q7_list_sin2, nb_below_q8_list_sin2, nb_below_q9_list_sin2, nb_below_q10_list_sin2 = nb_below_quantile(env_sin2, quantile0_sin2, quantile1_sin2, quantile2_sin2, quantile3_sin2, quantile4_sin2, quantile5_sin2, quantile6_sin2, quantile7_sin2, quantile8_sin2, quantile9_sin2, quantile10_sin2)\n",
    "plot_nb_below_quantiles(nb_belowq1_list_sin2, nb_below_q2_list_sin2, nb_below_q3_list_sin2, nb_below_q4_list_sin2, nb_below_q5_list_sin2, nb_below_q6_list_sin2, nb_below_q7_list_sin2, nb_below_q8_list_sin2, nb_below_q9_list_sin2, nb_below_q10_list_sin2, variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# omega1\n",
    "variable = \"omega1\"\n",
    "nb_belowq1_list_omega1, nb_below_q2_list_omega1, nb_below_q3_list_omega1, nb_below_q4_list_omega1, nb_below_q5_list_omega1, nb_below_q6_list_omega1, nb_below_q7_list_omega1, nb_below_q8_list_omega1, nb_below_q9_list_omega1, nb_below_q10_list_omega1 = nb_below_quantile(env_omega1, quantile0_omega1, quantile1_omega1, quantile2_omega1, quantile3_omega1, quantile4_omega1, quantile5_omega1, quantile6_omega1, quantile7_omega1, quantile8_omega1, quantile9_omega1, quantile10_omega1)\n",
    "plot_nb_below_quantiles(nb_belowq1_list_omega1, nb_below_q2_list_omega1, nb_below_q3_list_omega1, nb_below_q4_list_omega1, nb_below_q5_list_omega1, nb_below_q6_list_omega1, nb_below_q7_list_omega1, nb_below_q8_list_omega1, nb_below_q9_list_omega1, nb_below_q10_list_omega1, variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# omega2\n",
    "variable = \"omega2\"\n",
    "nb_belowq1_list_omega2, nb_below_q2_list_omega2, nb_below_q3_list_omega2, nb_below_q4_list_omega2, nb_below_q5_list_omega2, nb_below_q6_list_omega2, nb_below_q7_list_omega2, nb_below_q8_list_omega2, nb_below_q9_list_omega2, nb_below_q10_list_omega2 = nb_below_quantile(env_omega2, quantile0_omega2, quantile1_omega2, quantile2_omega2, quantile3_omega2, quantile4_omega2, quantile5_omega2, quantile6_omega2, quantile7_omega2, quantile8_omega2, quantile9_omega2, quantile10_omega2)\n",
    "plot_nb_below_quantiles(nb_belowq1_list_omega2, nb_below_q2_list_omega2, nb_below_q3_list_omega2, nb_below_q4_list_omega2, nb_below_q5_list_omega2, nb_below_q6_list_omega2, nb_below_q7_list_omega2, nb_below_q8_list_omega2, nb_below_q9_list_omega2, nb_below_q10_list_omega2, variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xdist\n",
    "variable = \"xdist\"\n",
    "nb_belowq1_list_xdist, nb_below_q2_list_xdist, nb_below_q3_list_xdist, nb_below_q4_list_xdist, nb_below_q5_list_xdist, nb_below_q6_list_xdist, nb_below_q7_list_xdist, nb_below_q8_list_xdist, nb_below_q9_list_xdist, nb_below_q10_list_xdist = nb_below_quantile(env_xdist, quantile0_xdist, quantile1_xdist, quantile2_xdist, quantile3_xdist, quantile4_xdist, quantile5_xdist, quantile6_xdist, quantile7_xdist, quantile8_xdist, quantile9_xdist, quantile10_xdist)\n",
    "plot_nb_below_quantiles(nb_belowq1_list_xdist, nb_below_q2_list_xdist, nb_below_q3_list_xdist, nb_below_q4_list_xdist, nb_below_q5_list_xdist, nb_below_q6_list_xdist, nb_below_q7_list_xdist, nb_below_q8_list_xdist, nb_below_q9_list_xdist, nb_below_q10_list_xdist, variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ydist \n",
    "variable = \"ydist\"\n",
    "nb_belowq1_list_ydist, nb_below_q2_list_ydist, nb_below_q3_list_ydist, nb_below_q4_list_ydist, nb_below_q5_list_ydist, nb_below_q6_list_ydist, nb_below_q7_list_ydist, nb_below_q8_list_ydist, nb_below_q9_list_ydist, nb_below_q10_list_ydist = nb_below_quantile(env_ydist, quantile0_ydist, quantile1_ydist, quantile2_ydist, quantile3_ydist, quantile4_ydist, quantile5_ydist, quantile6_ydist, quantile7_ydist, quantile8_ydist, quantile9_ydist, quantile10_ydist)\n",
    "plot_nb_below_quantiles(nb_belowq1_list_ydist, nb_below_q2_list_ydist, nb_below_q3_list_ydist, nb_below_q4_list_ydist, nb_below_q5_list_ydist, nb_below_q6_list_ydist, nb_below_q7_list_ydist, nb_below_q8_list_ydist, nb_below_q9_list_ydist, nb_below_q10_list_ydist, variable)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
