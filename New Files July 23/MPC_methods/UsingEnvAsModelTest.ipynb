{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6557dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import copy\n",
    "import panda_gym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e855098",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f836d3e6",
   "metadata": {},
   "source": [
    "# Environments that work\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a230d408",
   "metadata": {},
   "source": [
    "## Cart Pole (discrete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d91d8c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.01927434,  0.03158171, -0.01555932, -0.04551618], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1').unwrapped # .unwrapped is used to access the state directly\n",
    "env.reset(seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a102dae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h = 0 \n",
      "\n",
      "i  0 \n",
      "\n",
      "env_i.state  [ 0.01927434  0.03158171 -0.01555932 -0.04551618] \n",
      "\n",
      "next_state  (0.019905971019187348, -0.08655294196659766, -0.016469647869333498, 0.1270900912606458) \n",
      "\n",
      "i  1 \n",
      "\n",
      "env_i.state  [ 0.01927434  0.03158171 -0.01555932 -0.04551618] \n",
      "\n",
      "next_state  (0.019905971019187348, 0.0014594708235263036, -0.016469647869333498, -0.004912547883514723) \n",
      "\n",
      "i  2 \n",
      "\n",
      "env_i.state  [ 0.01927434  0.03158171 -0.01555932 -0.04551618] \n",
      "\n",
      "next_state  (0.019905971019187348, -0.15515744052636463, -0.016469647869333498, 0.22998438287205802) \n",
      "\n",
      "i  3 \n",
      "\n",
      "env_i.state  [ 0.01927434  0.03158171 -0.01555932 -0.04551618] \n",
      "\n",
      "next_state  (0.019905971019187348, -0.06759462778457094, -0.016469647869333498, 0.09865606216841635) \n",
      "\n",
      "i  4 \n",
      "\n",
      "env_i.state  [ 0.01927434  0.03158171 -0.01555932 -0.04551618] \n",
      "\n",
      "next_state  (0.019905971019187348, -0.09673757295243982, -0.016469647869333498, 0.1423651885590966) \n",
      "\n",
      "sim_states tensor([[ 0.0199, -0.0866, -0.0165,  0.1271],\n",
      "        [ 0.0199,  0.0015, -0.0165, -0.0049],\n",
      "        [ 0.0199, -0.1552, -0.0165,  0.2300],\n",
      "        [ 0.0199, -0.0676, -0.0165,  0.0987],\n",
      "        [ 0.0199, -0.0967, -0.0165,  0.1424]]) \n",
      "\n",
      "h = 1 \n",
      "\n",
      "i  0 \n",
      "\n",
      "env_i.state  [ 0.01990597 -0.08655294 -0.01646965  0.1270901 ] \n",
      "\n",
      "next_state  (0.018174912557005884, -0.16966593054263845, -0.013927846178412438, 0.24690081630537308) \n",
      "\n",
      "i  1 \n",
      "\n",
      "env_i.state  [ 0.01990597  0.00145947 -0.01646965 -0.00491255] \n",
      "\n",
      "next_state  (0.01993516077985987, 0.11309306171668833, -0.01656789906322956, -0.1771820818493216) \n",
      "\n",
      "i  2 \n",
      "\n",
      "env_i.state  [ 0.01990597 -0.15515745 -0.01646965  0.22998439] \n",
      "\n",
      "next_state  (0.016802822425961494, -0.09763261182954494, -0.011869960352778434, 0.1388669799770555) \n",
      "\n",
      "i  3 \n",
      "\n",
      "env_i.state  [ 0.01990597 -0.06759463 -0.01646965  0.09865607] \n",
      "\n",
      "next_state  (0.018554078862071038, -0.1835308827686365, -0.014496526792645455, 0.2676950094970805) \n",
      "\n",
      "i  4 \n",
      "\n",
      "env_i.state  [ 0.01990597 -0.09673757 -0.01646965  0.14236519] \n",
      "\n",
      "next_state  (0.017971219941973687, -0.2047818949226598, -0.013622344359755515, 0.29956783584022184) \n",
      "\n",
      "sim_states tensor([[ 0.0182, -0.1697, -0.0139,  0.2469],\n",
      "        [ 0.0199,  0.1131, -0.0166, -0.1772],\n",
      "        [ 0.0168, -0.0976, -0.0119,  0.1389],\n",
      "        [ 0.0186, -0.1835, -0.0145,  0.2677],\n",
      "        [ 0.0180, -0.2048, -0.0136,  0.2996]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "horizon = 2\n",
    "num_particles = 5\n",
    "\n",
    "sim_states = env.state\n",
    "\n",
    "for h in range(horizon):\n",
    "    print(\"h =\", h, \"\\n\")\n",
    "    next_states = []\n",
    "    for i in range(num_particles):\n",
    "        print(\"i \", i, \"\\n\")\n",
    "        if h >0:\n",
    "            env_i = copy.deepcopy(env)  # Assuming prob_vars.env is an environment object with a copy method\n",
    "            env_i.reset(seed=seed)\n",
    "            env_i.state = sim_states[i].numpy()  # Set the initial state of the environment\n",
    "        else: # if h == 0:\n",
    "            env_i = copy.deepcopy(env)  # Assuming prob_vars.env is an environment object with a copy method\n",
    "            env_i.reset(seed=seed)\n",
    "            if isinstance(sim_states, torch.Tensor):\n",
    "                sim_states.detach().cpu().numpy()  # Safely convert to NumPy\n",
    "            env_i.state = sim_states # Set the initial state of the environment\n",
    "        print(\"env_i.state \", env_i.state, \"\\n\")\n",
    "        # print(env_i.step(env_i.action_space.sample()))\n",
    "        action = env_i.action_space.sample()\n",
    "        next_state_step, reward, terminated, truncated, info = env_i.step(action)  # Sample a random action\n",
    "        next_state = env_i.state\n",
    "        print(\"next_state \", next_state, \"\\n\")\n",
    "        next_states.append(next_state)\n",
    "    \n",
    "    next_states = np.clip(next_states, env.observation_space.low, env.observation_space.high)\n",
    "    sim_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "    print(\"sim_states\", sim_states, \"\\n\")\n",
    "    # sim_states = torch.clip(sim_states, env.observation_space.low, env.observation_space.high)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c34cb5",
   "metadata": {},
   "source": [
    "## Cart Pole (continuous)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2ec51120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.01927434,  0.03158171, -0.01555932, -0.04551618]), {})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cartpole_continuous as cartpole_env\n",
    "            \n",
    "env = cartpole_env.CartPoleContinuousEnv(render_mode=\"rgb_array\").unwrapped # .unwrapped is used to access the state directly\n",
    "env.reset(seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d20eb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h = 0 \n",
      "\n",
      "i  0 \n",
      "\n",
      "env_i.state  [ 0.01927434  0.03158171 -0.01555932 -0.04551618] \n",
      "\n",
      "action  [-0.01280423] \n",
      "\n",
      "next_state  (0.019905971019187348, 0.029306441707807725, -0.016469647869333498, -0.046677948153375545) \n",
      "\n",
      "i  1 \n",
      "\n",
      "env_i.state  [ 0.01927434  0.03158171 -0.01555932 -0.04551618] \n",
      "\n",
      "action  [-0.96558434] \n",
      "\n",
      "next_state  (0.019905971019187348, -0.15659857971448876, -0.016469647869333498, 0.23214582999270555) \n",
      "\n",
      "i  2 \n",
      "\n",
      "env_i.state  [ 0.01927434  0.03158171 -0.01555932 -0.04551618] \n",
      "\n",
      "action  [0.77778393] \n",
      "\n",
      "next_state  (0.019905971019187348, 0.18356481323550308, -0.016469647869333498, -0.27803749740574113) \n",
      "\n",
      "i  3 \n",
      "\n",
      "env_i.state  [ 0.01927434  0.03158171 -0.01555932 -0.04551618] \n",
      "\n",
      "action  [-0.10685021] \n",
      "\n",
      "next_state  (0.019905971019187348, 0.01095633163422978, -0.016469647869333498, -0.01915611479477523) \n",
      "\n",
      "i  4 \n",
      "\n",
      "env_i.state  [ 0.01927434  0.03158171 -0.01555932 -0.04551618] \n",
      "\n",
      "action  [0.8319744] \n",
      "\n",
      "next_state  (0.019905971019187348, 0.1941383736310199, -0.016469647869333498, -0.2938959182024383) \n",
      "\n",
      "sim_states tensor([[ 0.0199,  0.0293, -0.0165, -0.0467],\n",
      "        [ 0.0199, -0.1566, -0.0165,  0.2321],\n",
      "        [ 0.0199,  0.1836, -0.0165, -0.2780],\n",
      "        [ 0.0199,  0.0110, -0.0165, -0.0192],\n",
      "        [ 0.0199,  0.1941, -0.0165, -0.2939]]) \n",
      "\n",
      "h = 1 \n",
      "\n",
      "i  0 \n",
      "\n",
      "env_i.state  [ 0.01990597  0.02930644 -0.01646965 -0.04667795] \n",
      "\n",
      "action  [-0.5992337] \n",
      "\n",
      "next_state  (0.020492100194096564, -0.0873787678442336, -0.017403207048773767, 0.12348427184495081) \n",
      "\n",
      "i  1 \n",
      "\n",
      "env_i.state  [ 0.01990597 -0.15659858 -0.01646965  0.23214583] \n",
      "\n",
      "action  [-0.9287022] \n",
      "\n",
      "next_state  (0.016773999705910682, -0.3375698817112167, -0.011826731488108635, 0.49872410619236046) \n",
      "\n",
      "i  2 \n",
      "\n",
      "env_i.state  [ 0.01990597  0.18356481 -0.01646965 -0.2780375 ] \n",
      "\n",
      "action  [-0.4693675] \n",
      "\n",
      "next_state  (0.023577267602086067, 0.09221763562357997, -0.02203039787709713, -0.1458771645972743) \n",
      "\n",
      "i  3 \n",
      "\n",
      "env_i.state  [ 0.01990597  0.01095633 -0.01646965 -0.01915612] \n",
      "\n",
      "action  [-0.09264533] \n",
      "\n",
      "next_state  (0.020125098004937173, -0.0068843015963236665, -0.016852770410478116, 0.0027593483885090253) \n",
      "\n",
      "i  4 \n",
      "\n",
      "env_i.state  [ 0.01990597  0.19413838 -0.01646965 -0.29389593] \n",
      "\n",
      "action  [-0.9535669] \n",
      "\n",
      "next_state  (0.023788738921284677, 0.008314998174522636, -0.022347566708922385, -0.020040520594263866) \n",
      "\n",
      "sim_states tensor([[ 0.0205, -0.0874, -0.0174,  0.1235],\n",
      "        [ 0.0168, -0.3376, -0.0118,  0.4987],\n",
      "        [ 0.0236,  0.0922, -0.0220, -0.1459],\n",
      "        [ 0.0201, -0.0069, -0.0169,  0.0028],\n",
      "        [ 0.0238,  0.0083, -0.0223, -0.0200]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "horizon = 2\n",
    "num_particles = 5\n",
    "\n",
    "sim_states = env.state\n",
    "\n",
    "for h in range(horizon):\n",
    "    print(\"h =\", h, \"\\n\")\n",
    "    next_states = []\n",
    "    for i in range(num_particles):\n",
    "        print(\"i \", i, \"\\n\")\n",
    "        if h >0:\n",
    "            env_i = copy.deepcopy(env)  # Assuming prob_vars.env is an environment object with a copy method\n",
    "            env_i.reset(seed=seed)\n",
    "            env_i.state = sim_states[i].numpy()  # Set the initial state of the environment\n",
    "        else: # if h == 0:\n",
    "            env_i = copy.deepcopy(env)  # Assuming prob_vars.env is an environment object with a copy method\n",
    "            env_i.reset(seed=seed)\n",
    "            if isinstance(sim_states, torch.Tensor):\n",
    "                sim_states.detach().cpu().numpy()  # Safely convert to NumPy\n",
    "            env_i.state = sim_states # Set the initial state of the environment\n",
    "        print(\"env_i.state \", env_i.state, \"\\n\")\n",
    "        # print(env_i.step(env_i.action_space.sample()))\n",
    "        action = env_i.action_space.sample()\n",
    "        next_state_step, reward, terminated, truncated, info = env_i.step(action)  # Sample a random action\n",
    "        next_state = env_i.state\n",
    "        print(\"action \", action, \"\\n\")\n",
    "        print(\"next_state \", next_state, \"\\n\")\n",
    "        next_states.append(next_state)\n",
    "    \n",
    "    next_states = np.clip(next_states, env.observation_space.low, env.observation_space.high)\n",
    "    sim_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "    print(\"sim_states\", sim_states, \"\\n\")\n",
    "    # sim_states = torch.clip(sim_states, env.observation_space.low, env.observation_space.high)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c541c8",
   "metadata": {},
   "source": [
    "## Mountain Car (discrete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "43496d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicle\\anaconda3\\Lib\\site-packages\\gymnasium\\envs\\registration.py:525: UserWarning: \u001b[33mWARN: Using the latest versioned environment `MountainCar-v0` instead of the unversioned environment `MountainCar`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.46145132,  0.        ], dtype=float32), {})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"MountainCar\", render_mode=\"rgb_array\").unwrapped # .unwrapped is used to access the state directly\n",
    "env.reset(seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "07ae7127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h = 0 \n",
      "\n",
      "i  0 \n",
      "\n",
      "env_i.state  [-0.46145133  0.        ] \n",
      "\n",
      "action  1 \n",
      "\n",
      "next_state  (-0.4619147366005067, -0.0004634101935372057) \n",
      "\n",
      "i  1 \n",
      "\n",
      "env_i.state  [-0.46145133  0.        ] \n",
      "\n",
      "action  0 \n",
      "\n",
      "next_state  (-0.4629147366005067, -0.0014634101935372059) \n",
      "\n",
      "i  2 \n",
      "\n",
      "env_i.state  [-0.46145133  0.        ] \n",
      "\n",
      "action  0 \n",
      "\n",
      "next_state  (-0.4629147366005067, -0.0014634101935372059) \n",
      "\n",
      "i  3 \n",
      "\n",
      "env_i.state  [-0.46145133  0.        ] \n",
      "\n",
      "action  0 \n",
      "\n",
      "next_state  (-0.4629147366005067, -0.0014634101935372059) \n",
      "\n",
      "i  4 \n",
      "\n",
      "env_i.state  [-0.46145133  0.        ] \n",
      "\n",
      "action  1 \n",
      "\n",
      "next_state  (-0.4619147366005067, -0.0004634101935372057) \n",
      "\n",
      "sim_states tensor([[-0.4619, -0.0005],\n",
      "        [-0.4629, -0.0015],\n",
      "        [-0.4629, -0.0015],\n",
      "        [-0.4629, -0.0015],\n",
      "        [-0.4619, -0.0005]]) \n",
      "\n",
      "h = 1 \n",
      "\n",
      "i  0 \n",
      "\n",
      "env_i.state  [-0.46191475 -0.00046341] \n",
      "\n",
      "action  0 \n",
      "\n",
      "next_state  (-0.4638381524654559, -0.0019234045120409948) \n",
      "\n",
      "i  1 \n",
      "\n",
      "env_i.state  [-0.46291474 -0.00146341] \n",
      "\n",
      "action  1 \n",
      "\n",
      "next_state  (-0.4648307656952789, -0.001916030616467295) \n",
      "\n",
      "i  2 \n",
      "\n",
      "env_i.state  [-0.46291474 -0.00146341] \n",
      "\n",
      "action  0 \n",
      "\n",
      "next_state  (-0.4658307656952789, -0.0029160306164672948) \n",
      "\n",
      "i  3 \n",
      "\n",
      "env_i.state  [-0.46291474 -0.00146341] \n",
      "\n",
      "action  1 \n",
      "\n",
      "next_state  (-0.4648307656952789, -0.001916030616467295) \n",
      "\n",
      "i  4 \n",
      "\n",
      "env_i.state  [-0.46191475 -0.00046341] \n",
      "\n",
      "action  1 \n",
      "\n",
      "next_state  (-0.4628381524654559, -0.0009234045120409946) \n",
      "\n",
      "sim_states tensor([[-0.4638, -0.0019],\n",
      "        [-0.4648, -0.0019],\n",
      "        [-0.4658, -0.0029],\n",
      "        [-0.4648, -0.0019],\n",
      "        [-0.4628, -0.0009]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "horizon = 2\n",
    "num_particles = 5\n",
    "\n",
    "sim_states = env.state\n",
    "\n",
    "for h in range(horizon):\n",
    "    print(\"h =\", h, \"\\n\")\n",
    "    next_states = []\n",
    "    for i in range(num_particles):\n",
    "        print(\"i \", i, \"\\n\")\n",
    "        if h >0:\n",
    "            env_i = copy.deepcopy(env)  # Assuming prob_vars.env is an environment object with a copy method\n",
    "            env_i.reset(seed=seed)\n",
    "            env_i.state = sim_states[i].numpy()  # Set the initial state of the environment\n",
    "        else: # if h == 0:\n",
    "            env_i = copy.deepcopy(env)  # Assuming prob_vars.env is an environment object with a copy method\n",
    "            env_i.reset(seed=seed)\n",
    "            if isinstance(sim_states, torch.Tensor):\n",
    "                sim_states.detach().cpu().numpy()  # Safely convert to NumPy\n",
    "            env_i.state = sim_states # Set the initial state of the environment\n",
    "        print(\"env_i.state \", env_i.state, \"\\n\")\n",
    "        # print(env_i.step(env_i.action_space.sample()))\n",
    "        action = env_i.action_space.sample()\n",
    "        next_state_step, reward, terminated, truncated, info = env_i.step(action)  # Sample a random action\n",
    "        next_state = env_i.state\n",
    "        print(\"action \", action, \"\\n\")\n",
    "        print(\"next_state \", next_state, \"\\n\")\n",
    "        next_states.append(next_state)\n",
    "    \n",
    "    next_states = np.clip(next_states, env.observation_space.low, env.observation_space.high)\n",
    "    sim_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "    print(\"sim_states\", sim_states, \"\\n\")\n",
    "    # sim_states = torch.clip(sim_states, env.observation_space.low, env.observation_space.high)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fddeff",
   "metadata": {},
   "source": [
    "## Mountain Car (continuous)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e25f1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.46145132,  0.        ], dtype=float32), {})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"MountainCar\", render_mode=\"rgb_array\").unwrapped # .unwrapped is used to access the state directly\n",
    "env.reset(seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b48d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h = 0 \n",
      "\n",
      "i  0 \n",
      "\n",
      "env_i.state  -0.4614513264069695 \n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable numpy.float64 object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# print(env_i.step(env_i.action_space.sample()))\u001b[39;00m\n\u001b[0;32m     28\u001b[0m action \u001b[38;5;241m=\u001b[39m env_i\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m---> 29\u001b[0m next_state_step, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m env_i\u001b[38;5;241m.\u001b[39mstep(action)  \u001b[38;5;66;03m# Sample a random action\u001b[39;00m\n\u001b[0;32m     30\u001b[0m next_state \u001b[38;5;241m=\u001b[39m env_i\u001b[38;5;241m.\u001b[39mstate\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction \u001b[39m\u001b[38;5;124m\"\u001b[39m, action, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nicle\\anaconda3\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\mountain_car.py:138\u001b[0m, in \u001b[0;36mMountainCarEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mcontains(\n\u001b[0;32m    135\u001b[0m         action\n\u001b[0;32m    136\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(action)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) invalid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 138\u001b[0m     position, velocity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n\u001b[0;32m    139\u001b[0m     velocity \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (action \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforce \u001b[38;5;241m+\u001b[39m math\u001b[38;5;241m.\u001b[39mcos(\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m position) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgravity)\n\u001b[0;32m    140\u001b[0m     velocity \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(velocity, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_speed, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_speed)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float64 object"
     ]
    }
   ],
   "source": [
    "horizon = 2\n",
    "num_particles = 5\n",
    "\n",
    "sim_states = env.state\n",
    "\n",
    "for h in range(horizon):\n",
    "    print(\"h =\", h, \"\\n\")\n",
    "    next_states = []\n",
    "    for i in range(num_particles):\n",
    "        print(\"i \", i, \"\\n\")\n",
    "        if h >0:\n",
    "            env_i = copy.deepcopy(env)  # Assuming prob_vars.env is an environment object with a copy method\n",
    "            env_i.reset(seed=seed)\n",
    "            env_i.state = sim_states[i].numpy()  # Set the initial state of the environment\n",
    "        else: # if h == 0:\n",
    "            env_i = copy.deepcopy(env)  # Assuming prob_vars.env is an environment object with a copy method\n",
    "            env_i.reset(seed=seed)\n",
    "            # if isinstance(sim_states, torch.Tensor):\n",
    "            #     sim_states.detach().cpu().numpy()  # Safely convert to NumPy\n",
    "            env_i.state = sim_states # Set the initial state of the environment\n",
    "        print(\"env_i.state \", env_i.state, \"\\n\")\n",
    "        # print(env_i.step(env_i.action_space.sample()))\n",
    "        action = env_i.action_space.sample()\n",
    "        next_state_step, reward, terminated, truncated, info = env_i.step(action)  # Sample a random action\n",
    "        next_state = env_i.state\n",
    "        print(\"action \", action, \"\\n\")\n",
    "        print(\"next_state \", next_state, \"\\n\")\n",
    "        next_states.append(next_state)\n",
    "    \n",
    "    next_states = np.clip(next_states, env.observation_space.low, env.observation_space.high)\n",
    "    sim_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "    print(\"sim_states\", sim_states, \"\\n\")\n",
    "    # sim_states = torch.clip(sim_states, env.observation_space.low, env.observation_space.high)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd316969",
   "metadata": {},
   "source": [
    "## Panda Reach (dense or sparse rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "302b6d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'observation': array([ 3.8439669e-02, -2.1944723e-12,  1.9740014e-01,  0.0000000e+00,\n",
       "         -0.0000000e+00,  0.0000000e+00], dtype=float32),\n",
       "  'achieved_goal': array([ 3.8439669e-02, -2.1944723e-12,  1.9740014e-01], dtype=float32),\n",
       "  'desired_goal': array([0.05782301, 0.09474514, 0.10332203], dtype=float32)},\n",
       " array([ 3.8439669e-02, -2.1944723e-12,  1.9740014e-01,  0.0000000e+00,\n",
       "        -0.0000000e+00,  0.0000000e+00], dtype=float32))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"PandaReach-v3\", render_mode=\"rgb_array\").unwrapped # .unwrapped is used to access the state directly\n",
    "observation, info = env.reset(seed=seed)\n",
    "state = observation['observation']\n",
    "observation, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25363cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h = 0 \n",
      "\n",
      "i  0 \n",
      "\n",
      "action  [ 0.83247334 -0.89065814 -0.97416496] \n",
      "\n",
      "next_state_step  {'observation': array([ 0.07388315, -0.02262967,  0.186062  ,  0.22507364, -1.0759819 ,\n",
      "       -1.2219623 ], dtype=float32), 'achieved_goal': array([ 0.07388315, -0.02262967,  0.186062  ], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.10332203], dtype=float32)} \n",
      "\n",
      "i  1 \n",
      "\n",
      "action  [-0.33444116  0.47676137  0.13973841] \n",
      "\n",
      "next_state_step  {'observation': array([ 0.04593961, -0.04136471,  0.1352841 , -0.43256766,  0.11031865,\n",
      "       -0.91326004], dtype=float32), 'achieved_goal': array([ 0.04593961, -0.04136471,  0.1352841 ], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.10332203], dtype=float32)} \n",
      "\n",
      "i  2 \n",
      "\n",
      "action  [-0.46033     0.22527717 -0.34618923] \n",
      "\n",
      "next_state_step  {'observation': array([ 0.03278071, -0.03195858,  0.10610695, -0.1948292 ,  0.09315319,\n",
      "       -0.36483383], dtype=float32), 'achieved_goal': array([ 0.03278071, -0.03195858,  0.10610695], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.10332203], dtype=float32)} \n",
      "\n",
      "i  3 \n",
      "\n",
      "action  [ 0.01501239  0.05011773 -0.15948044] \n",
      "\n",
      "next_state_step  {'observation': array([ 0.03480628, -0.02968442,  0.09834028,  0.02065283,  0.01625034,\n",
      "       -0.04615648], dtype=float32), 'achieved_goal': array([ 0.03480628, -0.02968442,  0.09834028], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.10332203], dtype=float32)} \n",
      "\n",
      "i  4 \n",
      "\n",
      "action  [-0.02516033 -0.03391881  0.67989993] \n",
      "\n",
      "next_state_step  {'observation': array([ 0.02686325, -0.03073008,  0.10454323,  0.0993451 , -0.01754937,\n",
      "        0.50013554], dtype=float32), 'achieved_goal': array([ 0.02686325, -0.03073008,  0.10454323], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.10332203], dtype=float32)} \n",
      "\n",
      "h = 1 \n",
      "\n",
      "i  0 \n",
      "\n",
      "action  [-0.9700085 -0.7962431  0.8820176] \n",
      "\n",
      "next_state_step  {'observation': array([-0.01052768, -0.05370245,  0.12349303, -0.535959  , -0.93748105,\n",
      "        0.7479953 ], dtype=float32), 'achieved_goal': array([-0.01052768, -0.05370245,  0.12349303], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.10332203], dtype=float32)} \n",
      "\n",
      "i  1 \n",
      "\n",
      "action  [ 0.15416934 -0.01131401  0.72820336] \n",
      "\n",
      "next_state_step  {'observation': array([-0.00736289, -0.06924348,  0.15447918,  0.18690468,  0.2789913 ,\n",
      "        0.33364144], dtype=float32), 'achieved_goal': array([-0.00736289, -0.06924348,  0.15447918], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.10332203], dtype=float32)} \n",
      "\n",
      "i  2 \n",
      "\n",
      "action  [0.6863307  0.4361801  0.64492637] \n",
      "\n",
      "next_state_step  {'observation': array([ 0.01311417, -0.05028628,  0.17718913,  0.35675853,  0.20038678,\n",
      "        0.4643694 ], dtype=float32), 'achieved_goal': array([ 0.01311417, -0.05028628,  0.17718913], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.10332203], dtype=float32)} \n",
      "\n",
      "i  3 \n",
      "\n",
      "action  [-0.7001054   0.65246767 -0.2909626 ] \n",
      "\n",
      "next_state_step  {'observation': array([-0.00223735, -0.02468745,  0.17381766, -0.5137788 ,  0.414519  ,\n",
      "       -0.49958155], dtype=float32), 'achieved_goal': array([-0.00223735, -0.02468745,  0.17381766], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.10332203], dtype=float32)} \n",
      "\n",
      "i  4 \n",
      "\n",
      "action  [ 0.18265183  0.27670792 -0.483161  ] \n",
      "\n",
      "next_state_step  {'observation': array([ 0.00107602, -0.01190455,  0.14994505, -0.01844173,  0.09837341,\n",
      "       -0.4853342 ], dtype=float32), 'achieved_goal': array([ 0.00107602, -0.01190455,  0.14994505], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.10332203], dtype=float32)} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "horizon = 2\n",
    "num_particles = 5\n",
    "\n",
    "state_ids = np.array([env.save_state() for _ in range(num_particles)], dtype=object)\n",
    "state_ids[:] = env.save_state()  # Save the initial state of the environment\n",
    "\n",
    "for h in range(horizon):\n",
    "    print(\"h =\", h, \"\\n\")\n",
    "    next_states = []\n",
    "    for i in range(num_particles):\n",
    "        print(\"i \", i, \"\\n\")\n",
    "        env.restore_state(state_ids[i])\n",
    "        env.remove_state(state_ids[i])\n",
    "        \n",
    "        action = env.action_space.sample()\n",
    "        next_state_step, reward, terminated, truncated, info = env.step(action)  # Sample a random action\n",
    "\n",
    "        state_ids[i] = env.save_state()\n",
    "            \n",
    "        next_states.append(next_state_step['observation'])\n",
    "        \n",
    "        print(\"action \", action, \"\\n\")\n",
    "        print(\"next_state_step \", next_state_step, \"\\n\")\n",
    "    \n",
    "    # next_states = np.clip(next_states, env.observation_space.low, env.observation_space.high)\n",
    "    # sim_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "    # print(\"sim_states\", sim_states, \"\\n\")\n",
    "    # sim_states = torch.clip(sim_states, env.observation_space.low, env.observation_space.high)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a97a85cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.08702072, -0.0112063 ,  0.26086777, -0.17163223, -1.211889  ,\n",
       "         0.5001206 ], dtype=float32),\n",
       " array([-0.06001816, -0.02955841,  0.28211418,  0.34303477,  0.37377453,\n",
       "         0.23396528], dtype=float32),\n",
       " array([-0.04143569, -0.04477818,  0.3038964 ,  0.21430662, -1.1719104 ,\n",
       "         0.5652366 ], dtype=float32),\n",
       " array([-0.04942478, -0.0614167 ,  0.32240614, -0.02463246,  0.37749085,\n",
       "         0.26439935], dtype=float32),\n",
       " array([-0.03534625, -0.05761719,  0.33242223,  0.16460375,  0.01213752,\n",
       "         0.08577067], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b20556b",
   "metadata": {},
   "source": [
    "## Panda Push (dense or sparse rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f39d784c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'observation': array([ 3.8439669e-02, -2.1944723e-12,  1.9740014e-01,  0.0000000e+00,\n",
       "         -0.0000000e+00,  0.0000000e+00, -1.3654855e-01,  2.1479176e-02,\n",
       "          2.0000000e-02,  0.0000000e+00, -0.0000000e+00,  0.0000000e+00,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "          0.0000000e+00,  0.0000000e+00], dtype=float32),\n",
       "  'achieved_goal': array([-0.13654855,  0.02147918,  0.02      ], dtype=float32),\n",
       "  'desired_goal': array([0.05782301, 0.09474514, 0.02      ], dtype=float32)},\n",
       " array([ 3.8439669e-02, -2.1944723e-12,  1.9740014e-01,  0.0000000e+00,\n",
       "        -0.0000000e+00,  0.0000000e+00, -1.3654855e-01,  2.1479176e-02,\n",
       "         2.0000000e-02,  0.0000000e+00, -0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00], dtype=float32))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"PandaPush-v3\", render_mode=\"rgb_array\").unwrapped # .unwrapped is used to access the state directly\n",
    "observation, info = env.reset(seed=seed)\n",
    "state = observation['observation']\n",
    "observation, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c63d3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h = 0 \n",
      "\n",
      "i  0 \n",
      "\n",
      "action  [-0.47496682 -0.61775315  0.49273023] \n",
      "\n",
      "next_state_step  {'observation': array([ 1.95859764e-02, -2.13152785e-02,  2.01412484e-01, -8.85352120e-02,\n",
      "       -5.51360190e-01,  5.36332071e-01, -1.36549190e-01,  2.14795396e-02,\n",
      "        1.99895296e-02,  4.48686751e-06, -3.08392118e-05, -3.87872387e-06,\n",
      "       -5.73867237e-06,  1.09538505e-05, -5.08076300e-06,  5.10964995e-08,\n",
      "       -2.53998151e-04, -9.67000524e-05], dtype=float32), 'achieved_goal': array([-0.13654919,  0.02147954,  0.01998953], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.02      ], dtype=float32)} \n",
      "\n",
      "i  1 \n",
      "\n",
      "action  [ 0.5809905   0.3511775  -0.58508754] \n",
      "\n",
      "next_state_step  {'observation': array([ 4.60014157e-02, -1.95030067e-02,  2.07699180e-01,  1.23327814e-01,\n",
      "        7.04958379e-01, -7.59111941e-01, -1.36549309e-01,  2.14799773e-02,\n",
      "        1.99894346e-02,  4.48783976e-06, -3.55768534e-05, -7.74457658e-06,\n",
      "       -1.61770095e-06,  1.09538014e-05, -9.57692350e-07,  9.50089607e-09,\n",
      "       -4.78768852e-05, -9.66187727e-05], dtype=float32), 'achieved_goal': array([-0.13654931,  0.02147998,  0.01998943], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.02      ], dtype=float32)} \n",
      "\n",
      "i  2 \n",
      "\n",
      "action  [0.5777733  0.83566135 0.95618045] \n",
      "\n",
      "next_state_step  {'observation': array([ 4.6426274e-02,  1.7824190e-02,  1.9196111e-01,  1.7404050e-01,\n",
      "        5.0580579e-01, -1.1637469e-01, -1.3654935e-01,  2.1480415e-02,\n",
      "        1.9989418e-02,  4.4880253e-06, -3.6469872e-05, -1.1608956e-05,\n",
      "       -8.4092119e-07,  1.0953763e-05, -1.8052098e-07,  1.8103056e-09,\n",
      "       -9.0246240e-06, -9.6605057e-05], dtype=float32), 'achieved_goal': array([-0.13654935,  0.02148042,  0.01998942], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.02      ], dtype=float32)} \n",
      "\n",
      "i  3 \n",
      "\n",
      "action  [-0.6365351   0.19730182 -0.36442178] \n",
      "\n",
      "next_state_step  {'observation': array([ 3.6747206e-02,  2.8296944e-02,  1.7877567e-01, -3.1028661e-01,\n",
      "        5.9000064e-02, -1.9288225e-01, -1.3654938e-01,  2.1480853e-02,\n",
      "        1.9989414e-02,  4.4880626e-06, -3.6638205e-05, -1.5473121e-05,\n",
      "       -6.9449044e-07,  1.0953730e-05, -3.4030048e-08,  3.8914305e-10,\n",
      "       -1.7012761e-06, -9.6604032e-05], dtype=float32), 'achieved_goal': array([-0.13654938,  0.02148085,  0.01998941], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.02      ], dtype=float32)} \n",
      "\n",
      "i  4 \n",
      "\n",
      "action  [-0.285194   -0.45631975 -0.18297042] \n",
      "\n",
      "next_state_step  {'observation': array([ 2.7785283e-02,  1.2370190e-02,  1.7084324e-01, -6.8176448e-02,\n",
      "       -3.4488800e-01, -6.2970370e-02, -1.3654941e-01,  2.1481290e-02,\n",
      "        1.9989412e-02,  4.4880717e-06, -3.6669942e-05, -1.9337309e-05,\n",
      "       -6.6687534e-07,  1.0953700e-05, -6.4176611e-09,  1.2656280e-10,\n",
      "       -3.2088133e-07, -9.6605399e-05], dtype=float32), 'achieved_goal': array([-0.13654941,  0.02148129,  0.01998941], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.02      ], dtype=float32)} \n",
      "\n",
      "h = 1 \n",
      "\n",
      "i  0 \n",
      "\n",
      "action  [-0.42137358  0.23266105 -0.32231602] \n",
      "\n",
      "next_state_step  {'observation': array([ 1.50694400e-02,  1.84906311e-02,  1.57929957e-01, -1.64167911e-01,\n",
      "        2.58065403e-01, -1.51656538e-01, -1.36549443e-01,  2.14817300e-02,\n",
      "        1.99894123e-02,  4.48807577e-06, -3.66759341e-05, -2.32015627e-05,\n",
      "       -6.61656088e-07,  1.09536695e-05, -1.21293620e-09,  7.81060078e-11,\n",
      "       -6.06878885e-08, -9.66072184e-05], dtype=float32), 'achieved_goal': array([-0.13654944,  0.02148173,  0.01998941], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.02      ], dtype=float32)} \n",
      "\n",
      "i  1 \n",
      "\n",
      "action  [ 0.4072785 -0.6416111  0.3185938] \n",
      "\n",
      "next_state_step  {'observation': array([ 2.43929233e-02,  5.40852034e-03,  1.63751885e-01,  2.84194618e-01,\n",
      "       -9.03673768e-01,  4.33565378e-01, -1.36549473e-01,  2.14821678e-02,\n",
      "        1.99894123e-02,  4.48807850e-06, -3.66770691e-05, -2.70658911e-05,\n",
      "       -6.60658259e-07,  1.09536395e-05, -2.31872244e-10,  6.92109425e-11,\n",
      "       -1.16441239e-08, -9.66091247e-05], dtype=float32), 'achieved_goal': array([-0.13654947,  0.02148217,  0.01998941], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.02      ], dtype=float32)} \n",
      "\n",
      "i  2 \n",
      "\n",
      "action  [0.51783115 0.9863355  0.85033786] \n",
      "\n",
      "next_state_step  {'observation': array([ 3.96632589e-02, -6.10010605e-03,  1.93619251e-01,  2.83251286e-01,\n",
      "        3.20531070e-01,  6.13720536e-01, -1.36549488e-01,  2.14826055e-02,\n",
      "        1.99894123e-02,  4.48808123e-06, -3.66772947e-05, -3.09302959e-05,\n",
      "       -6.60456124e-07,  1.09536095e-05, -4.69550197e-11,  6.72821590e-11,\n",
      "       -2.39939157e-09, -9.66110456e-05], dtype=float32), 'achieved_goal': array([-0.13654949,  0.02148261,  0.01998941], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.02      ], dtype=float32)} \n",
      "\n",
      "i  3 \n",
      "\n",
      "action  [-0.02761648 -0.7236734   0.48907685] \n",
      "\n",
      "next_state_step  {'observation': array([ 3.9754849e-02, -1.7163785e-02,  2.1468014e-01, -1.8809870e-02,\n",
      "       -9.0606916e-01,  2.2331785e-01, -1.3654952e-01,  2.1483043e-02,\n",
      "        1.9989412e-02,  4.4880840e-06, -3.6677342e-05, -3.4794779e-05,\n",
      "       -6.6040400e-07,  1.0953579e-05, -1.2105046e-11,  6.7523112e-11,\n",
      "       -6.5656386e-10, -9.6612966e-05], dtype=float32), 'achieved_goal': array([-0.13654952,  0.02148304,  0.01998941], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.02      ], dtype=float32)} \n",
      "\n",
      "i  4 \n",
      "\n",
      "action  [-0.0358899  -0.74819005 -0.39326018] \n",
      "\n",
      "next_state_step  {'observation': array([ 3.9272401e-02, -5.4587483e-02,  2.0110859e-01, -1.0526451e-01,\n",
      "       -3.8836145e-01, -5.0953060e-01, -1.3654955e-01,  2.1483483e-02,\n",
      "        1.9989412e-02,  4.4880867e-06, -3.6677360e-05, -3.8659338e-05,\n",
      "       -6.6038012e-07,  1.0953549e-05, -5.5324009e-12,  6.7292900e-11,\n",
      "       -3.2823466e-10, -9.6614895e-05], dtype=float32), 'achieved_goal': array([-0.13654955,  0.02148348,  0.01998941], dtype=float32), 'desired_goal': array([0.05782301, 0.09474514, 0.02      ], dtype=float32)} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "horizon = 2\n",
    "num_particles = 5\n",
    "\n",
    "state_ids = np.array([env.save_state() for _ in range(num_particles)], dtype=object)\n",
    "state_ids[:] = env.save_state()  # Save the initial state of the environment\n",
    "\n",
    "for h in range(horizon):\n",
    "    print(\"h =\", h, \"\\n\")\n",
    "    next_states = []\n",
    "    for i in range(num_particles):\n",
    "        print(\"i \", i, \"\\n\")\n",
    "        env.restore_state(state_ids[i])\n",
    "        env.remove_state(state_ids[i])\n",
    "        \n",
    "        action = env.action_space.sample()\n",
    "        next_state_step, reward, terminated, truncated, info = env.step(action)  # Sample a random action\n",
    "\n",
    "        state_ids[i] = env.save_state()\n",
    "            \n",
    "        next_states.append(next_state_step['observation'])\n",
    "        \n",
    "        print(\"action \", action, \"\\n\")\n",
    "        print(\"next_state_step \", next_state_step, \"\\n\")\n",
    "    \n",
    "    # next_states = np.clip(next_states, env.observation_space.low, env.observation_space.high)\n",
    "    # sim_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "    # print(\"sim_states\", sim_states, \"\\n\")\n",
    "    # sim_states = torch.clip(sim_states, env.observation_space.low, env.observation_space.high)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52359293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1.50694400e-02,  1.84906311e-02,  1.57929957e-01, -1.64167911e-01,\n",
       "         2.58065403e-01, -1.51656538e-01, -1.36549443e-01,  2.14817300e-02,\n",
       "         1.99894123e-02,  4.48807577e-06, -3.66759341e-05, -2.32015627e-05,\n",
       "        -6.61656088e-07,  1.09536695e-05, -1.21293620e-09,  7.81060078e-11,\n",
       "        -6.06878885e-08, -9.66072184e-05], dtype=float32),\n",
       " array([ 2.43929233e-02,  5.40852034e-03,  1.63751885e-01,  2.84194618e-01,\n",
       "        -9.03673768e-01,  4.33565378e-01, -1.36549473e-01,  2.14821678e-02,\n",
       "         1.99894123e-02,  4.48807850e-06, -3.66770691e-05, -2.70658911e-05,\n",
       "        -6.60658259e-07,  1.09536395e-05, -2.31872244e-10,  6.92109425e-11,\n",
       "        -1.16441239e-08, -9.66091247e-05], dtype=float32),\n",
       " array([ 3.96632589e-02, -6.10010605e-03,  1.93619251e-01,  2.83251286e-01,\n",
       "         3.20531070e-01,  6.13720536e-01, -1.36549488e-01,  2.14826055e-02,\n",
       "         1.99894123e-02,  4.48808123e-06, -3.66772947e-05, -3.09302959e-05,\n",
       "        -6.60456124e-07,  1.09536095e-05, -4.69550197e-11,  6.72821590e-11,\n",
       "        -2.39939157e-09, -9.66110456e-05], dtype=float32),\n",
       " array([ 3.9754849e-02, -1.7163785e-02,  2.1468014e-01, -1.8809870e-02,\n",
       "        -9.0606916e-01,  2.2331785e-01, -1.3654952e-01,  2.1483043e-02,\n",
       "         1.9989412e-02,  4.4880840e-06, -3.6677342e-05, -3.4794779e-05,\n",
       "        -6.6040400e-07,  1.0953579e-05, -1.2105046e-11,  6.7523112e-11,\n",
       "        -6.5656386e-10, -9.6612966e-05], dtype=float32),\n",
       " array([ 3.9272401e-02, -5.4587483e-02,  2.0110859e-01, -1.0526451e-01,\n",
       "        -3.8836145e-01, -5.0953060e-01, -1.3654955e-01,  2.1483483e-02,\n",
       "         1.9989412e-02,  4.4880867e-06, -3.6677360e-05, -3.8659338e-05,\n",
       "        -6.6038012e-07,  1.0953549e-05, -5.5324009e-12,  6.7292900e-11,\n",
       "        -3.2823466e-10, -9.6614895e-05], dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f635aba",
   "metadata": {},
   "source": [
    "# Environments that don't work\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aadf94",
   "metadata": {},
   "source": [
    "## Pendulum\n",
    "\n",
    "Clipping the next state is problematic since the step gives a 3D state and the env.state givees a 2D state. This isn't\n",
    "too problematic since the MPC methods seem to work well on this env.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0fc5be3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicle\\anaconda3\\Lib\\site-packages\\gymnasium\\envs\\registration.py:525: UserWarning: \u001b[33mWARN: Using the latest versioned environment `Pendulum-v1` instead of the unversioned environment `Pendulum`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.35204402, 0.9359834 , 0.63163424], dtype=float32), {})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"Pendulum\", render_mode=\"rgb_array\").unwrapped # .unwrapped is used to access the state directly\n",
    "env.reset(seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "deefce27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h = 0 \n",
      "\n",
      "i  0 \n",
      "\n",
      "env_i.state  [1.2110423  0.63163422] \n",
      "\n",
      "action  [-1.0778373] \n",
      "\n",
      "next_state  [1.29267388 1.63263168] \n",
      "\n",
      "i  1 \n",
      "\n",
      "env_i.state  [1.2110423  0.63163422] \n",
      "\n",
      "action  [-1.8573741] \n",
      "\n",
      "next_state  [1.26498214 1.07879693] \n",
      "\n",
      "i  2 \n",
      "\n",
      "env_i.state  [1.2110423  0.63163422] \n",
      "\n",
      "action  [1.7408022] \n",
      "\n",
      "next_state  [1.2659763  1.09868002] \n",
      "\n",
      "i  3 \n",
      "\n",
      "env_i.state  [1.2110423  0.63163422] \n",
      "\n",
      "action  [1.9067779] \n",
      "\n",
      "next_state  [1.28429773 1.46510871] \n",
      "\n",
      "i  4 \n",
      "\n",
      "env_i.state  [1.2110423  0.63163422] \n",
      "\n",
      "action  [0.70322055] \n",
      "\n",
      "next_state  [1.27446341 1.26842231] \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (5,2) (3,) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_state \u001b[39m\u001b[38;5;124m\"\u001b[39m, next_state, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m     next_states\u001b[38;5;241m.\u001b[39mappend(next_state)\n\u001b[1;32m---> 30\u001b[0m next_states \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(next_states, env\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mlow, env\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[0;32m     31\u001b[0m sim_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(next_states, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msim_states\u001b[39m\u001b[38;5;124m\"\u001b[39m, sim_states, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nicle\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2169\u001b[0m, in \u001b[0;36mclip\u001b[1;34m(a, a_min, a_max, out, **kwargs)\u001b[0m\n\u001b[0;32m   2100\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_clip_dispatcher)\n\u001b[0;32m   2101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclip\u001b[39m(a, a_min, a_max, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   2102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2103\u001b[0m \u001b[38;5;124;03m    Clip (limit) the values in an array.\u001b[39;00m\n\u001b[0;32m   2104\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2167\u001b[0m \n\u001b[0;32m   2168\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m'\u001b[39m, a_min, a_max, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nicle\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:56\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\nicle\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:45\u001b[0m, in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(asarray(obj), method)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "File \u001b[1;32mc:\\Users\\nicle\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:99\u001b[0m, in \u001b[0;36m_clip\u001b[1;34m(a, min, max, out, **kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m um\u001b[38;5;241m.\u001b[39mmaximum(a, \u001b[38;5;28mmin\u001b[39m, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m um\u001b[38;5;241m.\u001b[39mclip(a, \u001b[38;5;28mmin\u001b[39m, \u001b[38;5;28mmax\u001b[39m, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (5,2) (3,) (3,) "
     ]
    }
   ],
   "source": [
    "horizon = 2\n",
    "num_particles = 5\n",
    "\n",
    "sim_states = env.state\n",
    "\n",
    "for h in range(horizon):\n",
    "    print(\"h =\", h, \"\\n\")\n",
    "    next_states = []\n",
    "    for i in range(num_particles):\n",
    "        print(\"i \", i, \"\\n\")\n",
    "        if h >0:\n",
    "            env_i = copy.deepcopy(env)  # Assuming prob_vars.env is an environment object with a copy method\n",
    "            env_i.reset(seed=seed)\n",
    "            env_i.state = sim_states[i].numpy()  # Set the initial state of the environment\n",
    "        else: # if h == 0:\n",
    "            env_i = copy.deepcopy(env)  # Assuming prob_vars.env is an environment object with a copy method\n",
    "            env_i.reset(seed=seed)\n",
    "            if isinstance(sim_states, torch.Tensor):\n",
    "                sim_states.detach().cpu().numpy()  # Safely convert to NumPy\n",
    "            env_i.state = sim_states # Set the initial state of the environment\n",
    "        print(\"env_i.state \", env_i.state, \"\\n\")\n",
    "        # print(env_i.step(env_i.action_space.sample()))\n",
    "        action = env_i.action_space.sample()\n",
    "        next_state_step, reward, terminated, truncated, info = env_i.step(env_i.action_space.sample())  # Sample a random action\n",
    "        next_state = env_i.state\n",
    "        print(\"action \", action, \"\\n\")\n",
    "        print(\"next_state \", next_state, \"\\n\")\n",
    "        next_states.append(next_state)\n",
    "    \n",
    "    # next_states = np.clip(next_states, env.observation_space.low, env.observation_space.high) # Clipping the next state is problematic since the step gives a 3D state and the env.state givees a 2D state\n",
    "    sim_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "    print(\"sim_states\", sim_states, \"\\n\")\n",
    "    # sim_states = torch.clip(sim_states, env.observation_space.low, env.observation_space.high)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eecf81",
   "metadata": {},
   "source": [
    "## Lunar lander (continuous or discrete)\n",
    "\n",
    "Doesn't work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9611ae64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 8.8014605e-04,  1.4210069e+00,  8.9126542e-02,  4.4830140e-01,\n",
       "        -1.0129989e-03, -2.0188505e-02,  0.0000000e+00,  0.0000000e+00],\n",
       "       dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v3').unwrapped # .unwrapped is used to access the state directly\n",
    "env.reset(seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c90209a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b2Body(active=True,\n",
       "       angle=-0.001012998865917325,\n",
       "       angularDamping=0.0,\n",
       "       angularVelocity=-0.05047126114368439,\n",
       "       awake=True,\n",
       "       bullet=False,\n",
       "       contacts=[],\n",
       "       fixedRotation=False,\n",
       "       fixtures=[b2Fixture(body=b2Body(active=True,\n",
       "                                      angle=-0.001012998865917325,\n",
       "                                      angularDamping=0.0,\n",
       "                                      angularVelocity=-0.05047126114368439,...  )],\n",
       "       inertia=0.8333148956298828,\n",
       "       joints=[b2JointEdge(joint=b2RevoluteJoint(active=True,\n",
       "                                                anchorA=b2Vec2(10.0088,13.4067),\n",
       "                                                anchorB=b2Vec2(10.0088,13.4067),...  )],\n",
       "       linearDamping=0.0,\n",
       "       linearVelocity=b2Vec2(0.445633,3.36226),\n",
       "       localCenter=b2Vec2(0,0.101307),\n",
       "       mass=4.816666603088379,\n",
       "       massData=I=0.8333148956298828,center=b2Vec2(0,0.101307),mass=4.816666603088379,),\n",
       "       position=b2Vec2(10.0088,13.4067),\n",
       "       sleepingAllowed=True,\n",
       "       transform=R=<Box2D.Box2D.b2Rot; proxy of <Swig Object of type 'b2Rot *' at 0x000001151EADE310> >,angle=-0.0010129989823326468,position=b2Vec2(10.0088,13.4067),),\n",
       "       type=2,\n",
       "       userData=None,\n",
       "       worldCenter=b2Vec2(10.0089,13.508),\n",
       "       )"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.lander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be1711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h = 0 \n",
      "\n",
      "i  0 \n",
      "\n",
      "env_i.state  [ 0.01927434  0.03158171 -0.01555932 -0.04551618] \n",
      "\n",
      "next_state  (0.019905971019187348, -0.08655294196659766, -0.016469647869333498, 0.1270900912606458) \n",
      "\n",
      "i  1 \n",
      "\n",
      "env_i.state  [ 0.01927434  0.03158171 -0.01555932 -0.04551618] \n",
      "\n",
      "next_state  (0.019905971019187348, 0.0014594708235263036, -0.016469647869333498, -0.004912547883514723) \n",
      "\n",
      "i  2 \n",
      "\n",
      "env_i.state  [ 0.01927434  0.03158171 -0.01555932 -0.04551618] \n",
      "\n",
      "next_state  (0.019905971019187348, -0.15515744052636463, -0.016469647869333498, 0.22998438287205802) \n",
      "\n",
      "i  3 \n",
      "\n",
      "env_i.state  [ 0.01927434  0.03158171 -0.01555932 -0.04551618] \n",
      "\n",
      "next_state  (0.019905971019187348, -0.06759462778457094, -0.016469647869333498, 0.09865606216841635) \n",
      "\n",
      "i  4 \n",
      "\n",
      "env_i.state  [ 0.01927434  0.03158171 -0.01555932 -0.04551618] \n",
      "\n",
      "next_state  (0.019905971019187348, -0.09673757295243982, -0.016469647869333498, 0.1423651885590966) \n",
      "\n",
      "sim_states tensor([[ 0.0199, -0.0866, -0.0165,  0.1271],\n",
      "        [ 0.0199,  0.0015, -0.0165, -0.0049],\n",
      "        [ 0.0199, -0.1552, -0.0165,  0.2300],\n",
      "        [ 0.0199, -0.0676, -0.0165,  0.0987],\n",
      "        [ 0.0199, -0.0967, -0.0165,  0.1424]]) \n",
      "\n",
      "h = 1 \n",
      "\n",
      "i  0 \n",
      "\n",
      "env_i.state  [ 0.01990597 -0.08655294 -0.01646965  0.1270901 ] \n",
      "\n",
      "next_state  (0.018174912557005884, -0.16966593054263845, -0.013927846178412438, 0.24690081630537308) \n",
      "\n",
      "i  1 \n",
      "\n",
      "env_i.state  [ 0.01990597  0.00145947 -0.01646965 -0.00491255] \n",
      "\n",
      "next_state  (0.01993516077985987, 0.11309306171668833, -0.01656789906322956, -0.1771820818493216) \n",
      "\n",
      "i  2 \n",
      "\n",
      "env_i.state  [ 0.01990597 -0.15515745 -0.01646965  0.22998439] \n",
      "\n",
      "next_state  (0.016802822425961494, -0.09763261182954494, -0.011869960352778434, 0.1388669799770555) \n",
      "\n",
      "i  3 \n",
      "\n",
      "env_i.state  [ 0.01990597 -0.06759463 -0.01646965  0.09865607] \n",
      "\n",
      "next_state  (0.018554078862071038, -0.1835308827686365, -0.014496526792645455, 0.2676950094970805) \n",
      "\n",
      "i  4 \n",
      "\n",
      "env_i.state  [ 0.01990597 -0.09673757 -0.01646965  0.14236519] \n",
      "\n",
      "next_state  (0.017971219941973687, -0.2047818949226598, -0.013622344359755515, 0.29956783584022184) \n",
      "\n",
      "sim_states tensor([[ 0.0182, -0.1697, -0.0139,  0.2469],\n",
      "        [ 0.0199,  0.1131, -0.0166, -0.1772],\n",
      "        [ 0.0168, -0.0976, -0.0119,  0.1389],\n",
      "        [ 0.0186, -0.1835, -0.0145,  0.2677],\n",
      "        [ 0.0180, -0.2048, -0.0136,  0.2996]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "horizon = 2\n",
    "num_particles = 5\n",
    "\n",
    "sim_states = env.state\n",
    "\n",
    "for h in range(horizon):\n",
    "    print(\"h =\", h, \"\\n\")\n",
    "    next_states = []\n",
    "    for i in range(num_particles):\n",
    "        print(\"i \", i, \"\\n\")\n",
    "        if h >0:\n",
    "            env_i = copy.deepcopy(env)  # Assuming prob_vars.env is an environment object with a copy method\n",
    "            env_i.reset(seed=seed)\n",
    "            env_i.state = sim_states[i].numpy()  # Set the initial state of the environment\n",
    "        else: # if h == 0:\n",
    "            env_i = copy.deepcopy(env)  # Assuming prob_vars.env is an environment object with a copy method\n",
    "            env_i.reset(seed=seed)\n",
    "            if isinstance(sim_states, torch.Tensor):\n",
    "                sim_states.detach().cpu().numpy()  # Safely convert to NumPy\n",
    "            env_i.state = sim_states # Set the initial state of the environment\n",
    "        print(\"env_i.state \", env_i.state, \"\\n\")\n",
    "        # print(env_i.step(env_i.action_space.sample()))\n",
    "        action = env_i.action_space.sample()\n",
    "        next_state_step, reward, terminated, truncated, info = env_i.step(action)  # Sample a random action\n",
    "        next_state = env_i.state\n",
    "        print(\"next_state \", next_state, \"\\n\")\n",
    "        next_states.append(next_state)\n",
    "    \n",
    "    next_states = np.clip(next_states, env.observation_space.low, env.observation_space.high)\n",
    "    sim_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "    print(\"sim_states\", sim_states, \"\\n\")\n",
    "    # sim_states = torch.clip(sim_states, env.observation_space.low, env.observation_space.high)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7eb63b",
   "metadata": {},
   "source": [
    "## Inverted Pendulum\n",
    "\n",
    "Doesn't work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f81a3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicle\\anaconda3\\Lib\\site-packages\\gymnasium\\envs\\registration.py:517: DeprecationWarning: \u001b[33mWARN: The environment InvertedPendulum-v4 is out of date. You should consider upgrading to version `v5`.\u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TimeLimit' object has no attribute 'sim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Set the state\u001b[39;00m\n\u001b[0;32m     14\u001b[0m env\u001b[38;5;241m.\u001b[39mset_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m qpos, qvel: (\u001b[38;5;28msetattr\u001b[39m(env\u001b[38;5;241m.\u001b[39msim\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mqpos, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[:]\u001b[39m\u001b[38;5;124m\"\u001b[39m, qpos), \u001b[38;5;28msetattr\u001b[39m(env\u001b[38;5;241m.\u001b[39msim\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mqvel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[:]\u001b[39m\u001b[38;5;124m\"\u001b[39m, qvel))\n\u001b[1;32m---> 15\u001b[0m env\u001b[38;5;241m.\u001b[39mset_state(custom_qpos, custom_qvel)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Verify\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew state qpos:\u001b[39m\u001b[38;5;124m\"\u001b[39m, env\u001b[38;5;241m.\u001b[39msim\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mqpos)\n",
      "Cell \u001b[1;32mIn[66], line 14\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(qpos, qvel)\u001b[0m\n\u001b[0;32m     11\u001b[0m custom_qvel \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m])   \u001b[38;5;66;03m# velocities\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Set the state\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m env\u001b[38;5;241m.\u001b[39mset_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m qpos, qvel: (\u001b[38;5;28msetattr\u001b[39m(env\u001b[38;5;241m.\u001b[39msim\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mqpos, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[:]\u001b[39m\u001b[38;5;124m\"\u001b[39m, qpos), \u001b[38;5;28msetattr\u001b[39m(env\u001b[38;5;241m.\u001b[39msim\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mqvel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[:]\u001b[39m\u001b[38;5;124m\"\u001b[39m, qvel))\n\u001b[0;32m     15\u001b[0m env\u001b[38;5;241m.\u001b[39mset_state(custom_qpos, custom_qvel)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Verify\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TimeLimit' object has no attribute 'sim'"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('InvertedPendulum-v4')\n",
    "\n",
    "# Reset environment (to initialize)\n",
    "obs, info = env.reset()\n",
    "\n",
    "# Define your custom state\n",
    "custom_qpos = np.array([0.0, 0.1])   # cart position, pole angle\n",
    "custom_qvel = np.array([0.0, 0.0])   # velocities\n",
    "\n",
    "# Set the state\n",
    "env.set_state = lambda qpos, qvel: (setattr(env.sim.data.qpos, \"[:]\", qpos), setattr(env.sim.data.qvel, \"[:]\", qvel))\n",
    "env.set_state(custom_qpos, custom_qvel)\n",
    "\n",
    "# Verify\n",
    "print(\"New state qpos:\", env.sim.data.qpos)\n",
    "print(\"New state qvel:\", env.sim.data.qvel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff9852c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicle\\anaconda3\\Lib\\site-packages\\gymnasium\\envs\\registration.py:525: UserWarning: \u001b[33mWARN: Using the latest versioned environment `Pendulum-v1` instead of the unversioned environment `Pendulum`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.35204402, 0.9359834 , 0.63163424], dtype=float32), {})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"Pendulum\", render_mode=\"rgb_array\").unwrapped # .unwrapped is used to access the state directly\n",
    "env.reset(seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b831caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h = 0 \n",
      "\n",
      "i  0 \n",
      "\n",
      "env_i.state  [1.2110423  0.63163422] \n",
      "\n",
      "action  [-1.0778373] \n",
      "\n",
      "next_state  [1.29267388 1.63263168] \n",
      "\n",
      "i  1 \n",
      "\n",
      "env_i.state  [1.2110423  0.63163422] \n",
      "\n",
      "action  [-1.8573741] \n",
      "\n",
      "next_state  [1.26498214 1.07879693] \n",
      "\n",
      "i  2 \n",
      "\n",
      "env_i.state  [1.2110423  0.63163422] \n",
      "\n",
      "action  [1.7408022] \n",
      "\n",
      "next_state  [1.2659763  1.09868002] \n",
      "\n",
      "i  3 \n",
      "\n",
      "env_i.state  [1.2110423  0.63163422] \n",
      "\n",
      "action  [1.9067779] \n",
      "\n",
      "next_state  [1.28429773 1.46510871] \n",
      "\n",
      "i  4 \n",
      "\n",
      "env_i.state  [1.2110423  0.63163422] \n",
      "\n",
      "action  [0.70322055] \n",
      "\n",
      "next_state  [1.27446341 1.26842231] \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (5,2) (3,) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[65], line 30\u001b[0m\n",
      "\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_state \u001b[39m\u001b[38;5;124m\"\u001b[39m, next_state, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m     28\u001b[0m     next_states\u001b[38;5;241m.\u001b[39mappend(next_state)\n",
      "\u001b[1;32m---> 30\u001b[0m next_states \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(next_states, env\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mlow, env\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mhigh)\n",
      "\u001b[0;32m     31\u001b[0m sim_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(next_states, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msim_states\u001b[39m\u001b[38;5;124m\"\u001b[39m, sim_states, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\nicle\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2169\u001b[0m, in \u001b[0;36mclip\u001b[1;34m(a, a_min, a_max, out, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   2100\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_clip_dispatcher)\n",
      "\u001b[0;32m   2101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclip\u001b[39m(a, a_min, a_max, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[0;32m   2102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m   2103\u001b[0m \u001b[38;5;124;03m    Clip (limit) the values in an array.\u001b[39;00m\n",
      "\u001b[0;32m   2104\u001b[0m \n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   2167\u001b[0m \n",
      "\u001b[0;32m   2168\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;32m-> 2169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m'\u001b[39m, a_min, a_max, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\nicle\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:56\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m     54\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\nicle\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:45\u001b[0m, in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[0;32m     44\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m---> 45\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(asarray(obj), method)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n",
      "\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\nicle\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:99\u001b[0m, in \u001b[0;36m_clip\u001b[1;34m(a, min, max, out, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m um\u001b[38;5;241m.\u001b[39mmaximum(a, \u001b[38;5;28mmin\u001b[39m, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m um\u001b[38;5;241m.\u001b[39mclip(a, \u001b[38;5;28mmin\u001b[39m, \u001b[38;5;28mmax\u001b[39m, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (5,2) (3,) (3,) "
     ]
    }
   ],
   "source": [
    "horizon = 2\n",
    "num_particles = 5\n",
    "\n",
    "sim_states = env.state\n",
    "\n",
    "for h in range(horizon):\n",
    "    print(\"h =\", h, \"\\n\")\n",
    "    next_states = []\n",
    "    for i in range(num_particles):\n",
    "        print(\"i \", i, \"\\n\")\n",
    "        if h >0:\n",
    "            env_i = copy.deepcopy(env)  # Assuming prob_vars.env is an environment object with a copy method\n",
    "            env_i.reset(seed=seed)\n",
    "            env_i.state = sim_states[i].numpy()  # Set the initial state of the environment\n",
    "        else: # if h == 0:\n",
    "            env_i = copy.deepcopy(env)  # Assuming prob_vars.env is an environment object with a copy method\n",
    "            env_i.reset(seed=seed)\n",
    "            if isinstance(sim_states, torch.Tensor):\n",
    "                sim_states.detach().cpu().numpy()  # Safely convert to NumPy\n",
    "            env_i.state = sim_states # Set the initial state of the environment\n",
    "        print(\"env_i.state \", env_i.state, \"\\n\")\n",
    "        # print(env_i.step(env_i.action_space.sample()))\n",
    "        action = env_i.action_space.sample()\n",
    "        next_state_step, reward, terminated, truncated, info = env_i.step(env_i.action_space.sample())  # Sample a random action\n",
    "        next_state = env_i.state\n",
    "        print(\"action \", action, \"\\n\")\n",
    "        print(\"next_state \", next_state, \"\\n\")\n",
    "        next_states.append(next_state)\n",
    "    \n",
    "    next_states = np.clip(next_states, env.observation_space.low, env.observation_space.high)\n",
    "    sim_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "    print(\"sim_states\", sim_states, \"\\n\")\n",
    "    # sim_states = torch.clip(sim_states, env.observation_space.low, env.observation_space.high)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a4842f",
   "metadata": {},
   "source": [
    "## Same for MuJoCo Reacher and MuJoCo Pusher\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
